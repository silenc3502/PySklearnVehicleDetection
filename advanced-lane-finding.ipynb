{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "import math\n",
    "import webcolors\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# We have modularize our dynamic, multi-stage, multi-component pipeline\n",
    "# for Udacity Self-Driving Car: Project 5: Vehicle Detection and Tracking\n",
    "#\n",
    "# These include:\n",
    "# 1. CameraCal: class that handles camera calibration operations\n",
    "#from p5lib.cameraCal import CameraCal\n",
    "\n",
    "# 2. ImageFilters: class that handles image analysis and filtering operations\n",
    "#from p5lib.imageFilters import ImageFilters\n",
    "\n",
    "# 3. ProjectionManager: class that handles projection calculations and\n",
    "#    operations\n",
    "#from p5lib.projectionManager import ProjectionManager\n",
    "\n",
    "# 4. Line: class that handles line detection, measurements and confidence\n",
    "#    calculations and operations\n",
    "#from p5lib.line import Line\n",
    "\n",
    "# 5. Lane: class that handles multi-lane detection calculations\n",
    "#    and operations\n",
    "#from p5lib.lane import Lane\n",
    "\n",
    "# 9. RoadManager: class that handles image, projection, line, lane, vehicle\n",
    "#    propagation pipeline decisions\n",
    "#from p5lib.roadManager import RoadManager\n",
    "\n",
    "# 10. DiagManager: class that handles diagnostic output requests\n",
    "#from p5lib.diagManager import DiagManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera calibration\n",
    "\n",
    "Computation of the calibration parameters, and example proving we obtain the expected result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CameraCal():\n",
    "\n",
    "    # initialize - either go through and calculate the camera\n",
    "    # calibration if no pickle file exists\n",
    "    # or just load the pickle file.\n",
    "    def __init__(self, calibration_dir, pickle_file):\n",
    "        # Initialize cameraCal\n",
    "        self.mtx = None\n",
    "        self.dist = None\n",
    "        self.img_size = None\n",
    "\n",
    "        if not os.path.isfile(pickle_file):\n",
    "            objpoints = []  # 3d points in real world space\n",
    "            imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "            # prepare object points: (0,0,0), (1,0,0), (2,0,0) .., (6,5,0)\n",
    "            # The images may have different detected checker board dimensions!\n",
    "            # Currently, possible dimension combinations are: (9,6), (8,6),\n",
    "            # (9,5), (9,4) and (7,6)\n",
    "            objp1 = np.zeros((6 * 9, 3), np.float32)\n",
    "            objp1[:, :2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)\n",
    "            objp2 = np.zeros((6 * 8, 3), np.float32)\n",
    "            objp2[:, :2] = np.mgrid[0:8, 0:6].T.reshape(-1, 2)\n",
    "            objp3 = np.zeros((5 * 9, 3), np.float32)\n",
    "            objp3[:, :2] = np.mgrid[0:9, 0:5].T.reshape(-1, 2)\n",
    "            objp4 = np.zeros((4 * 9, 3), np.float32)\n",
    "            objp4[:, :2] = np.mgrid[0:9, 0:4].T.reshape(-1, 2)\n",
    "            objp5 = np.zeros((6 * 7, 3), np.float32)\n",
    "            objp5[:, :2] = np.mgrid[0:7, 0:6].T.reshape(-1, 2)\n",
    "            objp6 = np.zeros((6 * 5, 3), np.float32)\n",
    "            objp6[:, :2] = np.mgrid[0:5, 0:6].T.reshape(-1, 2)\n",
    "\n",
    "            text = 'Performing camara calibrations against chessboard images: '\n",
    "            print('{}\"./{}/calibration*.jpg\"...'.format(text, calibration_dir))\n",
    "            # Make a list of calibration images\n",
    "            images = glob.glob(calibration_dir + '/calibration*.jpg')\n",
    "\n",
    "            # Step through the list and search for chessboard corners\n",
    "            for idx, fname in enumerate(images):\n",
    "                img = cv2.imread(fname)\n",
    "                img2 = np.copy(img)\n",
    "                self.img_size = (img.shape[1], img.shape[0])\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Find the chessboard corners using possible combinations of\n",
    "                # dimensions.\n",
    "                ret, corners = cv2.findChessboardCorners(gray, (9, 6), None)\n",
    "                objp = objp1\n",
    "                if not ret:\n",
    "                    ret, corners = cv2.findChessboardCorners(\n",
    "                        gray, (8, 6), None)\n",
    "                    objp = objp2\n",
    "                if not ret:\n",
    "                    ret, corners = cv2.findChessboardCorners(\n",
    "                        gray, (9, 5), None)\n",
    "                    objp = objp3\n",
    "                if not ret:\n",
    "                    ret, corners = cv2.findChessboardCorners(\n",
    "                        gray, (9, 4), None)\n",
    "                    objp = objp4\n",
    "                if not ret:\n",
    "                    ret, corners = cv2.findChessboardCorners(\n",
    "                        gray, (7, 6), None)\n",
    "                    objp = objp5\n",
    "                if not ret:\n",
    "                    ret, corners = cv2.findChessboardCorners(\n",
    "                        gray, (5, 6), None)\n",
    "                    objp = objp6\n",
    "                # print(\"corners: \", corners.shape, \"\\n\", corners)\n",
    "\n",
    "                # If found, add object points, image points\n",
    "                if ret:\n",
    "                    objpoints.append(objp)\n",
    "                    imgpoints.append(corners)\n",
    "                    cv2.drawChessboardCorners(img2,\n",
    "                                              (corners.shape[1],\n",
    "                                               corners.shape[0]),\n",
    "                                              corners, ret)\n",
    "                    ret, self.mtx, self.dist, self.rvecs, self.tvecs = \\\n",
    "                        cv2.calibrateCamera(objpoints, imgpoints,\n",
    "                                            self.img_size, None, None)\n",
    "\n",
    "            # done and found all chessboard corners.\n",
    "            # now time to save the results into a pickle file for later\n",
    "            # retrieval without additional calculations.\n",
    "            try:\n",
    "                with open(pickle_file, 'w+b') as pfile1:\n",
    "                    text = 'Saving data to pickle file'\n",
    "                    print('{}: {} ...'.format(text, pickle_file))\n",
    "                    pickle.dump({'img_size': self.img_size,\n",
    "                                 'mtx': self.mtx,\n",
    "                                 'dist': self.dist,\n",
    "                                 'rvecs': self.rvecs,\n",
    "                                 'tvecs': self.tvecs},\n",
    "                                pfile1, pickle.HIGHEST_PROTOCOL)\n",
    "                    print(\"Camera Calibration Data saved to\", pickle_file)\n",
    "            except Exception as e:\n",
    "                print('Unable to save data to', pickle_file, ':', e)\n",
    "                raise\n",
    "\n",
    "        # previously saved pickle file of the distortion correction data\n",
    "        # has been found.  go ahead and revive it.\n",
    "        else:\n",
    "            try:\n",
    "                with open(pickle_file, 'rb') as f:\n",
    "                    pickle_data = pickle.load(f)\n",
    "                    self.img_size = pickle_data['img_size']\n",
    "                    self.mtx = pickle_data['mtx']\n",
    "                    self.dist = pickle_data['dist']\n",
    "                    self.rvecs = pickle_data['rvecs']\n",
    "                    self.tvecs = pickle_data['tvecs']\n",
    "                    del pickle_data\n",
    "                    print(\"Camera Calibration data restored from\", pickle_file)\n",
    "            except Exception as e:\n",
    "                print('Unable to restore camera calibration data from',\n",
    "                      pickle_file, ':', e)\n",
    "                raise\n",
    "\n",
    "    # if the source image is now smaller than the original calibration image\n",
    "    # just set it\n",
    "    def setImageSize(self, img_shape):\n",
    "        self.img_size = (img_shape[1], img_shape[0])\n",
    "\n",
    "    # Get a subset of the camera calibration result that\n",
    "    # the rest of the pipeline wants\n",
    "    def get(self):\n",
    "        return self.mtx, self.dist, self.img_size\n",
    "\n",
    "    # Get all of the camera calibration result that\n",
    "    # the rest of the pipeline wants\n",
    "    def getall(self):\n",
    "        return self.mtx, self.dist, self.img_size, self.rvecs, self.tvecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Filter\n",
    "\n",
    "Image Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFilters():\n",
    "    # Initialize ImageFilter\n",
    "\n",
    "    def __init__(self, camCal, projectedX, projectedY,\n",
    "                 defaultThrowDistance=100.0, debug=False):\n",
    "        # set debugging\n",
    "        self.debug = debug\n",
    "\n",
    "        # frameNumber\n",
    "        self.curFrame = None\n",
    "\n",
    "        # our own copy of the camera calibration results\n",
    "        self.mtx, self.dist, self.img_size = camCal.get()\n",
    "\n",
    "        # normal image size\n",
    "        self.x, self.y = self.img_size\n",
    "\n",
    "        # projected image size\n",
    "        self.projectedX = projectedX\n",
    "        self.projectedY = projectedY\n",
    "\n",
    "        # mid point in picture (by height)\n",
    "        self.mid = int(self.y / 2)\n",
    "\n",
    "        # current Image RGB - undistorted\n",
    "        self.curImage = np.zeros((self.y, self.x, 3), dtype=np.float32)\n",
    "\n",
    "        # current Image Top half RGB\n",
    "        self.curSkyRGB = np.zeros((self.mid, self.x, 3), dtype=np.float32)\n",
    "\n",
    "        # current Image Bottom half RGB\n",
    "        self.curRoadRGB = np.zeros((self.mid, self.x, 3), dtype=np.float32)\n",
    "\n",
    "        # current Sky Luma Image\n",
    "        self.curSkyL = np.zeros((self.mid, self.x), dtype=np.float32)\n",
    "\n",
    "        # current Road Luma Image\n",
    "        self.curRoadL = np.zeros((self.mid, self.x), dtype=np.float32)\n",
    "\n",
    "        # current Edge\n",
    "        self.curRoadEdge = np.zeros((self.mid, self.x), dtype=np.uint8)\n",
    "        self.curRoadEdgeProjected = np.zeros(\n",
    "            (self.projectedY, self.projectedX, 3), dtype=np.uint8)\n",
    "\n",
    "        # current Projected image\n",
    "        self.curRoadProjected = np.zeros(\n",
    "            (self.projectedY, self.projectedX, 3), dtype=np.uint8)\n",
    "\n",
    "        # image stats\n",
    "        self.skylrgb = np.zeros((4), dtype=np.float32)\n",
    "        self.roadlrgb = np.zeros((4), dtype=np.float32)\n",
    "        self.roadbalance = 0.0\n",
    "        self.horizonFound = False\n",
    "        self.roadhorizon = 0\n",
    "        self.visibility = 0\n",
    "        self.defaultThrowDistance = defaultThrowDistance\n",
    "        self.throwDistanceFound = False\n",
    "        self.throwDistancePixel = self.projectedY\n",
    "        self.throwDistance = defaultThrowDistance\n",
    "\n",
    "        # Textural Image Info\n",
    "        self.skyText = 'NOIMAGE'\n",
    "        self.skyImageQ = 'NOIMAGE'\n",
    "        self.roadText = 'NOIMAGE'\n",
    "        self.roadImageQ = 'NOIMAGE'\n",
    "\n",
    "        # set up debugging diag screens\n",
    "        if self.debug:\n",
    "            self.diag1 = np.zeros((self.mid, self.x, 3), dtype=np.float32)\n",
    "            self.diag2 = np.zeros((self.mid, self.x, 3), dtype=np.float32)\n",
    "            self.diag3 = np.zeros((self.mid, self.x, 3), dtype=np.float32)\n",
    "            self.diag4 = np.zeros((self.mid, self.x, 3), dtype=np.float32)\n",
    "\n",
    "    # Define a function to chop a picture in half horizontally\n",
    "    def makehalf(self, image, half=0):\n",
    "        if half == 0:\n",
    "            if len(image.shape) < 3:\n",
    "                newimage = np.copy(image[self.mid:self.y, :])\n",
    "            else:\n",
    "                newimage = np.copy(image[self.mid:self.y, :, :])\n",
    "        else:\n",
    "            if len(image.shape) < 3:\n",
    "                newimage = np.copy(image[0:self.mid, :])\n",
    "            else:\n",
    "                newimage = np.copy(image[0:self.mid, :, :])\n",
    "        return newimage\n",
    "\n",
    "    # Define a function to make a half picture whole horizontally\n",
    "    def makefull(self, image, half=0):\n",
    "        if len(image.shape) < 3:\n",
    "            newimage = np.zeros((self.y, self.x), dtype=np.uint8)\n",
    "        else:\n",
    "            newimage = np.zeros((self.y, self.x, 3), dtype=np.uint8)\n",
    "\n",
    "        if half == 0:\n",
    "            if len(image.shape) < 3:\n",
    "                newimage[self.mid:self.y, :] = image\n",
    "            else:\n",
    "                newimage[self.mid:self.y, :, :] = image\n",
    "        else:\n",
    "            if len(image.shape) < 3:\n",
    "                newimage[0:self.mid, :] = image\n",
    "            else:\n",
    "                newimage[0:self.mid, :, :] = image\n",
    "        return newimage\n",
    "\n",
    "    # Define a function that attempts to masks out yellow lane lines\n",
    "    def image_only_yellow_white(self, image):\n",
    "        # setup inRange to mask off everything except white and yellow\n",
    "        lower_yellow_white = np.array([140, 140, 64])\n",
    "        upper_yellow_white = np.array([255, 255, 255])\n",
    "        mask = cv2.inRange(image, lower_yellow_white, upper_yellow_white)\n",
    "        return cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Define a function that applies Gaussian Noise kernel\n",
    "    def gaussian_blur(self, img, kernel_size):\n",
    "        return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "    # Define a function that applies Canny transform\n",
    "    def canny(self, img, low_threshold, high_threshold, kernel_size):\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        blur_gray = self.gaussian_blur(gray, kernel_size)\n",
    "        return cv2.Canny(\n",
    "            blur_gray.astype(np.uint8), low_threshold, high_threshold)\n",
    "\n",
    "    # Define a function that applies Sobel x or y,\n",
    "    # then takes an absolute value and applies a threshold.\n",
    "    def abs_sobel_thresh(self, img, orient='x', thresh=(0, 255)):\n",
    "        # Apply the following steps to img\n",
    "        # 1) Convert to grayscale\n",
    "        # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "        # 3) Take the absolute value of the derivative or gradient\n",
    "        # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "        # 5) Create a mask of 1's where the scaled gradient magnitude\n",
    "        #    is > thresh_min and < thresh_max\n",
    "        # 6) Return this mask as your binary_output image\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        if orient == 'x':\n",
    "            sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "            abs_sobel = np.absolute(sobelx)\n",
    "        if orient == 'y':\n",
    "            sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "            abs_sobel = np.absolute(sobely)\n",
    "        # Rescale back to 8 bit integer\n",
    "        scaled_sobel = np.uint8(255 * abs_sobel / np.max(abs_sobel))\n",
    "        # Create a copy and apply the threshold\n",
    "        ret, binary_output = cv2.threshold(\n",
    "            scaled_sobel, thresh[0], thresh[1], cv2.THRESH_BINARY)\n",
    "        # Return the result\n",
    "        return binary_output\n",
    "\n",
    "    # Define a function that applies Sobel x and y,\n",
    "    # then computes the magnitude of the gradient\n",
    "    # and applies a threshold\n",
    "    def mag_thresh(self, img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "        # Apply the following steps to img\n",
    "        # 1) Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        # 2) Take the gradient in x and y separately\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "        # 3) Calculate the magnitude\n",
    "        gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "        # 5) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "        scale_factor = np.max(gradmag) / 255\n",
    "        gradmag = (gradmag / scale_factor).astype(np.uint8)\n",
    "        # 6) Create a binary mask where mag thresholds are met\n",
    "        ret, mag_binary = cv2.threshold(\n",
    "            gradmag, mag_thresh[0], mag_thresh[1], cv2.THRESH_BINARY)\n",
    "        # 7) Return this mask as your binary_output image\n",
    "        return mag_binary\n",
    "\n",
    "    # Define a function that applies Sobel x and y,\n",
    "    # then computes the direction of the gradient\n",
    "    # and applies a threshold.\n",
    "    def dir_threshold(self, img, sobel_kernel=3, thresh=(0, np.pi / 2)):\n",
    "        # Apply the following steps to img\n",
    "        # 1) Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        # 2) Take the gradient in x and y separately\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "        # 3) Calculate the direction of the gradient\n",
    "        # 4) Take the absolute value\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            dirout = np.absolute(np.arctan(sobely / sobelx))\n",
    "            # 5) Create a binary mask where direction thresholds are met\n",
    "            dir_binary = np.zeros_like(dirout).astype(np.float32)\n",
    "            dir_binary[(dirout > thresh[0]) & (dirout < thresh[1])] = 1\n",
    "            # 6) Return this mask as your binary_output image\n",
    "        # update nan to number\n",
    "        np.nan_to_num(dir_binary)\n",
    "        # make it fit\n",
    "        dir_binary[(dir_binary > 0) | (dir_binary < 0)] = 128\n",
    "        return dir_binary.astype(np.uint8)\n",
    "\n",
    "    # Python 3 has support for cool math symbols.\n",
    "    def miximg(self, img1, img2, α=0.8, β=1., λ=0.):\n",
    "        \"\"\"\n",
    "        The result image is computed as follows:\n",
    "        img1 * α + img2 * β + λ\n",
    "        NOTE: img1 and img2 must be the same shape!\n",
    "        \"\"\"\n",
    "        return cv2.addWeighted(img1.astype(np.uint8),\n",
    "                               α, img2.astype(np.uint8), β, λ)\n",
    "\n",
    "    # Define a function that thresholds the S-channel of HLS\n",
    "    def hls_s(self, img, thresh=(0, 255)):\n",
    "        # 1) Convert to HLS color space\n",
    "        # 2) Apply a threshold to the S channel\n",
    "        # 3) Return a binary image of threshold result\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        s = hls[:, :, 2]\n",
    "        retval, s_binary = cv2.threshold(s.astype('uint8'), thresh[\n",
    "                                         0], thresh[1], cv2.THRESH_BINARY)\n",
    "        return s_binary\n",
    "\n",
    "    # Define a function that thresholds the H-channel of HLS\n",
    "    def hls_h(self, img, thresh=(0, 255)):\n",
    "        # 1) Convert to HLS color space\n",
    "        # 2) Apply a threshold to the S channel\n",
    "        # 3) Return a binary image of threshold result\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        h = hls[:, :, 0]\n",
    "        retval, h_binary = cv2.threshold(h.astype('uint8'), thresh[\n",
    "                                         0], thresh[1], cv2.THRESH_BINARY)\n",
    "        return h_binary\n",
    "\n",
    "    # retrieve edges detected by the filter combinations (used by other\n",
    "    # modules to locate current binary image.)\n",
    "    def edges(self):\n",
    "        # piece together images that we want to project\n",
    "        img = np.zeros((self.y, self.x, 3), dtype=np.uint8)\n",
    "        img[self.mid:self.y, :, :] = np.dstack(\n",
    "            (self.curRoadEdge, self.curRoadEdge, self.curRoadEdge))\n",
    "        return img\n",
    "\n",
    "    # check image quality\n",
    "    def imageQ(self, image):\n",
    "        self.curImage = cv2.undistort(\n",
    "            image, self.mtx, self.dist, None, self.mtx).astype(np.float32)\n",
    "        self.yuv = cv2.cvtColor(\n",
    "            self.curImage, cv2.COLOR_RGB2YUV).astype(np.float32)\n",
    "\n",
    "        # get some stats for the sky image\n",
    "        self.curSkyL = self.yuv[0:self.mid, :, 0]\n",
    "        self.curSkyRGB[:, :] = self.curImage[0:self.mid, :]\n",
    "        self.skylrgb[0] = np.average(self.curSkyL[0:self.mid, :])\n",
    "        self.skylrgb[1] = np.average(self.curSkyRGB[0:self.mid, :, 0])\n",
    "        self.skylrgb[2] = np.average(self.curSkyRGB[0:self.mid, :, 1])\n",
    "        self.skylrgb[3] = np.average(self.curSkyRGB[0:self.mid, :, 2])\n",
    "\n",
    "        # get some stats for the road image\n",
    "        self.curRoadL = self.yuv[self.mid:self.y, :, 0]\n",
    "        self.curRoadRGB[:, :] = self.curImage[self.mid:self.y, :]\n",
    "        self.roadlrgb[0] = np.average(self.curRoadL[0:self.mid, :])\n",
    "        self.roadlrgb[1] = np.average(self.curRoadRGB[0:self.mid, :, 0])\n",
    "        self.roadlrgb[2] = np.average(self.curRoadRGB[0:self.mid, :, 1])\n",
    "        self.roadlrgb[3] = np.average(self.curRoadRGB[0:self.mid, :, 2])\n",
    "\n",
    "        # Sky image condition\n",
    "        if self.skylrgb[0] > 160:\n",
    "            self.skyImageQ = 'Sky Image: overexposed'\n",
    "        elif self.skylrgb[0] < 50:\n",
    "            self.skyImageQ = 'Sky Image: underexposed'\n",
    "        elif self.skylrgb[0] > 143:\n",
    "            self.skyImageQ = 'Sky Image: normal bright'\n",
    "        elif self.skylrgb[0] < 113:\n",
    "            self.skyImageQ = 'Sky Image: normal dark'\n",
    "        else:\n",
    "            self.skyImageQ = 'Sky Image: normal'\n",
    "\n",
    "        # Sky detected weather or lighting conditions\n",
    "        if self.skylrgb[0] > 128:\n",
    "            if self.skylrgb[3] > self.skylrgb[0]:\n",
    "                if self.skylrgb[1] > 120 and self.skylrgb[2] > 120:\n",
    "                    if (self.skylrgb[2] - self.skylrgb[1]) > 20.0:\n",
    "                        self.skyText = 'Sky Condition: tree shaded'\n",
    "                    else:\n",
    "                        self.skyText = 'Sky Condition: cloudy'\n",
    "                else:\n",
    "                    self.skyText = 'Sky Condition: clear'\n",
    "            else:\n",
    "                self.skyText = 'Sky Condition: UNKNOWN SKYL>128'\n",
    "        else:\n",
    "            if self.skylrgb[2] > self.skylrgb[3]:\n",
    "                self.skyText = 'Sky Condition: surrounded by trees'\n",
    "                self.visibility = -80\n",
    "            elif self.skylrgb[3] > self.skylrgb[0]:\n",
    "                if (self.skylrgb[2] - self.skylrgb[1]) > 10.0:\n",
    "                    self.skyText = 'Sky Condition: tree shaded'\n",
    "                else:\n",
    "                    self.skyText = \\\n",
    "                        'Sky Condition: very cloudy or under overpass'\n",
    "            else:\n",
    "                self.skyText = 'Sky Condition: UNKNOWN!'\n",
    "\n",
    "        self.roadbalance = self.roadlrgb[0] / 10.0\n",
    "\n",
    "        # Road image condition\n",
    "        if self.roadlrgb[0] > 160:\n",
    "            self.roadImageQ = 'Road Image: overexposed'\n",
    "        elif self.roadlrgb[0] < 50:\n",
    "            self.roadImageQ = 'Road Image: underexposed'\n",
    "        elif self.roadlrgb[0] > 143:\n",
    "            self.roadImageQ = 'Road Image: normal bright'\n",
    "        elif self.roadlrgb[0] < 113:\n",
    "            self.roadImageQ = 'Road Image: normal dark'\n",
    "        else:\n",
    "            self.roadImageQ = 'Road Image: normal'\n",
    "\n",
    "    # function to detect the horizon using the Sobel magnitude operation\n",
    "    def horizonDetect(self, debug=False, thresh=50):\n",
    "        if not self.horizonFound:\n",
    "            img = np.copy(self.curRoadRGB).astype(np.uint8)\n",
    "            magch = self.mag_thresh(img, sobel_kernel=9, mag_thresh=(30, 150))\n",
    "            horizonLine = 50\n",
    "            while not self.horizonFound and horizonLine < int(self.y / 2):\n",
    "                magchlinesum = np.sum(\n",
    "                    magch[horizonLine:(horizonLine + 1), :]).astype(np.float32)\n",
    "                if magchlinesum > (self.x * thresh):\n",
    "                    self.horizonFound = True\n",
    "                    self.roadhorizon = horizonLine + int(self.y / 2)\n",
    "                    if debug:\n",
    "                        self.diag4[horizonLine:(horizonLine + 1), :, 0] = 255\n",
    "                        self.diag4[horizonLine:(horizonLine + 1), :, 1] = 255\n",
    "                        self.diag4[horizonLine:(horizonLine + 1), :, 2] = 0\n",
    "                else:\n",
    "                    horizonLine += 1\n",
    "\n",
    "    # function to detect the throw distance of the projection\n",
    "    def projectionThrowDistanceDetect(self, debug=False, thresh=150.0):\n",
    "        # maxThrowSum = 0\n",
    "        if not self.throwDistanceFound:\n",
    "            maskedEdge = np.copy(self.curRoadEdgeProjected[\n",
    "                                 :, :, 1]).astype(np.uint8)\n",
    "            topOfThrow = 0\n",
    "            while not self.throwDistanceFound and \\\n",
    "                    topOfThrow < int(self.projectedY * 0.75):\n",
    "                maskedEdgeLineSum = np.sum(\n",
    "                     maskedEdge[topOfThrow:(topOfThrow + 1), :])\n",
    "                maskedEdgeLineSum = maskedEdgeLineSum.astype(np.float32)\n",
    "\n",
    "                # if maxThrowSum < maskedEdgeLineSum:\n",
    "                #    maxThrowSum = maskedEdgeLineSum\n",
    "                if maskedEdgeLineSum > thresh:\n",
    "                    self.throwDistanceFound = True\n",
    "                    self.throwDistancePixel = topOfThrow\n",
    "                    self.throwDistance = self.throwDistance * \\\n",
    "                        ((self.projectedY - topOfThrow) / self.projectedY)\n",
    "                    if debug:\n",
    "                        self.curRoadEdgeProjected[\n",
    "                            topOfThrow:(topOfThrow + 1), :, 0] = 0\n",
    "                        self.curRoadEdgeProjected[\n",
    "                            topOfThrow:(topOfThrow + 1), :, 1] = 255\n",
    "                        self.curRoadEdgeProjected[\n",
    "                            topOfThrow:(topOfThrow + 1), :, 2] = 0\n",
    "                else:\n",
    "                    topOfThrow += 1\n",
    "        # print(\"maxThrowSum: \", maxThrowSum)\n",
    "        return self.throwDistancePixel\n",
    "\n",
    "    # function to attempt to balance the image exposure for easier lane line\n",
    "    # detection\n",
    "    def balanceEx(self):\n",
    "        # separate each of the RGB color channels\n",
    "        r = self.curRoadRGB[:, :, 0]\n",
    "        g = self.curRoadRGB[:, :, 1]\n",
    "        b = self.curRoadRGB[:, :, 2]\n",
    "        # Get the Y channel (Luma) from the YUV color space\n",
    "        # and make two copies\n",
    "        yo = np.copy(self.curRoadL[:, :]).astype(np.float32)\n",
    "        yc = np.copy(self.curRoadL[:, :]).astype(np.float32)\n",
    "        # use the balance factor calculated previously to calculate the\n",
    "        # corrected Y\n",
    "        yc = (yc / self.roadbalance) * 8.0\n",
    "        # make a copy and threshold it to maximum value 255.\n",
    "        lymask = np.copy(yc)\n",
    "        lymask[(lymask > 255.0)] = 255.0\n",
    "        # create another mask that attempts to masks yellow road markings.\n",
    "        uymask = np.copy(yc) * 0\n",
    "        # subtract the thresholded mask from the corrected Y.\n",
    "        # Now we just have peaks.\n",
    "        yc -= lymask\n",
    "        # If we are dealing with an over exposed image\n",
    "        # cap its corrected Y to 242.\n",
    "        if self.roadlrgb[0] > 160:\n",
    "            yc[(b > 254) & (g > 254) & (r > 254)] = 242.0\n",
    "        # If we are dealing with a darker image\n",
    "        # try to pickup faint blue and cap them to 242.\n",
    "        elif self.roadlrgb[0] < 128:\n",
    "            yc[(b > self.roadlrgb[3]) & (\n",
    "                yo > 160 + (self.roadbalance * 20))] = 242.0\n",
    "        else:\n",
    "            yc[(b > self.roadlrgb[3]) & (\n",
    "                yo > 210 + (self.roadbalance * 10))] = 242.0\n",
    "        # attempt to mask yellow lane lines\n",
    "        uymask[(b < self.roadlrgb[0]) & (r > self.roadlrgb[0]) &\n",
    "               (g > self.roadlrgb[0])] = 242.0\n",
    "        # combined the corrected road luma and the masked yellow\n",
    "        yc = self.miximg(yc, uymask, 1.0, 1.0)\n",
    "        # mix it back to the original luma.\n",
    "        yc = self.miximg(yc, yo, 1.0, 0.8)\n",
    "        # resize the image in an attempt to get the lane lines to the bottom.\n",
    "        yc[int((self.y / 72) * 70):self.y, :] = 0\n",
    "        self.yuv[self.mid:self.y, :, 0] = yc.astype(np.uint8)\n",
    "        self.yuv[(self.y - 40):self.y, :, 0] = \\\n",
    "            yo[(self.mid - 40):self.mid, :].astype(np.uint8)\n",
    "        # convert back to RGB.\n",
    "        self.curRoadRGB = cv2.cvtColor(\n",
    "            self.yuv[self.mid:self.y, :, :], cv2.COLOR_YUV2RGB)\n",
    "\n",
    "    # filter 1\n",
    "    # builds combination number 1\n",
    "    def applyFilter1(self):\n",
    "        # Run the functions\n",
    "        img = np.copy(self.curRoadRGB).astype(np.uint8)\n",
    "        gradx = self.abs_sobel_thresh(img, orient='x', thresh=(25, 100))\n",
    "        grady = self.abs_sobel_thresh(img, orient='y', thresh=(50, 150))\n",
    "        magch = self.mag_thresh(img, sobel_kernel=9, mag_thresh=(50, 250))\n",
    "        dirch = self.dir_threshold(img, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "        sch = self.hls_s(img, thresh=(88, 190))\n",
    "        hch = self.hls_h(img, thresh=(50, 100))\n",
    "\n",
    "        # Output \"masked_lines\" is a single channel mask\n",
    "        shadow = np.zeros_like(dirch).astype(np.uint8)\n",
    "        shadow[(sch > 0) & (hch > 0)] = 128\n",
    "\n",
    "        # create the Red filter\n",
    "        rEdgeDetect = img[:, :, 0] / 4\n",
    "        rEdgeDetect = 255 - rEdgeDetect\n",
    "        rEdgeDetect[(rEdgeDetect > 210)] = 0\n",
    "\n",
    "        # build the combination\n",
    "        combined = np.zeros_like(dirch).astype(np.uint8)\n",
    "        combined[((gradx > 0) | (grady > 0) | ((magch > 0) & (dirch > 0)) | (\n",
    "            sch > 0)) & (shadow == 0) & (rEdgeDetect > 0)] = 35\n",
    "        self.curRoadEdge = combined\n",
    "\n",
    "        # build diag screen if in debug mode\n",
    "        if self.debug:\n",
    "            # create diagnostic screen 1-3\n",
    "            # creating a blank color channel for combining\n",
    "            ignore_color = np.copy(gradx) * 0\n",
    "            self.diag1 = np.dstack((rEdgeDetect, gradx, grady))\n",
    "            self.diag2 = np.dstack((ignore_color, magch, dirch))\n",
    "            self.diag3 = np.dstack((sch, shadow, hch))\n",
    "            self.diag4 = np.dstack((combined, combined, combined)) * 4\n",
    "\n",
    "    # filter 2\n",
    "    # builds combination number 2\n",
    "    def applyFilter2(self):\n",
    "        # Run the functions\n",
    "        img = np.copy(self.curRoadRGB).astype(np.uint8)\n",
    "        gradx = self.abs_sobel_thresh(img, orient='x', thresh=(25, 100))\n",
    "        grady = self.abs_sobel_thresh(img, orient='y', thresh=(50, 150))\n",
    "        magch = self.mag_thresh(img, sobel_kernel=9, mag_thresh=(50, 250))\n",
    "        dirch = self.dir_threshold(img, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "        sch = self.hls_s(img, thresh=(88, 250))\n",
    "        hch = self.hls_h(img, thresh=(50, 100))\n",
    "\n",
    "        # Output \"masked_lines\" is a single channel mask\n",
    "        shadow = np.zeros_like(dirch).astype(np.uint8)\n",
    "        shadow[(sch > 0) & (hch > 0)] = 128\n",
    "\n",
    "        # create the Red filter\n",
    "        rEdgeDetect = img[:, :, 0] / 4\n",
    "        rEdgeDetect = 255 - rEdgeDetect\n",
    "        rEdgeDetect[(rEdgeDetect > 210)] = 0\n",
    "\n",
    "        # build the combination\n",
    "        combined = np.zeros_like(dirch).astype(np.uint8)\n",
    "        combined[((gradx > 0) | (grady > 0) | ((magch > 0) & (dirch > 0)) | (\n",
    "            sch > 0)) & (shadow == 0) & (rEdgeDetect > 0)] = 35\n",
    "        combined[(grady > 0) & (dirch > 0) & (magch > 0)] = 35\n",
    "        self.curRoadEdge = combined\n",
    "\n",
    "        # build diag screen if in debug mode\n",
    "        if self.debug:\n",
    "            # create diagnostic screen 1-3\n",
    "            # creating a blank color channel for combining\n",
    "            ignore_color = np.copy(gradx) * 0\n",
    "            self.diag1 = np.dstack((rEdgeDetect, gradx, grady))\n",
    "            self.diag2 = np.dstack((ignore_color, magch, dirch))\n",
    "            self.diag3 = np.dstack((sch, shadow, hch))\n",
    "            self.diag4 = np.dstack((combined, combined, combined)) * 4\n",
    "\n",
    "    # filter 3\n",
    "    # builds combination number 3\n",
    "    def applyFilter3(self):\n",
    "        # Run the functions\n",
    "        img = np.copy(self.curRoadRGB).astype(np.uint8)\n",
    "        gradx = self.abs_sobel_thresh(img, orient='x', thresh=(25, 100))\n",
    "        grady = self.abs_sobel_thresh(img, orient='y', thresh=(50, 150))\n",
    "        magch = self.mag_thresh(img, sobel_kernel=9, mag_thresh=(30, 150))\n",
    "        dirch = self.dir_threshold(img, sobel_kernel=15, thresh=(0.6, 1.3))\n",
    "        sch = self.hls_s(img, thresh=(20, 100))\n",
    "        hch = self.hls_h(img, thresh=(125, 175))\n",
    "\n",
    "        # create the Red filter\n",
    "        rEdgeDetect = img[:, :, 0] / 4\n",
    "        rEdgeDetect = 255 - rEdgeDetect\n",
    "        rEdgeDetect[(rEdgeDetect > 220)] = 0\n",
    "\n",
    "        # Output \"masked_lines\" is a single channel mask\n",
    "        shadow = np.zeros_like(dirch).astype(np.uint8)\n",
    "        shadow[(sch > 0) & (hch > 0)] = 128\n",
    "\n",
    "        # build the combination\n",
    "        combined = np.zeros_like(dirch).astype(np.uint8)\n",
    "        combined[((gradx > 0) | (grady > 0) | ((magch > 0) & (dirch > 0)) | (\n",
    "            sch > 0)) & (shadow == 0) & (rEdgeDetect > 0)] = 35\n",
    "        self.curRoadEdge = combined\n",
    "\n",
    "        # build diag screen if in debug mode\n",
    "        if self.debug:\n",
    "            # create diagnostic screen 1-3\n",
    "            # creating a blank color channel for combining\n",
    "            ignore_color = np.copy(gradx) * 0\n",
    "            self.diag1 = np.dstack((rEdgeDetect, gradx, grady))\n",
    "            self.diag2 = np.dstack((ignore_color, magch, dirch))\n",
    "            self.diag3 = np.dstack((sch, shadow, hch))\n",
    "            self.diag4 = np.dstack((combined, combined, combined)) * 4\n",
    "\n",
    "    # filter 4\n",
    "    # builds combination number 4\n",
    "    def applyFilter4(self):\n",
    "        # Run the functions\n",
    "        img = np.copy(self.curRoadRGB).astype(np.uint8)\n",
    "        gradx = self.abs_sobel_thresh(img, orient='x', thresh=(30, 100))\n",
    "        grady = self.abs_sobel_thresh(img, orient='y', thresh=(75, 150))\n",
    "        magch = self.mag_thresh(img, sobel_kernel=9, mag_thresh=(30, 150))\n",
    "        dirch = self.dir_threshold(img, sobel_kernel=15, thresh=(0.6, 1.3))\n",
    "        sch = self.hls_s(img, thresh=(20, 100))\n",
    "        hch = self.hls_h(img, thresh=(125, 175))\n",
    "\n",
    "        # create the Red filter\n",
    "        rEdgeDetect = img[:, :, 0] / 4\n",
    "        rEdgeDetect = 255 - rEdgeDetect\n",
    "        rEdgeDetect[(rEdgeDetect > 220)] = 0\n",
    "\n",
    "        # Output \"masked_lines\" is a single channel mask\n",
    "        shadow = np.zeros_like(dirch).astype(np.uint8)\n",
    "        shadow[(sch > 0) & (hch > 0)] = 128\n",
    "\n",
    "        # build the combination\n",
    "        combined = np.zeros_like(dirch).astype(np.uint8)\n",
    "        combined[((magch > 0) & (dirch > 0)) | (\n",
    "            (rEdgeDetect > 192) & (rEdgeDetect < 200) & (magch > 0))] = 35\n",
    "        self.curRoadEdge = combined\n",
    "\n",
    "        # build diag screen if in debug mode\n",
    "        if self.debug:\n",
    "            # create diagnostic screen 1-3\n",
    "            # creating a blank color channel for combining\n",
    "            ignore_color = np.copy(gradx) * 0\n",
    "            self.diag1 = np.dstack((rEdgeDetect, gradx, grady))\n",
    "            self.diag2 = np.dstack((ignore_color, magch, dirch))\n",
    "            self.diag3 = np.dstack((sch, shadow, hch))\n",
    "            self.diag4 = np.dstack((combined, combined, combined)) * 4\n",
    "\n",
    "    # filter 5\n",
    "    # builds combination number 5\n",
    "    def applyFilter5(self):\n",
    "        # Run the functions\n",
    "        img = np.copy(self.curRoadRGB).astype(np.uint8)\n",
    "        gradx = self.abs_sobel_thresh(img, orient='x', thresh=(25, 100))\n",
    "        grady = self.abs_sobel_thresh(img, orient='y', thresh=(50, 150))\n",
    "        magch = self.mag_thresh(img, sobel_kernel=9, mag_thresh=(30, 150))\n",
    "        dirch = self.dir_threshold(img, sobel_kernel=15, thresh=(0.5, 1.3))\n",
    "        sch = self.hls_s(img, thresh=(20, 80))\n",
    "        hch = self.hls_h(img, thresh=(130, 175))\n",
    "\n",
    "        # create the Red filter\n",
    "        rEdgeDetect = img[:, :, 0] / 4\n",
    "        rEdgeDetect = 255 - rEdgeDetect\n",
    "        rEdgeDetect[(rEdgeDetect > 220)] = 0\n",
    "\n",
    "        # Output \"masked_lines\" is a single channel mask\n",
    "        shadow = np.zeros_like(dirch).astype(np.uint8)\n",
    "        shadow[(sch > 0) & (hch > 0)] = 128\n",
    "\n",
    "        # build the combination\n",
    "        combined = np.zeros_like(dirch).astype(np.uint8)\n",
    "        combined[(rEdgeDetect > 192) & (rEdgeDetect < 205) & (sch > 0)] = 35\n",
    "        self.curRoadEdge = combined\n",
    "\n",
    "        # build diag screen if in debug mode\n",
    "        if self.debug:\n",
    "            # create diagnostic screen 1-3\n",
    "            # creating a blank color channel for combining\n",
    "            ignore_color = np.copy(gradx) * 0\n",
    "            self.diag1 = np.dstack((rEdgeDetect, gradx, grady))\n",
    "            self.diag2 = np.dstack((ignore_color, magch, dirch))\n",
    "            self.diag3 = np.dstack((sch, shadow, hch))\n",
    "            self.diag4 = np.dstack((combined, combined, combined)) * 4\n",
    "\n",
    "    # set the edge projection image\n",
    "    def setEdgeProjection(self, projected):\n",
    "        # print(\"projected: \",projected.shape)\n",
    "        self.curRoadEdgeProjected = np.copy(projected)\n",
    "\n",
    "    # get the edge projection image\n",
    "    def getEdgeProjection(self):\n",
    "        return self.curRoadEdgeProjected\n",
    "\n",
    "    # set the full road projection image\n",
    "    def setRoadProjection(self, projected):\n",
    "        self.curRoadProjected = np.copy(projected)\n",
    "\n",
    "    # get the full road projection image\n",
    "    def getRoadProjection(self):\n",
    "        return self.curRoadProjected\n",
    "\n",
    "    # draw the discovered horizon in the image\n",
    "    def drawHorizon(self, image):\n",
    "        horizonLine = self.roadhorizon\n",
    "        image[horizonLine:(horizonLine + 1), :, 0] = 255\n",
    "        image[horizonLine:(horizonLine + 1), :, 1] = 255\n",
    "        image[horizonLine:(horizonLine + 1), :, 2] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection Management\n",
    "\n",
    "Projection Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ProjectionManager():\n",
    "\n",
    "    # Initialize projectionManager\n",
    "    def __init__(self, camCal, keepN=10, gradientLevel=75, debug=False):\n",
    "        # set debugging\n",
    "        self.debug = debug\n",
    "\n",
    "        # frameNumber\n",
    "        self.curFrame = None\n",
    "\n",
    "        # keep last N\n",
    "        self.keepN = keepN\n",
    "\n",
    "        # keep our own copy of the camera calibration\n",
    "        self.camCal = camCal\n",
    "\n",
    "        # our own copy of the camera calibration results\n",
    "        self.mtx, self.dist, self.img_size = camCal.get()\n",
    "\n",
    "        # normal image size\n",
    "        self.x, self.y = self.img_size\n",
    "        # based on hough3 (default)\n",
    "        self.z = self.y/45\n",
    "\n",
    "        # projection mask calculations\n",
    "        self.xbottom1 = int(self.x / 16)\n",
    "        self.xbottom2 = int(self.x * 15 / 16)\n",
    "        self.xtop1 = int(self.x * 14 / 32)\n",
    "        self.xtop2 = int(self.x * 18 / 32)\n",
    "        self.ybottom1 = self.y\n",
    "        self.ybottom2 = self.y\n",
    "        self.ytopbox = int(self.y * 9 / 16)\n",
    "\n",
    "        # mid point in picture (by height)\n",
    "        self.mid = int(self.y / 2)\n",
    "\n",
    "        # ghosting\n",
    "        self.roadGhost = np.zeros((self.mid, self.x), dtype=np.uint8)\n",
    "\n",
    "        # gradient level starts here\n",
    "        self.gradient0 = self.mid + gradientLevel\n",
    "\n",
    "        # current image Filter\n",
    "        self.curImgFtr = None\n",
    "\n",
    "        # current road corners\n",
    "        self.curSrcRoadCorners = None\n",
    "\n",
    "        # current horizon\n",
    "        self.curHorizon = None\n",
    "\n",
    "        # current gradient\n",
    "        self.curGradient = None\n",
    "\n",
    "        # last n projected image filters\n",
    "        self.recentProjected = []\n",
    "\n",
    "        # last n road corners\n",
    "        self.recentRoadCorners = []\n",
    "\n",
    "        # last n horizon detected\n",
    "        self.recentHorizon = []\n",
    "\n",
    "        # last n gradient detected\n",
    "        self.recentGradient = []\n",
    "\n",
    "        # for 3D reconstruction and augmentation\n",
    "        self.rvecs = None\n",
    "        self.tvecs = None\n",
    "        self.inliers = None\n",
    "\n",
    "        # our projection settings - FULLHD 1080p on its side.\n",
    "        self.projectedX = 1080\n",
    "        self.projectedY = 1920\n",
    "\n",
    "        # set up debugging diag screens\n",
    "        if self.debug:\n",
    "            self.diag1 = np.zeros((self.mid, self.x, 3), dtype=np.float32)\n",
    "            self.diag2 = np.zeros((self.y, self.x, 3), dtype=np.float32)\n",
    "            self.diag3 = np.zeros(\n",
    "                (self.projectedY, self.projectedX, 3), dtype=np.float32)\n",
    "            self.diag4 = np.zeros(\n",
    "                (self.projectedY, self.projectedX, 3), dtype=np.float32)\n",
    "\n",
    "    # set current image filter\n",
    "    def set_image_filter(self, imgFtr):\n",
    "        self.curImgFtr = imgFtr\n",
    "\n",
    "    # create a region of interest mask\n",
    "    def region_of_interest(self, img, vertices):\n",
    "        \"\"\"\n",
    "        Applies an image mask.\n",
    "        Only keeps the region of the image defined by the polygon\n",
    "        formed from `vertices`. The rest of the image is set to black.\n",
    "        \"\"\"\n",
    "        # defining a blank mask to start with\n",
    "        mask = np.zeros_like(img)\n",
    "\n",
    "        # defining a 3 channel or 1 channel color to fill the mask with\n",
    "        # depending on the input image\n",
    "        if len(img.shape) > 2:\n",
    "            channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "            ignore_mask_color = (255,) * channel_count\n",
    "        else:\n",
    "            ignore_mask_color = 255\n",
    "\n",
    "        # filling pixels inside the polygon defined by \"vertices\" with the fill\n",
    "        # color\n",
    "        cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "        # returning the image only where mask pixels are nonzero\n",
    "        masked_image = cv2.bitwise_and(img, mask)\n",
    "        return masked_image\n",
    "\n",
    "    # draw outline of given area\n",
    "    def draw_area_of_interest(self, img, areas,\n",
    "                              color=[128, 0, 128], thickness=2):\n",
    "        for points in areas:\n",
    "            for i in range(len(points) - 1):\n",
    "                cv2.line(img,\n",
    "                         (points[i][0],\n",
    "                          points[i][1]),\n",
    "                         (points[i + 1][0],\n",
    "                          points[i + 1][1]), color, thickness)\n",
    "            cv2.line(img,\n",
    "                     (points[0][0],\n",
    "                      points[0][1]),\n",
    "                     (points[len(points) - 1][0],\n",
    "                      points[len(points) - 1][1]), color, thickness)\n",
    "\n",
    "    # draw outline of given area\n",
    "    def draw_area_of_interest_for_projection(self, img, areas,\n",
    "                                             color=[128, 0, 128],\n",
    "                                             thickness1=2,\n",
    "                                             thickness2=10):\n",
    "        for points in areas:\n",
    "            for i in range(len(points) - 1):\n",
    "                if i == 0 or i == 1:\n",
    "                    cv2.line(img, (points[i][0], points[i][1]), (points[\n",
    "                             i + 1][0], points[i + 1][1]), color, thickness1)\n",
    "                else:\n",
    "                    cv2.line(img, (points[i][0], points[i][1]), (points[\n",
    "                             i + 1][0], points[i + 1][1]), color, thickness2)\n",
    "            cv2.line(img,\n",
    "                     (points[0][0],\n",
    "                      points[0][1]),\n",
    "                     (points[len(points) - 1][0],\n",
    "                      points[len(points) - 1][1]), color, thickness1)\n",
    "\n",
    "    def draw_masked_area(self, img, areas, color=[128, 0, 128], thickness=2):\n",
    "        for points in areas:\n",
    "            for i in range(len(points) - 1):\n",
    "                cv2.line(img,\n",
    "                         (points[i][0],\n",
    "                          points[i][1]),\n",
    "                         (points[i + 1][0],\n",
    "                          points[i + 1][1]), color, thickness)\n",
    "            cv2.line(img,\n",
    "                     (points[0][0],\n",
    "                      points[0][1]),\n",
    "                     (points[len(points) - 1][0],\n",
    "                      points[len(points) - 1][1]), color, thickness)\n",
    "\n",
    "    def draw_bounding_box(self, img, boundingbox,\n",
    "                          color=[0, 255, 0], thickness=6):\n",
    "        x1, y1, x2, y2 = boundingbox\n",
    "        cv2.line(img, (x1, y1), (x2, y1), color, thickness)\n",
    "        cv2.line(img, (x2, y1), (x2, y2), color, thickness)\n",
    "        cv2.line(img, (x2, y2), (x1, y2), color, thickness)\n",
    "        cv2.line(img, (x1, y2), (x1, y1), color, thickness)\n",
    "\n",
    "    # draw parallel lines in a perspective image that will later be projected\n",
    "    # into a flat surface\n",
    "    def draw_parallel_lines_pre_projection(self, img, lane_info,\n",
    "                                           color=[128, 0, 0], thickness=5):\n",
    "        lx1 = lane_info[3][0]\n",
    "        rx1 = lane_info[4][0]\n",
    "        rx2 = lane_info[5][0]\n",
    "        lx2 = lane_info[6][0]\n",
    "        ly1 = lane_info[3][1]\n",
    "        ry1 = lane_info[4][1]\n",
    "        ry2 = lane_info[5][1]\n",
    "        ly2 = lane_info[6][1]\n",
    "        cv2.line(img, (lx1, ly1), (lx2, ly2), color, thickness)\n",
    "        cv2.line(img, (rx1, ry1), (rx2, ry2), color, thickness)\n",
    "\n",
    "    def draw_estimated_lane_line_location(self, img, base_pos, distance,\n",
    "                                          color=[128, 0, 0], thickness=5):\n",
    "        x = int(base_pos + distance)\n",
    "        y1 = self.projectedY - 750\n",
    "        y2 = self.projectedY\n",
    "        cv2.line(img, (x, y1), (x, y2), color, thickness)\n",
    "\n",
    "    # calculate and draw initial estimated lines on the roadway.\n",
    "    def draw_lines(self, img, lines,\n",
    "                   color=[255, 0, 0], thickness=6, backoff=0, debug=False):\n",
    "        if backoff == 0:\n",
    "            backoff = thickness * 2\n",
    "            # backoff=thickness*5\n",
    "        ysize = img.shape[0]\n",
    "        midleft = img.shape[1] / 2 - 200 + backoff * 2\n",
    "        midright = img.shape[1] / 2 + 200 - backoff * 2\n",
    "        top = ysize / 2 + backoff * 2\n",
    "        rightslopemin = 0.5  # 8/backoff\n",
    "        rightslopemax = 3.0  # backoff/30\n",
    "        leftslopemax = -0.5  # -8/backoff\n",
    "        leftslopemin = -3.0  # -backoff/30\n",
    "        try:\n",
    "            # rightline and leftline cumlators\n",
    "            rl = {'num': 0, 'slope': 0.0, 'x1': 0, 'y1': 0, 'x2': 0, 'y2': 0}\n",
    "            ll = {'num': 0, 'slope': 0.0, 'x1': 0, 'y1': 0, 'x2': 0, 'y2': 0}\n",
    "            for line in lines:\n",
    "                for x1, y1, x2, y2 in line:\n",
    "                    slope = ((y2 - y1) / (x2 - x1))\n",
    "                    sides = (x1 + x2) / 2\n",
    "                    vmid = (y1 + y2) / 2\n",
    "                    if (slope > rightslopemin and slope < rightslopemax and\n",
    "                            sides > midright and vmid > top):   # right\n",
    "                        if debug:\n",
    "                            # print(\"x1,y1,x2,y2: \", x1, y1, x2, y2)\n",
    "                            cv2.line(img, (x1, y1), (x2, y2),\n",
    "                                     [128, 128, 0], thickness)\n",
    "                        rl['num'] += 1\n",
    "                        rl['slope'] += slope\n",
    "                        rl['x1'] += x1\n",
    "                        rl['y1'] += y1\n",
    "                        rl['x2'] += x2\n",
    "                        rl['y2'] += y2\n",
    "                    elif (slope > leftslopemin and slope < leftslopemax and\n",
    "                          sides < midleft and vmid > top):   # left\n",
    "                        if debug:\n",
    "                            # print(\"x1,y1,x2,y2: \", x1, y1, x2, y2)\n",
    "                            cv2.line(img, (x1, y1), (x2, y2),\n",
    "                                     [128, 128, 0], thickness)\n",
    "                        ll['num'] += 1\n",
    "                        ll['slope'] += slope\n",
    "                        ll['x1'] += x1\n",
    "                        ll['y1'] += y1\n",
    "                        ll['x2'] += x2\n",
    "                        ll['y2'] += y2\n",
    "\n",
    "            if rl['num'] > 0 and ll['num'] > 0:\n",
    "                # average/extrapolate all of the lines that makes the right\n",
    "                # line\n",
    "                rslope = rl['slope'] / rl['num']\n",
    "                rx1 = int(rl['x1'] / rl['num'])\n",
    "                ry1 = int(rl['y1'] / rl['num'])\n",
    "                rx2 = int(rl['x2'] / rl['num'])\n",
    "                ry2 = int(rl['y2'] / rl['num'])\n",
    "\n",
    "                # average/extrapolate all of the lines that makes the left line\n",
    "                lslope = ll['slope'] / ll['num']\n",
    "                lx1 = int(ll['x1'] / ll['num'])\n",
    "                ly1 = int(ll['y1'] / ll['num'])\n",
    "                lx2 = int(ll['x2'] / ll['num'])\n",
    "                ly2 = int(ll['y2'] / ll['num'])\n",
    "\n",
    "                # find the right and left line's intercept, which means solving\n",
    "                # the following two equations:\n",
    "                #\n",
    "                # rslope = ( yi - ry1 )/( xi - rx1)\n",
    "                # lslope = ( yi = ly1 )/( xi - lx1)\n",
    "                # solve for (xi, yi): the intercept of the left and right lines\n",
    "                # which is:\n",
    "                #   xi = (ly2 - ry2 + rslope*rx2 - lslope*lx2)/(rslope-lslope)\n",
    "                # and\n",
    "                #   yi = ry2 + rslope*(xi-rx2)\n",
    "                xi = int((ly2 - ry2 + rslope * rx2 -\n",
    "                          lslope * lx2) / (rslope - lslope))\n",
    "                yi = int(ry2 + rslope * (xi - rx2))\n",
    "\n",
    "                # calculate backoff from intercept for right line\n",
    "                if (rslope > rightslopemin and\n",
    "                        rslope < rightslopemax):   # right\n",
    "                    ry1 = yi + int(backoff)\n",
    "                    rx1 = int(rx2 - (ry2 - ry1) / rslope)\n",
    "                    ry2 = ysize - 1\n",
    "                    rx2 = int(rx1 + (ry2 - ry1) / rslope)\n",
    "                    cv2.line(img, (rx1, ry1), (rx2, ry2),\n",
    "                             [255, 0, 0], thickness)\n",
    "\n",
    "                # calculate backoff from intercept for left line\n",
    "                if (lslope < leftslopemax and\n",
    "                        lslope > leftslopemin):   # left\n",
    "                    ly1 = yi + int(backoff)\n",
    "                    lx1 = int(lx2 - (ly2 - ly1) / lslope)\n",
    "                    ly2 = ysize - 1\n",
    "                    lx2 = int(lx1 + (ly2 - ly1) / lslope)\n",
    "                    cv2.line(img, (lx1, ly1), (lx2, ly2),\n",
    "                             [255, 0, 0], thickness)\n",
    "\n",
    "                # if we have all of the points - draw the backoff line near the\n",
    "                # horizon\n",
    "                if lx1 > 0 and ly1 > 0 and rx1 > 0 and ry1 > 0:\n",
    "                    cv2.line(img, (lx1, ly1), (rx1, ry1),\n",
    "                             [255, 0, 0], thickness)\n",
    "\n",
    "            # return the left and right line slope, found rectangler box shape\n",
    "            # and the estimated vanishing point.\n",
    "            return lslope + rslope, lslope, rslope, \\\n",
    "                (lx1, ly1), (rx1, ry1), (rx2, ry2), (lx2, ly2), (xi, yi)\n",
    "        except:\n",
    "            return -1000, 0.0, 0.0, (0, 0), (0, 0), (0, 0), (0, 0)\n",
    "\n",
    "    # generate a set of hough lines and calculates its estimates for lane lines\n",
    "    def hough_lines(self, img, rho, theta, threshold,\n",
    "                    min_line_len, max_line_gap, backoff=0, debug=False):\n",
    "        \"\"\"\n",
    "        `img` should be the output of a Canny transform.\n",
    "        Returns an image with hough lines drawn using the new single line\n",
    "            for left and right lane line method.\n",
    "        \"\"\"\n",
    "        lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array(\n",
    "            []), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "        masked_lines = np.zeros(img.shape, dtype=np.uint8)\n",
    "        lane_info = self.draw_lines(\n",
    "            masked_lines, lines, backoff=backoff, debug=debug)\n",
    "\n",
    "        return masked_lines, lane_info\n",
    "\n",
    "    # function to project the undistorted camera image to a plane looking down.\n",
    "    def unwarp_lane(self, img, src, dst, mtx):\n",
    "        # Pass in your image, 4 source points:\n",
    "        #     src = np.float32([[,],[,],[,],[,]])\n",
    "        # and 4 destination points:\n",
    "        #     dst = np.float32([[,],[,],[,],[,]])\n",
    "        # Note: you could pick any four of the detected corners\n",
    "        # as long as those four corners define a rectangle\n",
    "        # One especially smart way to do this would be to use four well-chosen\n",
    "        # use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "        # use cv2.warpPerspective() to warp your image to a top-down view\n",
    "\n",
    "        self.src2dstM = cv2.getPerspectiveTransform(src, dst)\n",
    "        self.dst2srcM = cv2.getPerspectiveTransform(dst, src)\n",
    "        img_size = (self.projectedX, self.projectedY)\n",
    "        warped = cv2.warpPerspective(\n",
    "            img, self.src2dstM, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "        # warped = gray\n",
    "        return warped, self.src2dstM\n",
    "\n",
    "    # function to project the undistorted camera image to a plane looking down.\n",
    "    def unwarp_lane_back(self, img, src, dst, mtx):\n",
    "        # Pass in your image, 4 source points:\n",
    "        #     src = np.float32([[,],[,],[,],[,]])\n",
    "        # and 4 destination points:\n",
    "        #     dst = np.float32([[,],[,],[,],[,]])\n",
    "        # Note: you could pick any four of the detected corners\n",
    "        # as long as those four corners define a rectangle\n",
    "        # One especially smart way to do this would be to use four well-chosen\n",
    "        # use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "        # use cv2.warpPerspective() to warp your image to a top-down view\n",
    "\n",
    "        img_size = (self.x, self.y)\n",
    "        warped = cv2.warpPerspective(\n",
    "            img, self.dst2srcM, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "        # warped = gray\n",
    "        return warped, self.dst2srcM\n",
    "\n",
    "    # function to find starting lane line positions\n",
    "    # return left and right column positions\n",
    "    def find_lane_locations(self, masked_lines):\n",
    "        height = masked_lines.shape[0]\n",
    "        width = masked_lines.shape[1]\n",
    "        lefthistogram = np.sum(\n",
    "            masked_lines[int(height / 2):height, 0:int(width / 2)],\n",
    "            axis=0).astype(np.float32)\n",
    "        righthistogram = np.sum(\n",
    "            masked_lines[int(height / 2):height, int(width / 2):width],\n",
    "            axis=0).astype(np.float32)\n",
    "        leftpos = np.argmax(lefthistogram)\n",
    "        rightpos = np.argmax(righthistogram) + int(width / 2)\n",
    "        # print(\"leftpos\",leftpos,\"rightpos\",rightpos)\n",
    "        return leftpos, rightpos, rightpos - leftpos\n",
    "\n",
    "    # hough version1\n",
    "    def hough_lines1(self, masked_edges, debug=False):\n",
    "        # Define the Hough transform parameters\n",
    "        # Make a blank the same size as our image to draw on\n",
    "        rho = 2  # distance resolution in pixels of the Hough grid\n",
    "        theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "        # minimum number of votes (intersections in Hough grid cell)\n",
    "        threshold = 40\n",
    "        # 50 75 25 minimum number of pixels making up a line\n",
    "        min_line_length = 120\n",
    "        # 40 50 20 maximum gap in pixels between connectable line segments\n",
    "        max_line_gap = 40\n",
    "        return self.hough_lines(masked_edges, rho, theta, threshold,\n",
    "                                min_line_length, max_line_gap,\n",
    "                                backoff=30, debug=debug)\n",
    "\n",
    "    # hough version2\n",
    "    def hough_lines2(self, masked_edges, debug=False):\n",
    "        # Define the Hough transform parameters\n",
    "        # Make a blank the same size as our image to draw on\n",
    "        rho = 2  # distance resolution in pixels of the Hough grid\n",
    "        theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "        # minimum number of votes (intersections in Hough grid cell)\n",
    "        threshold = 40\n",
    "        # 50 75 25 minimum number of pixels making up a line\n",
    "        min_line_length = 100\n",
    "        # 40 50 20 maximum gap in pixels between connectable line segments\n",
    "        max_line_gap = 40\n",
    "        return self.hough_lines(masked_edges, rho, theta, threshold,\n",
    "                                min_line_length, max_line_gap,\n",
    "                                backoff=40, debug=debug)\n",
    "\n",
    "    # hough version3\n",
    "    def hough_lines3(self, masked_edges, debug=False):\n",
    "        # Define the Hough transform parameters\n",
    "        # Make a blank the same size as our image to draw on\n",
    "        rho = 2  # distance resolution in pixels of the Hough grid\n",
    "        theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "        # minimum number of votes (intersections in Hough grid cell)\n",
    "        threshold = 40\n",
    "        # 50 75 25 minimum number of pixels making up a line\n",
    "        min_line_length = 75\n",
    "        # 40 50 20 maximum gap in pixels between connectable line segments\n",
    "        max_line_gap = 40\n",
    "        return self.hough_lines(masked_edges, rho, theta, threshold,\n",
    "                                min_line_length, max_line_gap,\n",
    "                                backoff=40, debug=debug)\n",
    "\n",
    "    # hough version4\n",
    "    def hough_lines4(self, masked_edges, debug=False):\n",
    "        # Define the Hough transform parameters\n",
    "        # Make a blank the same size as our image to draw on\n",
    "        rho = 2  # distance resolution in pixels of the Hough grid\n",
    "        theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "        # minimum number of votes (intersections in Hough grid cell)\n",
    "        threshold = 40\n",
    "        # 50 75 25 minimum number of pixels making up a line\n",
    "        min_line_length = 50\n",
    "        # 40 50 20 maximum gap in pixels between connectable line segments\n",
    "        max_line_gap = 30\n",
    "        return self.hough_lines(masked_edges, rho, theta, threshold,\n",
    "                                min_line_length, max_line_gap,\n",
    "                                backoff=50, debug=debug)\n",
    "\n",
    "    # hough version5\n",
    "    def hough_lines5(self, masked_edges, debug=False):\n",
    "        # Define the Hough transform parameters\n",
    "        # Make a blank the same size as our image to draw on\n",
    "        rho = 2  # distance resolution in pixels of the Hough grid\n",
    "        theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "        # minimum number of votes (intersections in Hough grid cell)\n",
    "        threshold = 40\n",
    "        # 50 75 25 minimum number of pixels making up a line\n",
    "        min_line_length = 20\n",
    "        # 40 50 20 maximum gap in pixels between connectable line segments\n",
    "        max_line_gap = 20\n",
    "        return self.hough_lines(masked_edges, rho, theta, threshold,\n",
    "                                min_line_length, max_line_gap,\n",
    "                                backoff=50, debug=debug)\n",
    "\n",
    "    # function to find initial road corners to find a projection matrix.\n",
    "    # once corners are found, project the edges into a plane\n",
    "    # or when we fall below 50% confidence in the lane line detected.\n",
    "    def findInitialRoadCorners(self, imgftr):\n",
    "        # first time?\n",
    "        if self.curFrame is None:\n",
    "            self.curFrame = 0\n",
    "        else:\n",
    "            self.curFrame += 1\n",
    "\n",
    "        # piece together images that we want to project\n",
    "        edge = imgftr.edges()[:, :, 0]\n",
    "\n",
    "        # We are defining a four sided polygon to mask\n",
    "        vertices = np.array([[(self.xbottom1, self.ybottom1),\n",
    "                              (self.xtop1, self.ytopbox),\n",
    "                              (self.xtop2, self.ytopbox),\n",
    "                              (self.xbottom2, self.ybottom2)]], dtype=np.int32)\n",
    "\n",
    "        # now mask it\n",
    "        masked_edge = self.region_of_interest(np.copy(edge), vertices)\n",
    "        masked_edges = np.dstack((edge, masked_edge, masked_edge))\n",
    "\n",
    "        # cascading hough mapping line attempts\n",
    "        self.hough = 1\n",
    "        line_image, lane_info = self.hough_lines1(masked_edge)\n",
    "        if lane_info[0] == -1000:\n",
    "            self.hough = 2\n",
    "            line_image, lane_info = self.hough_lines2(masked_edge)\n",
    "            if lane_info[0] == -1000:\n",
    "                self.hough = 3\n",
    "                line_image, lane_info = self.hough_lines3(masked_edge)\n",
    "                if lane_info[0] == -1000:\n",
    "                    self.hough = 4\n",
    "                    line_image, lane_info = self.hough_lines4(masked_edge)\n",
    "                    if lane_info[0] == -1000:\n",
    "                        self.hough = 5\n",
    "                        line_image, lane_info = self.hough_lines5(masked_edge)\n",
    "\n",
    "        # if we made it: calculate the area of interest\n",
    "        if lane_info[0] > -1000:\n",
    "            self.curGradient = lane_info[3][1]\n",
    "\n",
    "            areaOfInterest = np.array([[(lane_info[3][0] - 50,\n",
    "                                         lane_info[3][1] - 11),\n",
    "                                        (lane_info[4][0] + 50,\n",
    "                                         lane_info[4][1] - 11),\n",
    "                                        (lane_info[4][0] + 525,\n",
    "                                         lane_info[4][1] + 75),\n",
    "                                        (lane_info[4][0] +\n",
    "                                         500, lane_info[5][1]),\n",
    "                                        (lane_info[4][0] -\n",
    "                                         500, lane_info[6][1]),\n",
    "                                        (lane_info[3][0] - 525,\n",
    "                                         lane_info[3][1] + 75)]],\n",
    "                                      dtype=np.int32)\n",
    "\n",
    "            # generate src rect for projection of road to flat plane\n",
    "            self.curSrcRoadCorners = np.float32(\n",
    "                [lane_info[3], lane_info[4], lane_info[5], lane_info[6]])\n",
    "\n",
    "            # generate destination rect for projection of road to flat plane\n",
    "            us_lane_width = 12     # US highway width: 12 feet wide\n",
    "            if self.hough == 1:\n",
    "                # slight curvy road - poor visibility (challenge)\n",
    "                # 30.0 Approximate distance to vanishing point\n",
    "                # from end of rectangle\n",
    "                approx_dest = 30.0\n",
    "                self.z = self.y/40\n",
    "            elif self.hough == 2:\n",
    "                # road is almost straight - high visibility\n",
    "                # 42.0 Approximate distance to vanishing point\n",
    "                # from end of rectangle\n",
    "                approx_dest = 42.0\n",
    "                self.z = self.y/55\n",
    "            elif self.hough == 3:\n",
    "                # slightly more curvy road - normal visibility\n",
    "                # 36.0 # 35.56 Approximate distance to vanishing point from\n",
    "                # end of rectangle\n",
    "                approx_dest = 36.0\n",
    "                self.z = self.y/45\n",
    "            elif self.hough == 4:\n",
    "                # curvy road - lower visibility\n",
    "                # 25.0 Approximate distance to vanishing point\n",
    "                # from end of rectangle\n",
    "                approx_dest = 25.0\n",
    "                self.z = self.y/35\n",
    "            else:\n",
    "                # very curvy road - very low visibility (harder challenge)\n",
    "                # 20.0 Approximate distance to vanishing point\n",
    "                # from end of rectangle\n",
    "                approx_dest = 15.0\n",
    "                self.z = self.y/20\n",
    "\n",
    "            scale_factor = 6.0     # scaling for display\n",
    "            top = approx_dest * approx_dest\n",
    "            left = -(us_lane_width / 2) * scale_factor\n",
    "            right = (us_lane_width / 2) * scale_factor\n",
    "            self.curDstRoadCorners = np.float32(\n",
    "                [[(self.projectedX / 2) + left, top],\n",
    "                 [(self.projectedX / 2) + right, top],\n",
    "                 [(self.projectedX / 2) + right,\n",
    "                  self.projectedY],\n",
    "                 [(self.projectedX / 2) + left,\n",
    "                  self.projectedY]])\n",
    "\n",
    "            # create 3D dst road corners\n",
    "            self.cur3DDstRoadCorners = np.zeros((4, 3), np.float32)\n",
    "            self.cur3DDstRoadCorners[:, :2] = self.curDstRoadCorners\n",
    "\n",
    "            # generate grayscaled map image for projection\n",
    "            projected_roadsurface, M = self.unwarp_lane(\n",
    "                np.copy(masked_edges), self.curSrcRoadCorners,\n",
    "                self.curDstRoadCorners, self.mtx)\n",
    "            imgftr.setEdgeProjection(projected_roadsurface)\n",
    "\n",
    "            # generate full color projection\n",
    "            projected, M = self.unwarp_lane(\n",
    "                imgftr.curImage, self.curSrcRoadCorners,\n",
    "                self.curDstRoadCorners, self.mtx)\n",
    "            imgftr.setRoadProjection(projected)\n",
    "\n",
    "            # save current source projection rect.\n",
    "            self.lane_info = lane_info\n",
    "\n",
    "            # calculate the rotation and translation vectors for augmentation\n",
    "            # ret, self.rvecs, self.tvecs, inliners = cv2.solvePnPRansac(\n",
    "            #     self.cur3DDstRoadCorners.reshape([4,1,3]),\n",
    "            #     self.curSrcRoadCorners.reshape([4,1,2]),\n",
    "            #     self.mtx, self.dist, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "            # ret, self.rvecs, self.tvecs = cv2.solvePnP(\n",
    "            #     self.cur3DDstRoadCorners.reshape([4,1,3]),\n",
    "            #     self.curSrcRoadCorners.reshape([4,1,2]),\n",
    "            #     self.mtx, self.dist, self.rvecs, self.tvecs,\n",
    "            #     useExtrinsicGuess=True, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "            ret, self.rvecs, self.tvecs = cv2.solvePnP(\n",
    "                self.cur3DDstRoadCorners.reshape([4, 1, 3]),\n",
    "                self.curSrcRoadCorners.reshape([4, 1, 2]),\n",
    "                self.mtx, self.dist, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "        # create debug/diag screens if required\n",
    "        if self.debug:\n",
    "            # diag 1 screen - road edges with masked out area shown\n",
    "            self.diag1 = imgftr.makehalf(masked_edges) * 4\n",
    "\n",
    "            # rest is only valid if we are able to get lane_info...\n",
    "            if lane_info[0] > -1000:\n",
    "                leftbound = int(lane_info[7][0] - (self.x * 0.1))\n",
    "                rightbound = int(lane_info[7][0] + (self.x * 0.1))\n",
    "                topbound = int(lane_info[7][1] - (self.y * 0.15))\n",
    "                bottombound = int(lane_info[7][1] + (self.y * 0.05))\n",
    "                boundingbox = (leftbound - 2, topbound - 2,\n",
    "                               rightbound + 2, bottombound + 2)\n",
    "\n",
    "                # non-projected image with found points\n",
    "                ignore = np.copy(line_image) * 0\n",
    "                self.diag2 = imgftr.miximg(imgftr.curImage, masked_edges * 2)\n",
    "                self.diag2 = imgftr.miximg(\n",
    "                    self.diag2, np.dstack((line_image, ignore, ignore)))\n",
    "                if imgftr.visibility > -30:\n",
    "                    self.draw_masked_area(self.diag2, vertices)\n",
    "                # self.draw_bounding_box(self.diag2, boundingbox)\n",
    "                font = cv2.FONT_HERSHEY_COMPLEX\n",
    "                cv2.putText(self.diag2, 'Frame: %d   Hough: %d' % (\n",
    "                    self.curFrame, self.hough),\n",
    "                    (30, 30), font, 1, (255, 0, 0), 2)\n",
    "                self.draw_area_of_interest(self.diag2, areaOfInterest, color=[\n",
    "                                           0, 128, 0], thickness=5)\n",
    "\n",
    "                cv2.putText(\n",
    "                    self.diag2, 'x1,y1: %d,%d' %\n",
    "                    (int(lane_info[3][0]), int(lane_info[3][1])),\n",
    "                    (int(lane_info[3][0]) - 250, int(lane_info[3][1]) - 30),\n",
    "                    font, 1, (255, 0, 0), 2)\n",
    "                cv2.putText(\n",
    "                    self.diag2, 'x2,y2: %d,%d' %\n",
    "                    (int(lane_info[4][0]), int(lane_info[4][1])),\n",
    "                    (int(lane_info[4][0]), int(lane_info[4][1]) - 30),\n",
    "                    font, 1, (255, 0, 0), 2)\n",
    "                cv2.putText(\n",
    "                    self.diag2, 'x3,y3: %d,%d' %\n",
    "                    (int(lane_info[5][0]), int(lane_info[5][1])),\n",
    "                    (int(lane_info[5][0]) - 200, int(lane_info[5][1]) - 30),\n",
    "                    font, 1, (255, 0, 0), 2)\n",
    "                cv2.putText(\n",
    "                    self.diag2, 'x4,y4: %d,%d' %\n",
    "                    (int(lane_info[6][0]), int(lane_info[6][1])),\n",
    "                    (int(lane_info[6][0]) - 200, int(lane_info[6][1]) - 30),\n",
    "                    font, 1, (255, 0, 0), 2)\n",
    "\n",
    "                # diag 3 screen - complete road RGB image projected\n",
    "                # new_edge = np.copy(edge)\n",
    "                # new_edge[masked_edge>0] = 0\n",
    "                # diag3tmp = np.dstack((new_edge, new_edge, new_edge)) * 4\n",
    "                # diag3tmp = imgftr.miximg(imgftr.curImage, masked_edges*4)\n",
    "                # self.draw_area_of_interest_for_projection(diag3tmp,\n",
    "                #     areaOfInterest, color=[0,128,0],\n",
    "                #     thickness1=1, thickness2=50)\n",
    "                # self.draw_parallel_lines_pre_projection(diag3tmp,\n",
    "                #     lane_info, color=[128,0,0], thickness=2)\n",
    "                self.diag3 = np.copy(projected)\n",
    "\n",
    "                # diag 4 screen - road edges with masked out area shown\n",
    "                # projected\n",
    "                self.diag4, M = self.unwarp_lane(\n",
    "                    imgftr.makefull(self.diag1),\n",
    "                    self.curSrcRoadCorners,\n",
    "                    self.curDstRoadCorners, self.mtx)\n",
    "                cv2.putText(\n",
    "                    self.diag4, 'x1,y1: %d,%d' %\n",
    "                    (int(self.curDstRoadCorners[0][0]),\n",
    "                     int(self.curDstRoadCorners[0][1]) - 1),\n",
    "                    (int(self.curDstRoadCorners[0][0]) - 275,\n",
    "                     int(self.curDstRoadCorners[0][1]) - 15),\n",
    "                    font, 1, (255, 0, 0), 2)\n",
    "                cv2.putText(\n",
    "                    self.diag4, 'x2,y2: %d,%d' %\n",
    "                    (int(self.curDstRoadCorners[1][0]),\n",
    "                     int(self.curDstRoadCorners[1][1]) - 1),\n",
    "                    (int(self.curDstRoadCorners[1][0]) + 25,\n",
    "                     int(self.curDstRoadCorners[1][1]) - 15),\n",
    "                    font, 1, (255, 0, 0), 2)\n",
    "                cv2.putText(\n",
    "                    self.diag4, 'x3,y3: %d,%d' %\n",
    "                    (int(self.curDstRoadCorners[2][0]),\n",
    "                     int(self.curDstRoadCorners[2][1]) - 1),\n",
    "                    (int(self.curDstRoadCorners[2][0]) + 25,\n",
    "                     int(self.curDstRoadCorners[2][1]) - 15),\n",
    "                    font, 1, (255, 0, 0), 2)\n",
    "                cv2.putText(\n",
    "                    self.diag4, 'x4,y4: %d,%d' %\n",
    "                    (int(self.curDstRoadCorners[3][0]),\n",
    "                     int(self.curDstRoadCorners[3][1]) - 1),\n",
    "                    (int(self.curDstRoadCorners[3][0]) - 275,\n",
    "                     int(self.curDstRoadCorners[3][1]) - 15),\n",
    "                    font, 1, (255, 0, 0), 2)\n",
    "\n",
    "                # draw circles of destination points\n",
    "                cv2.circle(\n",
    "                    self.diag4,\n",
    "                    (int(self.curDstRoadCorners[0][0]),\n",
    "                     int(self.curDstRoadCorners[0][1])),\n",
    "                    10, (255, 64, 64), 10)\n",
    "                cv2.circle(\n",
    "                    self.diag4,\n",
    "                    (int(self.curDstRoadCorners[1][0]),\n",
    "                     int(self.curDstRoadCorners[1][1])),\n",
    "                    10, (255, 64, 64), 10)\n",
    "                cv2.circle(\n",
    "                    self.diag4,\n",
    "                    (int(self.curDstRoadCorners[2][0]),\n",
    "                     int(self.curDstRoadCorners[2][1])),\n",
    "                    10, (255, 64, 64), 10)\n",
    "                cv2.circle(\n",
    "                    self.diag4,\n",
    "                    (int(self.curDstRoadCorners[3][0]),\n",
    "                     int(self.curDstRoadCorners[3][1])),\n",
    "                    10, (255, 64, 64), 10)\n",
    "\n",
    "    # function to project the edges into a plane\n",
    "    # this function is for when we are now at greater than 50% confidence in\n",
    "    # the lane lines identified.\n",
    "    def project(self, imgftr, leftRightOffset=0, sameFrame=False):\n",
    "        if not sameFrame:\n",
    "            self.curFrame += 1\n",
    "\n",
    "        lane_info = self.lane_info\n",
    "\n",
    "        # piece together images that we want to project\n",
    "        edge = imgftr.edges()[:, :, 0]\n",
    "\n",
    "        # We are defining a four sided polygon to mask\n",
    "        vertices = np.array([[(self.xbottom1, self.ybottom1),\n",
    "                              (self.xtop1, self.ytopbox),\n",
    "                              (self.xtop2, self.ytopbox),\n",
    "                              (self.xbottom2, self.ybottom2)]],\n",
    "                            dtype=np.int32)\n",
    "\n",
    "        # now mask it\n",
    "        masked_edge = self.region_of_interest(np.copy(edge), vertices)\n",
    "        masked_edges = np.dstack((edge, masked_edge, masked_edge))\n",
    "\n",
    "        # calculate the area of interest\n",
    "        self.curGradient = lane_info[3][1]\n",
    "        areaOfInterest = np.array(\n",
    "            [[(lane_info[3][0] - 50 + leftRightOffset,\n",
    "               lane_info[3][1] - 11),\n",
    "              (lane_info[4][0] + 50 + leftRightOffset,\n",
    "               lane_info[4][1] - 11),\n",
    "              (lane_info[4][0] + 525,\n",
    "               lane_info[4][1] + 75),\n",
    "              (lane_info[4][0] + 500, lane_info[5][1]),\n",
    "              (lane_info[4][0] - 500, lane_info[6][1]),\n",
    "              (lane_info[3][0] - 525, lane_info[3][1] + 75)]], dtype=np.int32)\n",
    "\n",
    "        # generate src rect for projection of road to flat plane\n",
    "        # since this is a fast version of the projector in general\n",
    "        # we will use the last projection information what we obtained\n",
    "        # from the last search; however, roadmanager can reset this based\n",
    "        # on gap thresholds with the last detected horizon.\n",
    "        # see setSrcTop() function below.\n",
    "        self.curSrcRoadCorners = np.float32(\n",
    "            [lane_info[3], lane_info[4], lane_info[5], lane_info[6]])\n",
    "\n",
    "        # generate grayscaled map image\n",
    "        projected_roadsurface, M = self.unwarp_lane(\n",
    "            np.copy(masked_edges), self.curSrcRoadCorners,\n",
    "            self.curDstRoadCorners, self.mtx)\n",
    "        imgftr.setEdgeProjection(projected_roadsurface)\n",
    "\n",
    "        # generate full color projection\n",
    "        projected, M = self.unwarp_lane(\n",
    "            imgftr.curImage, self.curSrcRoadCorners,\n",
    "            self.curDstRoadCorners, self.mtx)\n",
    "        imgftr.setRoadProjection(projected)\n",
    "\n",
    "        # re-calculate the rotation and translation vectors for augmentation\n",
    "        # ret, self.rvecs, self.tvecs, inliners = cv2.solvePnPRansac(\n",
    "        #     self.cur3DDstRoadCorners.reshape([4,1,3]),\n",
    "        #     self.curSrcRoadCorners.reshape([4,1,2]),\n",
    "        #     self.mtx, self.dist, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "        # ret, self.rvecs, self.tvecs = cv2.solvePnP(\n",
    "        #     self.cur3DDstRoadCorners.reshape([4,1,3]),\n",
    "        #     self.curSrcRoadCorners.reshape([4,1,2]),\n",
    "        #     self.mtx, self.dist, self.rvecs, self.tvecs,\n",
    "        #     useExtrinsicGuess=True, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "        ret, self.rvecs, self.tvecs = cv2.solvePnP(\n",
    "            self.cur3DDstRoadCorners.reshape([4, 1, 3]),\n",
    "            self.curSrcRoadCorners.reshape([4, 1, 2]),\n",
    "            self.mtx, self.dist, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "        # create debug/diag screens if required\n",
    "        if self.debug:\n",
    "            # diag 1 screen - road edges with masked out area shown\n",
    "            self.diag1 = imgftr.makehalf(masked_edges) * 4\n",
    "\n",
    "            # rest is only valid if we are able to get lane_info...\n",
    "            if lane_info[0] > -1000:\n",
    "                leftbound = int(lane_info[3][0] - 50 + leftRightOffset)\n",
    "                rightbound = int(lane_info[4][0] + 50 + leftRightOffset)\n",
    "                topbound = int(lane_info[3][1] - 71)\n",
    "                bottombound = int(lane_info[3][1] - 11)\n",
    "                boundingbox = (leftbound - 2, topbound - 2,\n",
    "                               rightbound + 2, bottombound + 2)\n",
    "\n",
    "                # non-projected image with found points\n",
    "                self.diag2 = imgftr.miximg(imgftr.curImage, masked_edges * 2)\n",
    "                if imgftr.visibility > -30:\n",
    "                    self.draw_masked_area(self.diag2, vertices)\n",
    "                # self.draw_bounding_box(self.diag2, boundingbox)\n",
    "                font = cv2.FONT_HERSHEY_COMPLEX\n",
    "                cv2.putText(\n",
    "                    self.diag2, 'Frame: %d   Hough: %d' %\n",
    "                    (self.curFrame, self.hough),\n",
    "                    (30, 30), font, 1, (255, 0, 0), 2)\n",
    "                self.draw_area_of_interest(self.diag2, areaOfInterest, color=[\n",
    "                                           0, 128, 0], thickness=5)\n",
    "\n",
    "                # diag 3 screen - complete road RGB image projected\n",
    "                diag3tmp = imgftr.miximg(imgftr.curImage, masked_edges * 4)\n",
    "                self.draw_area_of_interest_for_projection(\n",
    "                    diag3tmp, areaOfInterest, color=[0, 128, 0],\n",
    "                    thickness1=1, thickness2=50)\n",
    "                self.draw_parallel_lines_pre_projection(\n",
    "                    diag3tmp, lane_info, color=[128, 0, 0], thickness=2)\n",
    "                self.diag3, M = self.unwarp_lane(\n",
    "                    diag3tmp, self.curSrcRoadCorners,\n",
    "                    self.curDstRoadCorners, self.mtx)\n",
    "\n",
    "                # diag 4 screen - road edges with masked out area shown\n",
    "                # projected\n",
    "                self.diag4, M = self.unwarp_lane(\n",
    "                    imgftr.makefull(self.diag1),\n",
    "                    self.curSrcRoadCorners,\n",
    "                    self.curDstRoadCorners, self.mtx)\n",
    "\n",
    "    # warp the perspective view to planar view\n",
    "    def curWarp(self, imgftr, image):\n",
    "        warped, M = self.unwarp_lane(\n",
    "            image, self.curSrcRoadCorners, self.curDstRoadCorners, self.mtx)\n",
    "        return warped\n",
    "\n",
    "    # unwarp the planar view back to perspective view\n",
    "    def curUnWarp(self, imgftr, image):\n",
    "        unwarped, M = self.unwarp_lane_back(\n",
    "            image, self.curDstRoadCorners, self.curSrcRoadCorners, self.mtx)\n",
    "        return unwarped\n",
    "\n",
    "    # an attempt to dampen the bounce of the car and the road surface.\n",
    "    # called by RoadManager class\n",
    "    def setSrcTop(self, newTop, sideDelta):\n",
    "        if newTop > self.gradient0:\n",
    "            self.ytopbox = newTop - 15\n",
    "            self.xtop1 += sideDelta\n",
    "            self.xtop2 -= sideDelta\n",
    "            self.lane_info = (self.lane_info[0],\n",
    "                              self.lane_info[1],\n",
    "                              self.lane_info[2],\n",
    "                              (self.lane_info[3][0] + sideDelta, newTop),\n",
    "                              (self.lane_info[4][0] - sideDelta, newTop),\n",
    "                              self.lane_info[5],\n",
    "                              self.lane_info[6],\n",
    "                              self.lane_info[7])\n",
    "\n",
    "    # another attempt to dampen the bounce of the car and the road surface.\n",
    "    def setSrcTopX(self, sideDelta):\n",
    "        self.lane_info = (self.lane_info[0],\n",
    "                          self.lane_info[1],\n",
    "                          self.lane_info[2],\n",
    "                          (self.xtop1 + sideDelta, self.lane_info[3][1]),\n",
    "                          (self.xtop2 + sideDelta, self.lane_info[4][1]),\n",
    "                          self.lane_info[5],\n",
    "                          self.lane_info[6],\n",
    "                          (self.lane_info[7][0] + sideDelta,\n",
    "                           self.lane_info[7][1]))\n",
    "\n",
    "    # another attempt to dampen the bounce of the car and the road surface.\n",
    "    # This time by detecting the dest projection top and reset it if it is too\n",
    "    # low\n",
    "    def resetDestTop(self, projectionTopPixel):\n",
    "        us_lane_width = 12     # US highway width: 12 feet wide\n",
    "\n",
    "        # Approximate distance to vanishing point from end of rectangle\n",
    "        # calculate back off from vanishing point to move the display up\n",
    "        approx_dest = 42.0 * \\\n",
    "            (1.0 - ((projectionTopPixel / self.projectedY) * 0.50))\n",
    "\n",
    "        scale_factor = 6.0     # scaling for display\n",
    "        top = approx_dest * approx_dest\n",
    "        left = -(us_lane_width / 2) * scale_factor\n",
    "        right = (us_lane_width / 2) * scale_factor\n",
    "        self.curDstRoadCorners = np.float32(\n",
    "            [[(self.projectedX / 2) + left, top],\n",
    "             [(self.projectedX / 2) + right, top],\n",
    "             [(self.projectedX / 2) + right, self.projectedY],\n",
    "             [(self.projectedX / 2) + left, self.projectedY]])\n",
    "\n",
    "        # create 3D dst road corners\n",
    "        self.cur3DDstRoadCorners = np.zeros((4, 3), np.float32)\n",
    "        self.cur3DDstRoadCorners[:, :2] = self.curDstRoadCorners\n",
    "\n",
    "    # pixel to meter distance calculation\n",
    "    def pixel2Meter(self):\n",
    "        return self.curImgFtr.throwDistance / self.projectedY\n",
    "\n",
    "    # Augmentation Special Effects - default full sweep takes about two\n",
    "    # seconds 52 frames - video is 26fps\n",
    "    def wireframe(self, wireFrameProjection, frame, mainLane,\n",
    "                  color=[255, 255, 255], wireThick=1,\n",
    "                  sweepThick=5, fullsweepFrame=26):\n",
    "        # calculate the wireframe positions\n",
    "        nlanes = len(mainLane.lines) - 1\n",
    "        leftPolynomial = np.poly1d(mainLane.lines[0].currentFit)\n",
    "        roadleftPolynomial = np.poly1d(\n",
    "            mainLane.lines[mainLane.left].currentFit)\n",
    "        roadrightPolynomial = np.poly1d(\n",
    "            mainLane.lines[mainLane.right].currentFit)\n",
    "        rightPolynomial = np.poly1d(mainLane.lines[nlanes].currentFit)\n",
    "        delta = (frame * 32) % 128\n",
    "        squares = []\n",
    "\n",
    "        # horizontal lines\n",
    "        for i in range(int(self.projectedY / 128)):\n",
    "            y1 = 128 * i + delta\n",
    "            x1 = leftPolynomial([y1])\n",
    "            x2 = roadleftPolynomial([y1])\n",
    "            x3 = roadrightPolynomial([y1])\n",
    "            x4 = rightPolynomial([y1])\n",
    "            cv2.line(wireFrameProjection, (x1, y1),\n",
    "                     (x4, y1), color, wireThick * 3)\n",
    "            squares.append(((x2, y1), (x3, y1)))\n",
    "\n",
    "        # vertical lines\n",
    "        allY = [n * 32 for n in range(int(self.projectedY / 32))]\n",
    "        polyDiff = np.polysub(mainLane.lines[nlanes].currentFit,\n",
    "                              mainLane.lines[0].currentFit) / (nlanes * 2)\n",
    "        curPoly = leftPolynomial\n",
    "        for i in range(nlanes * 2):\n",
    "            allX = curPoly(allY)\n",
    "            XYPolyline = np.column_stack((allX, allY)).astype(np.int32)\n",
    "            cv2.polylines(wireFrameProjection, [\n",
    "                          XYPolyline], 0, color, int(wireThick / 4))\n",
    "            curPoly = np.polyadd(curPoly, polyDiff)\n",
    "        return squares\n",
    "\n",
    "    # Augmentation Special Effects - default full sweep takes about four\n",
    "    # seconds 104 frames - video is 26fps\n",
    "    def sweep(self, wireFrameProjection, frame, lines,\n",
    "              color=[0, 0, 255], sweepThick=5, fullsweepFrame=104):\n",
    "        # calculate sweep angle\n",
    "        halfcycle = fullsweepFrame / 2\n",
    "        position = (frame % fullsweepFrame)\n",
    "        if position > halfcycle:\n",
    "            position = fullsweepFrame - position\n",
    "        sweep = position / halfcycle\n",
    "        allY = [n * 32 for n in range(int(self.projectedY / 32))]\n",
    "\n",
    "        # calculate the wireframe positions\n",
    "        nlanes = len(lines) - 1\n",
    "        leftPolynomial = np.poly1d(lines[0].currentFit)\n",
    "        rightPolynomial = np.poly1d(lines[nlanes].currentFit)\n",
    "\n",
    "        # scanning sweep\n",
    "        polySweepDiff = np.polysub(\n",
    "            lines[nlanes].currentFit,\n",
    "            lines[0].currentFit) * sweep\n",
    "        sweepPoly = np.polyadd(leftPolynomial, polySweepDiff)\n",
    "        allX = sweepPoly(allY)\n",
    "        XYPolyline = np.column_stack((allX, allY)).astype(np.int32)\n",
    "        cv2.polylines(wireFrameProjection, [XYPolyline], 0, color, sweepThick)\n",
    "        sweepLane = 0\n",
    "        for i in range(nlanes):\n",
    "            leftLine = np.poly1d(lines[i].currentFit)\n",
    "            rightLine = np.poly1d(lines[i+1].currentFit)\n",
    "            if (leftLine([self.projectedY])[0] <\n",
    "                    sweepPoly([self.projectedY])[0] and\n",
    "                    sweepPoly([self.projectedY])[0] <\n",
    "                    rightLine([self.projectedY])[0]):\n",
    "                sweepLane = i\n",
    "        return sweepLane\n",
    "\n",
    "    def drawAxisOnLane(self, perspectiveImage):\n",
    "        be_corner = np.float32(\n",
    "            [[self.curDstRoadCorners[0][0],\n",
    "              self.curDstRoadCorners[0][1], 0],\n",
    "             [self.curDstRoadCorners[0][0],\n",
    "              self.curDstRoadCorners[0][1], 0],\n",
    "             [self.curDstRoadCorners[0][0],\n",
    "              self.curDstRoadCorners[0][1], 0]]).reshape(-1, 3)\n",
    "\n",
    "        be_axis = np.float32(\n",
    "            [[self.curDstRoadCorners[0][0] + 64,\n",
    "              self.curDstRoadCorners[0][1], 0],\n",
    "             [self.curDstRoadCorners[0][0],\n",
    "              self.curDstRoadCorners[0][1] + 128, 0],\n",
    "             [self.curDstRoadCorners[0][0],\n",
    "              self.curDstRoadCorners[0][1], -64]]).reshape(-1, 3)\n",
    "\n",
    "        corner, jac = cv2.projectPoints(\n",
    "            be_corner, self.rvecs, self.tvecs, self.mtx, self.dist)\n",
    "        axis, jac = cv2.projectPoints(\n",
    "            be_axis, self.rvecs, self.tvecs, self.mtx, self.dist)\n",
    "        corner = tuple(corner[0].ravel())\n",
    "\n",
    "        cv2.line(perspectiveImage, corner, tuple(\n",
    "            axis[0].ravel()), (255, 0, 0), 5)\n",
    "        cv2.line(perspectiveImage, corner, tuple(\n",
    "            axis[1].ravel()), (0, 255, 0), 5)\n",
    "        cv2.line(perspectiveImage, corner, tuple(\n",
    "            axis[2].ravel()), (0, 0, 255), 5)\n",
    "\n",
    "    def projectPoints(self, birdsEye3DPoints):\n",
    "        m11 = self.dst2srcM[0][0]\n",
    "        m12 = self.dst2srcM[0][1]\n",
    "        m13 = self.dst2srcM[0][2]\n",
    "        m21 = self.dst2srcM[1][0]\n",
    "        m22 = self.dst2srcM[1][1]\n",
    "        m23 = self.dst2srcM[1][2]\n",
    "        m31 = self.dst2srcM[2][0]\n",
    "        m32 = self.dst2srcM[2][1]\n",
    "        m33 = self.dst2srcM[2][2]\n",
    "        x = birdsEye3DPoints[:, 0]\n",
    "        y = birdsEye3DPoints[:, 1]\n",
    "        z = birdsEye3DPoints[:, 2]\n",
    "        size = len(birdsEye3DPoints)\n",
    "        perspectiveImagePoints = np.zeros((size, 2), dtype=np.float32)\n",
    "        perspectiveImagePoints[:, 0] = (\n",
    "            m11 * x + m12 * y + m13) / (m31 * x + m32 * y + m33)\n",
    "        perspectiveImagePoints[:, 1] = (\n",
    "            m21 * x + m22 * y + m23 - z) / (m31 * x + m32 * y + m33)\n",
    "        return perspectiveImagePoints\n",
    "\n",
    "    def drawCalibrationCube(self, perspectiveImage):\n",
    "        be_cube = np.float32(\n",
    "            [[self.curDstRoadCorners[0][0],\n",
    "              self.curDstRoadCorners[0][1], 0],\n",
    "             [self.curDstRoadCorners[1][0],\n",
    "              self.curDstRoadCorners[1][1], 0],\n",
    "             [self.curDstRoadCorners[2][0],\n",
    "              self.curDstRoadCorners[2][1]-100, 0],\n",
    "             [self.curDstRoadCorners[3][0],\n",
    "              self.curDstRoadCorners[3][1]-100, 0],\n",
    "             [self.curDstRoadCorners[0][0],\n",
    "              self.curDstRoadCorners[0][1], self.z*2],\n",
    "             [self.curDstRoadCorners[1][0],\n",
    "              self.curDstRoadCorners[1][1], self.z*2],\n",
    "             [self.curDstRoadCorners[2][0],\n",
    "              self.curDstRoadCorners[2][1]-100, self.z*2],\n",
    "             [self.curDstRoadCorners[3][0],\n",
    "              self.curDstRoadCorners[3][1]-100, self.z*2]]).reshape(-1, 3)\n",
    "        cube = self.projectPoints(be_cube)\n",
    "        imgpts = np.int32(cube).reshape(-1, 2)\n",
    "\n",
    "        # draw bottom of cube\n",
    "        cv2.drawContours(perspectiveImage, [imgpts[:4]], -1, (255, 0, 0), 3)\n",
    "        # draw sides of cube\n",
    "        for i, j in zip(range(4), range(4, 8)):\n",
    "            cv2.line(perspectiveImage, tuple(\n",
    "                imgpts[i]), tuple(imgpts[j]), (0, 255, 0), 3)\n",
    "        # draw top of cube\n",
    "        cv2.drawContours(perspectiveImage, [imgpts[4:]], -1, (0, 0, 255), 3)\n",
    "\n",
    "    def drawRoadSquares(self, perspectiveImage, squares):\n",
    "        for square in squares:\n",
    "            be_square = np.float32(\n",
    "                [[square[0][0] - 16, square[0][1], 0],\n",
    "                 [square[0][0] - 16, square[0][1], self.z*2],\n",
    "                 [square[1][0] + 16, square[1][1], self.z*2],\n",
    "                 [square[1][0] + 16, square[1][1], 0]]).reshape(-1, 3)\n",
    "            square = self.projectPoints(be_square)\n",
    "            imgpts = np.int32(square).reshape(-1, 2)\n",
    "            # draw bottom of square\n",
    "            cv2.drawContours(perspectiveImage, [imgpts[:4]], -1, (0, 255, 0), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane\n",
    "\n",
    "Lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lane():\n",
    "\n",
    "    def __init__(self, x, y, projectedX, projectedY, maskDelta,\n",
    "                 lines, left=0, right=1, maskvalue=128):\n",
    "        # initial setup\n",
    "        self.curFrame = None\n",
    "\n",
    "        # our own copy of the lines array\n",
    "        self.lines = lines\n",
    "\n",
    "        # dimensions\n",
    "        self.mid = int(y / 2)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.projectedX = projectedX\n",
    "        self.projectedY = projectedY\n",
    "\n",
    "        # frameNumber\n",
    "        self.currentFrame = None\n",
    "\n",
    "        # left lines only\n",
    "        # left line identifier\n",
    "        self.left = left\n",
    "\n",
    "        # left lane stats\n",
    "        self.leftLineLastTop = None\n",
    "        self.adjacentLeft = False\n",
    "\n",
    "        # right lines only\n",
    "        # right line identifier\n",
    "        self.right = right\n",
    "\n",
    "        # right lane stats\n",
    "        self.rightLineLastTop = None\n",
    "        self.adjacentRight = False\n",
    "\n",
    "        # number of points fitted\n",
    "        self.leftLinePoints = 0\n",
    "        self.rightLinePoints = 0\n",
    "\n",
    "        # mask value\n",
    "        self.maskvalue = maskvalue\n",
    "\n",
    "    # confidence calculation\n",
    "    def confidence(self):\n",
    "        lconf = self.lines[self.left].confidence\n",
    "        rconf = self.lines[self.right].confidence\n",
    "        if lconf > rconf:\n",
    "            return rconf\n",
    "        return lconf\n",
    "\n",
    "    # function to set left/right indexes\n",
    "    def setLineIndex(self, left, right):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    # function to get left/right indexes\n",
    "    def getLineIndex(self):\n",
    "        return self.left, self.right\n",
    "\n",
    "    # function to get combined lineBasePos\n",
    "    def getLineBasePos(self):\n",
    "        lineBasePos = self.lines[self.left].lineBasePos\n",
    "        lineBasePos += self.lines[self.right].lineBasePos\n",
    "        return lineBasePos\n",
    "\n",
    "    # function to draw lane polygon\n",
    "    def drawLanePoly(self, roadmask):\n",
    "        if self.lines[self.right].XYPolyline is not None and \\\n",
    "           self.lines[self.left].XYPolyline is not None:\n",
    "            roadpoly = np.concatenate(\n",
    "                (self.lines[self.right].XYPolyline,\n",
    "                 self.lines[self.left].XYPolyline[::-1]), axis=0)\n",
    "            cv2.fillConvexPoly(roadmask, roadpoly, self.maskvalue)\n",
    "        return roadmask\n",
    "\n",
    "    # function to calculate radius of curvature measurements\n",
    "    def getRadiusOfCurvature(self):\n",
    "        if self.lines[self.left].radiusOfCurvature is None or \\\n",
    "           self.lines[self.right].radiusOfCurvature is None:\n",
    "            if self.lines[self.left].radiusOfCurvature is None:\n",
    "                if self.lines[self.right].radiusOfCurvature is None:\n",
    "                    radius = 0.000001\n",
    "                else:\n",
    "                    radius = self.lines[\n",
    "                        self.right].radiusOfCurvature\n",
    "            else:\n",
    "                if self.lines[self.right].radiusOfCurvature is None:\n",
    "                    radius = self.lines[self.left].radiusOfCurvature\n",
    "                else:\n",
    "                    radius = self.lines[self.left].radiusOfCurvature\n",
    "                    radius += self.lines[self.right].radiusOfCurvature\n",
    "                    radius /= 2.0\n",
    "        elif self.lines[self.left].radiusOfCurvature > 0.0 and \\\n",
    "                self.lines[self.right].radiusOfCurvature > 0.0:\n",
    "            radius = self.lines[self.left].radiusOfCurvature\n",
    "            radius += self.lines[self.right].radiusOfCurvature\n",
    "            radius /= 2.0\n",
    "            if self.lines[self.left].radiusOfCurvature > 3000.0:\n",
    "                roadStraight = True\n",
    "            elif self.lines[self.right].radiusOfCurvature > 3000.0:\n",
    "                roadStraight = True\n",
    "            else:\n",
    "                roadStraight = False\n",
    "        elif self.lines[self.left].radiusOfCurvature < 0.0 and \\\n",
    "                self.lines[self.right].radiusOfCurvature < 0.0:\n",
    "            radius = self.lines[self.left].radiusOfCurvature\n",
    "            radius += self.lines[self.right].radiusOfCurvature\n",
    "            radius /= 2.0\n",
    "            if self.lines[self.left].radiusOfCurvature < -3000.0:\n",
    "                roadStraight = True\n",
    "            elif self.lines[self.right].radiusOfCurvature < -3000.0:\n",
    "                roadStraight = True\n",
    "            else:\n",
    "                roadStraight = False\n",
    "        else:\n",
    "            radius = 0.000001\n",
    "            roadStraight = True\n",
    "        return radius, roadStraight\n",
    "\n",
    "    # function to set maskDelta\n",
    "    def setMaskDelta(self, maskDelta):\n",
    "        self.lines[self.left].setMaskDelta(maskDelta)\n",
    "        self.lines[self.right].setMaskDelta(maskDelta)\n",
    "\n",
    "    # function to find starting lane line positions\n",
    "    def findInitialLines(self, curImgFtr, resized=False):\n",
    "        self.curImgFtr = curImgFtr\n",
    "\n",
    "        if self.curFrame is None:\n",
    "            self.curFrame = 0\n",
    "        else:\n",
    "            self.curFrame += 1\n",
    "\n",
    "        masked_edges = curImgFtr.getEdgeProjection()\n",
    "        # print(\"masked_edges: \", masked_edges.shape)\n",
    "        masked_edge = masked_edges[:, :, 1]\n",
    "        height = masked_edge.shape[0]\n",
    "        width = masked_edge.shape[1]\n",
    "\n",
    "        # get the initial points into the lines\n",
    "        # height used to be half - but with 1920 pixels - we just need 20%\n",
    "        # now...\n",
    "        lefthistogram = np.sum(masked_edge[int(\n",
    "            height * 0.80):height, 0:int(width * 0.5)], axis=0)\n",
    "        lefthistogram = lefthistogram.astype(np.float32)\n",
    "        righthistogram = np.sum(masked_edge[int(\n",
    "            height * 0.80):height, int(width * 0.5):width], axis=0)\n",
    "        righthistogram = righthistogram.astype(np.float32)\n",
    "        self.leftpos = np.argmax(lefthistogram)\n",
    "        self.rightpos = np.argmax(righthistogram) + int(width / 2)\n",
    "        self.distance = self.rightpos - self.leftpos\n",
    "\n",
    "        # set the left and right line's base\n",
    "        self.lines[self.left].setBasePos(self.leftpos)\n",
    "        self.lines[self.right].setBasePos(self.rightpos)\n",
    "\n",
    "        # set their points\n",
    "        self.lines[self.left].find_lane_lines_points(masked_edge)\n",
    "        self.lines[self.right].find_lane_lines_points(masked_edge)\n",
    "\n",
    "        # fit the left line side\n",
    "        self.lines[self.left].fitpoly()\n",
    "        self.leftprojection = self.lines[self.left].applyLineMask(masked_edges)\n",
    "        self.lines[self.left].radius_in_meters(\n",
    "            self.curImgFtr.throwDistance, self.distance)\n",
    "        self.lines[self.left].meters_from_center_of_vehicle(self.distance)\n",
    "\n",
    "        # classify the left line\n",
    "        if not self.lines[self.left].lineClassified:\n",
    "            # print(\"classifying the left line\",self.left)\n",
    "            self.lines[self.left].getLineStats(\n",
    "                self.curImgFtr.getRoadProjection(), resized=resized)\n",
    "            self.lines[self.left].adjacentRLine = self.lines[self.right]\n",
    "            self.adjacentLeft = self.lines[self.left].adjacentLeft\n",
    "            self.adjacentLLane = None\n",
    "\n",
    "        # fit the right side\n",
    "        self.lines[self.right].fitpoly()\n",
    "        self.rightprojection = self.lines[\n",
    "            self.right].applyLineMask(masked_edges)\n",
    "        self.lines[self.right].radius_in_meters(\n",
    "            self.curImgFtr.throwDistance, self.distance)\n",
    "        self.lines[self.right].meters_from_center_of_vehicle(self.distance)\n",
    "\n",
    "        # classify the right line\n",
    "        if not self.lines[self.right].lineClassified:\n",
    "            # print(\"classifying the right line\",self.right)\n",
    "            self.lines[self.right].getLineStats(\n",
    "                self.curImgFtr.getRoadProjection(), resized=resized)\n",
    "            self.lines[self.right].adjacentLLine = self.lines[self.left]\n",
    "            self.adjacentRight = self.lines[self.right].adjacentRight\n",
    "            self.adjacentRLane = None\n",
    "\n",
    "        # Update Stats and Top points for next frame.\n",
    "        self.leftLineLastTop = self.lines[self.left].getTopPoint()\n",
    "        self.rightLineLastTop = self.lines[self.right].getTopPoint()\n",
    "        self.leftLinePoints = len(self.lines[self.left].allX)\n",
    "        self.rightLinePoints = len(self.lines[self.right].allX)\n",
    "\n",
    "    # function to calculate center x position given y for a lane\n",
    "    def calculateXCenter(self, y):\n",
    "        leftPolynomial = np.poly1d(self.lines[self.left].currentFit)\n",
    "        rightPolynomial = np.poly1d(self.lines[self.right].currentFit)\n",
    "        return int((rightPolynomial([y]) + leftPolynomial([y])) / 2)\n",
    "\n",
    "    # function to calculate bottom y for a lane\n",
    "    def bottomY(self):\n",
    "        return np.min([\n",
    "            self.lines[self.left].bottomProjectedY,\n",
    "            self.lines[self.right].bottomProjectedY])\n",
    "\n",
    "    # function to mask lane line positions\n",
    "    # and do lane measurement calculations\n",
    "    def findExistingLines(self, curImgFtr):\n",
    "        self.curImgFtr = curImgFtr\n",
    "        self.curFrame += 1\n",
    "\n",
    "        masked_edges = curImgFtr.getEdgeProjection()\n",
    "        # print(\"masked_edges: \", masked_edges.shape)\n",
    "        masked_edge = masked_edges[:, :, 1]\n",
    "        height = masked_edge.shape[0]\n",
    "        width = masked_edge.shape[1]\n",
    "\n",
    "        # Left Lane Line Projection setup\n",
    "        self.leftprojection = self.lines[self.left].applyLineMask(masked_edges)\n",
    "        leftPoints = np.nonzero(self.leftprojection)\n",
    "        self.lines[self.left].allX = leftPoints[1]\n",
    "        self.lines[self.left].allY = leftPoints[0]\n",
    "        self.lines[self.left].fitpoly2()\n",
    "\n",
    "        # Right Lane Line Projection setup\n",
    "        self.rightprojection = self.lines[\n",
    "            self.right].applyLineMask(masked_edges)\n",
    "        rightPoints = np.nonzero(self.rightprojection)\n",
    "        self.lines[self.right].allX = rightPoints[1]\n",
    "        self.lines[self.right].allY = rightPoints[0]\n",
    "        self.lines[self.right].fitpoly2()\n",
    "\n",
    "        # take and calculate some measurements\n",
    "        self.distance = self.lines[\n",
    "            self.right].pixelBasePos - self.lines[self.left].pixelBasePos\n",
    "        self.lines[self.left].radius_in_meters(\n",
    "            self.curImgFtr.throwDistance, self.distance)\n",
    "        self.lines[self.left].meters_from_center_of_vehicle(self.distance)\n",
    "        self.lines[self.right].radius_in_meters(\n",
    "            self.curImgFtr.throwDistance, self.distance)\n",
    "        self.lines[self.right].meters_from_center_of_vehicle(self.distance)\n",
    "\n",
    "        leftTop = self.lines[self.left].getTopPoint()\n",
    "        rightTop = self.lines[self.right].getTopPoint()\n",
    "\n",
    "        # Attempt to move up the Lane lines if we missed some predictions\n",
    "        if self.leftLineLastTop is not None and \\\n",
    "                self.rightLineLastTop is not None:\n",
    "\n",
    "            # If we are in the harder challenge, our visibility is obscured,\n",
    "            # so only do this if we are certain that our visibility is good.\n",
    "            # i.e.: not in the harder challenge!\n",
    "            if self.curImgFtr.visibility > -30:\n",
    "                # if either lines differs by greater than 50 pixel vertically\n",
    "                # we need to request the shorter line to go higher.\n",
    "                if abs(self.leftLineLastTop[1] -\n",
    "                       self.rightLineLastTop[1]) > 50:\n",
    "                    if self.leftLineLastTop[1] > self.rightLineLastTop[1]:\n",
    "                        self.lines[self.left].requestTopY(\n",
    "                            self.rightLineLastTop[1])\n",
    "                    else:\n",
    "                        self.lines[self.right].requestTopY(\n",
    "                            self.leftLineLastTop[1])\n",
    "\n",
    "                # if our lane line has fallen to below our threshold, get it to\n",
    "                # come back up\n",
    "                if leftTop is not None and leftTop[1] > self.mid - 100:\n",
    "                    self.lines[self.left].requestTopY(leftTop[1] - 10)\n",
    "                if leftTop is not None and \\\n",
    "                   leftTop[1] > self.leftLineLastTop[1]:\n",
    "                    self.lines[self.left].requestTopY(leftTop[1] - 10)\n",
    "                if rightTop is not None and rightTop[1] > self.mid - 100:\n",
    "                    self.lines[self.right].requestTopY(rightTop[1] - 10)\n",
    "                if rightTop is not None and \\\n",
    "                   rightTop[1] > self.rightLineLastTop[1]:\n",
    "                    self.lines[self.right].requestTopY(rightTop[1] - 10)\n",
    "\n",
    "            # visibility poor...\n",
    "            # harder challenge... need to be less agressive going back\n",
    "            # up the lane... let at least 30 frame pass before trying to\n",
    "            # move forward.\n",
    "            elif self.curFrame > 30:\n",
    "                # if either lines differs by greater than 50 pixel vertically\n",
    "                # we need to request the shorter line to go higher.\n",
    "                if abs(self.leftLineLastTop[1] -\n",
    "                       self.rightLineLastTop[1]) > 50:\n",
    "                    if self.leftLineLastTop[1] > self.rightLineLastTop[1] and \\\n",
    "                       leftTop is not None:\n",
    "                        self.lines[self.left].requestTopY(leftTop[1] - 10)\n",
    "                    elif rightTop is not None:\n",
    "                        self.lines[self.right].requestTopY(rightTop[1] - 10)\n",
    "\n",
    "                # if our lane line has fallen to below our threshold, get it to\n",
    "                # come back up\n",
    "                if leftTop is not None and leftTop[1] > self.mid + 100:\n",
    "                    self.lines[self.left].requestTopY(leftTop[1] - 10)\n",
    "                if leftTop is not None and \\\n",
    "                   leftTop[1] > self.leftLineLastTop[1]:\n",
    "                    self.lines[self.left].requestTopY(leftTop[1] - 10)\n",
    "                if rightTop is not None and rightTop[1] > self.mid + 100:\n",
    "                    self.lines[self.right].requestTopY(rightTop[1] - 10)\n",
    "                if rightTop is not None and \\\n",
    "                   rightTop[1] > self.rightLineLastTop[1]:\n",
    "                    self.lines[self.right].requestTopY(rightTop[1] - 10)\n",
    "\n",
    "        # Update Stats and Top points for next frame.\n",
    "        self.leftLineLastTop = self.lines[self.left].getTopPoint()\n",
    "        self.rightLineLastTop = self.lines[self.right].getTopPoint()\n",
    "        self.leftLinePoints = len(self.lines[self.left].allX)\n",
    "        self.rightLinePoints = len(self.lines[self.right].allX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line\n",
    "\n",
    "Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line():\n",
    "\n",
    "    def __init__(self, side, x, y, projectedX, projectedY, maskDelta, n=10):\n",
    "        # iterations to keep\n",
    "        self.n = n\n",
    "\n",
    "        # assigned side\n",
    "        self.side = side\n",
    "\n",
    "        # dimensions\n",
    "        self.mid = int(y / 2)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.projectedX = projectedX\n",
    "        self.projectedY = projectedY\n",
    "\n",
    "        # frameNumber\n",
    "        self.currentFrame = None\n",
    "\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False\n",
    "\n",
    "        # was the line detected in the last iteration?\n",
    "        self.confidence = 0.0\n",
    "        self.confidence_based = 0\n",
    "\n",
    "        # polynomial coefficients averaged over the last n iterations\n",
    "        self.bestFit = None\n",
    "\n",
    "        # polynomial coefficients for the most recent fit\n",
    "        self.currentFit = None\n",
    "\n",
    "        # x values of the current fitted line\n",
    "        self.currentX = None\n",
    "\n",
    "        # radius of curvature of the line in meters\n",
    "        self.radiusOfCurvature = None\n",
    "\n",
    "        # distance in meters of vehicle center from the line\n",
    "        self.lineBasePos = None\n",
    "\n",
    "        # pixel base position\n",
    "        self.pixelBasePos = None\n",
    "        self.bottomProjectedY = projectedY\n",
    "\n",
    "        # difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0, 0, 0], dtype='float')\n",
    "\n",
    "        # x values for detected line pixels\n",
    "        self.allX = None\n",
    "\n",
    "        # y values for detected line pixels\n",
    "        self.allY = None\n",
    "\n",
    "        # xy values for drawing\n",
    "        self.XYPolyline = None\n",
    "\n",
    "        # mask delta for masking points in lane\n",
    "        self.maskDelta = maskDelta\n",
    "\n",
    "        # poly for fitting new values\n",
    "        self.linePoly = None\n",
    "\n",
    "        # mask for lanes\n",
    "        self.linemask = np.zeros(\n",
    "            (self.projectedY, self.projectedX), dtype=np.uint8)\n",
    "\n",
    "        # road manager request\n",
    "        self.newYTop = None\n",
    "\n",
    "        # classify line\n",
    "        self.lineClassified = False\n",
    "        self.lineType = \"not found\"\n",
    "        self.line_color = \"\"\n",
    "\n",
    "    # create adjacent lane lines using an existing lane on the right\n",
    "    def createPolyFitLeft(self, curImgFtr, rightLane,\n",
    "                          faint=1.0, resized=False):\n",
    "        # create new left line polynomial\n",
    "        polyDiff = np.polysub(rightLane.lines[rightLane.left].currentFit,\n",
    "                              rightLane.lines[rightLane.right].currentFit)\n",
    "        self.currentFit = np.polyadd(\n",
    "            rightLane.lines[rightLane.left].currentFit, polyDiff)\n",
    "        polynomial = np.poly1d(self.currentFit)\n",
    "        self.allY = rightLane.lines[rightLane.left].allY\n",
    "        self.currentX = polynomial(self.allY)\n",
    "        self.allX = self.currentX\n",
    "\n",
    "        if len(self.allY) > 75:\n",
    "            # We need to increase our pixel count by 2 to get to 100%\n",
    "            # confidence and maintain the current pixel count to keep\n",
    "            # the line detection\n",
    "            self.confidence_based = len(self.allY) * 2\n",
    "            self.confidence = len(self.allY) / self.confidence_based\n",
    "            self.detected = True\n",
    "\n",
    "            # create linepoly\n",
    "            xy1 = np.column_stack(\n",
    "                (self.currentX + self.maskDelta, self.allY)).astype(np.int32)\n",
    "            xy2 = np.column_stack(\n",
    "                (self.currentX - self.maskDelta, self.allY)).astype(np.int32)\n",
    "            self.linePoly = np.concatenate((xy1, xy2[::-1]), axis=0)\n",
    "\n",
    "            # create mask\n",
    "            self.linemask = np.zeros_like(self.linemask)\n",
    "            cv2.fillConvexPoly(self.linemask, self.linePoly, 64)\n",
    "\n",
    "            # Add the point at the bottom.\n",
    "            allY = np.append(self.allY, self.projectedY - 1)\n",
    "            allX = polynomial(allY)\n",
    "            self.XYPolyline = np.column_stack((allX, allY)).astype(np.int32)\n",
    "\n",
    "            # create the accumulator\n",
    "            self.bestFit = self.currentFit\n",
    "\n",
    "            # classify the line\n",
    "            # print(\"classifying the left line\",self.side)\n",
    "            self.getLineStats(\n",
    "                curImgFtr.getRoadProjection(), faint=faint, resized=resized)\n",
    "\n",
    "            # set bottom of line\n",
    "            x = polynomial([self.projectedY - 1])\n",
    "            self.pixelBasePos = x[0]\n",
    "\n",
    "    # create adjacent lane lines using an existing lane on the left\n",
    "    def createPolyFitRight(self, curImgFtr, leftLane,\n",
    "                           faint=1.0, resized=False):\n",
    "        # create new right line polynomial\n",
    "        polyDiff = np.polysub(leftLane.lines[leftLane.right].currentFit,\n",
    "                              leftLane.lines[leftLane.left].currentFit)\n",
    "        self.currentFit = np.polyadd(\n",
    "            leftLane.lines[leftLane.right].currentFit, polyDiff)\n",
    "        polynomial = np.poly1d(self.currentFit)\n",
    "        self.allY = leftLane.lines[leftLane.right].allY\n",
    "        self.currentX = polynomial(self.allY)\n",
    "        self.allX = self.currentX\n",
    "\n",
    "        if len(self.allY) > 75:\n",
    "            # We need to increase our pixel count by 2 to get to 100%\n",
    "            # confidence and maintain the current pixel count to keep\n",
    "            # the line detection\n",
    "            self.confidence_based = len(self.allY) * 2\n",
    "            self.confidence = len(self.allY) / self.confidence_based\n",
    "            self.detected = True\n",
    "\n",
    "            # create linepoly\n",
    "            xy1 = np.column_stack(\n",
    "                (self.currentX + self.maskDelta, self.allY))\n",
    "            xy1 = xy1.astype(np.int32)\n",
    "            xy2 = np.column_stack(\n",
    "                (self.currentX - self.maskDelta, self.allY))\n",
    "            xy2 = xy2.astype(np.int32)\n",
    "            self.linePoly = np.concatenate((xy1, xy2[::-1]), axis=0)\n",
    "\n",
    "            # create mask\n",
    "            self.linemask = np.zeros_like(self.linemask)\n",
    "            cv2.fillConvexPoly(self.linemask, self.linePoly, 64)\n",
    "\n",
    "            # Add the point at the bottom.\n",
    "            allY = np.append(self.allY, self.projectedY - 1)\n",
    "            allX = polynomial(allY)\n",
    "            self.XYPolyline = np.column_stack((allX, allY))\n",
    "            self.XYPolyline = self.XYPolyline.astype(np.int32)\n",
    "\n",
    "            # create the accumulator\n",
    "            self.bestFit = self.currentFit\n",
    "\n",
    "            # classify the line\n",
    "            # print(\"classifying the right line\",self.side)\n",
    "            self.getLineStats(\n",
    "                curImgFtr.getRoadProjection(), faint=faint, resized=resized)\n",
    "\n",
    "            # set bottom of line\n",
    "            x = polynomial([self.projectedY - 1])\n",
    "            self.pixelBasePos = x[0]\n",
    "\n",
    "    # update adjacent lane lines using an existing lane on the right\n",
    "    def updatePolyFitLeft(self, rightLane):\n",
    "        # update new left line polynomial\n",
    "        polyDiff = np.polysub(rightLane.lines[rightLane.left].currentFit,\n",
    "                              rightLane.lines[rightLane.right].currentFit)\n",
    "        self.currentFit = np.polyadd(\n",
    "            rightLane.lines[rightLane.left].currentFit, polyDiff)\n",
    "        polynomial = np.poly1d(self.currentFit)\n",
    "        self.allY = rightLane.lines[rightLane.left].allY\n",
    "        self.currentX = polynomial(self.allY)\n",
    "        self.allX = self.currentX\n",
    "\n",
    "        if len(self.allY) > 150:\n",
    "            # We need to increase our pixel count by 2 to get to 100%\n",
    "            # confidence and maintain the current pixel count to keep\n",
    "            # the line detection\n",
    "            self.confidence = len(self.allY) / self.confidence_based\n",
    "            if self.confidence > 0.5:\n",
    "                self.detected = True\n",
    "                if self.confidence > 1.0:\n",
    "                    self.confidence = 1.0\n",
    "            else:\n",
    "                self.detected = False\n",
    "\n",
    "            # create linepoly\n",
    "            xy1 = np.column_stack(\n",
    "                (self.currentX + self.maskDelta, self.allY)).astype(np.int32)\n",
    "            xy2 = np.column_stack(\n",
    "                (self.currentX - self.maskDelta, self.allY)).astype(np.int32)\n",
    "            self.linePoly = np.concatenate((xy1, xy2[::-1]), axis=0)\n",
    "\n",
    "            # create mask\n",
    "            self.linemask = np.zeros_like(self.linemask)\n",
    "            cv2.fillConvexPoly(self.linemask, self.linePoly, 64)\n",
    "\n",
    "            # Add the point at the bottom.\n",
    "            allY = np.append(self.allY, self.projectedY - 1)\n",
    "            allX = polynomial(allY)\n",
    "            self.XYPolyline = np.column_stack((allX, allY)).astype(np.int32)\n",
    "\n",
    "            # create the accumulator\n",
    "            self.bestFit = self.currentFit\n",
    "\n",
    "    # update adjacent lane lines using an existing lane on the left\n",
    "    def updatePolyFitRight(self, leftLane):\n",
    "        # update new right line polynomial\n",
    "        polyDiff = np.polysub(leftLane.lines[leftLane.right].currentFit,\n",
    "                              leftLane.lines[leftLane.left].currentFit)\n",
    "        self.currentFit = np.polyadd(\n",
    "            leftLane.lines[leftLane.right].currentFit, polyDiff)\n",
    "        polynomial = np.poly1d(self.currentFit)\n",
    "        self.allY = leftLane.lines[leftLane.right].allY\n",
    "        self.currentX = polynomial(self.allY)\n",
    "        self.allX = self.currentX\n",
    "\n",
    "        if len(self.allY) > 150:\n",
    "            # We need to increase our pixel count by 2 to get to 100%\n",
    "            # confidence and maintain the current pixel count to keep\n",
    "            # the line detection\n",
    "            self.confidence = len(self.allY) / self.confidence_based\n",
    "            if self.confidence > 0.5:\n",
    "                self.detected = True\n",
    "                if self.confidence > 1.0:\n",
    "                    self.confidence = 1.0\n",
    "            else:\n",
    "                self.detected = False\n",
    "\n",
    "            # create linepoly\n",
    "            xy1 = np.column_stack(\n",
    "                (self.currentX + self.maskDelta, self.allY)).astype(np.int32)\n",
    "            xy2 = np.column_stack(\n",
    "                (self.currentX - self.maskDelta, self.allY)).astype(np.int32)\n",
    "            self.linePoly = np.concatenate((xy1, xy2[::-1]), axis=0)\n",
    "\n",
    "            # create mask\n",
    "            self.linemask = np.zeros_like(self.linemask)\n",
    "            cv2.fillConvexPoly(self.linemask, self.linePoly, 64)\n",
    "\n",
    "            # Add the point at the bottom.\n",
    "            allY = np.append(self.allY, self.projectedY - 1)\n",
    "            allX = polynomial(allY)\n",
    "            self.XYPolyline = np.column_stack((allX, allY)).astype(np.int32)\n",
    "\n",
    "            # create the accumulator\n",
    "            self.bestFit = self.currentFit\n",
    "\n",
    "    # function to find bottom of projection (camera cone)\n",
    "    def findBottomOfLine(self, curImgFtr):\n",
    "        projection = curImgFtr.getRoadProjection()\n",
    "        masked_projection = self.applyLineMask(projection)\n",
    "        points = np.nonzero(masked_projection)\n",
    "        self.bottomProjectedY = np.max(points[0])\n",
    "\n",
    "    # function to find lane line positions given histogram row,\n",
    "    # last column positions and n_neighbors\n",
    "    # return column positions\n",
    "    def find_lane_nearest_neighbors(self, histogram, lastpos, nneighbors):\n",
    "        ncol = len(histogram) - 1\n",
    "        x = []\n",
    "        list = {\"count\": 0, \"position\": lastpos}\n",
    "        for i in range(nneighbors):\n",
    "            if (lastpos + i) < len(histogram) and histogram[lastpos + i] > 0:\n",
    "                x.append(lastpos + i)\n",
    "                if list['count'] < histogram[lastpos + i]:\n",
    "                    list['count'] = histogram[lastpos + i]\n",
    "                    list['position'] = lastpos + i\n",
    "            if (lastpos - i) > 0 and histogram[lastpos - i] > 0:\n",
    "                x.append(lastpos - i)\n",
    "                if list['count'] < histogram[lastpos - i]:\n",
    "                    list['count'] = histogram[lastpos - i]\n",
    "                    list['position'] = lastpos - i\n",
    "        return list['position'], x\n",
    "\n",
    "    # function to set base position\n",
    "    def setBasePos(self, basePos):\n",
    "        self.pixelBasePos = basePos\n",
    "\n",
    "    # function to find lane lines points using a sliding window\n",
    "    # histogram given starting position\n",
    "    # return arrays x and y positions\n",
    "    def find_lane_lines_points(self, masked_lines):\n",
    "        xval = []\n",
    "        yval = []\n",
    "        nrows = masked_lines.shape[0] - 1\n",
    "        neighbors = 12\n",
    "        pos1 = self.pixelBasePos\n",
    "        start_row = nrows - 16\n",
    "        for i in range(int((nrows / neighbors))):\n",
    "            histogram = np.sum(\n",
    "                masked_lines[start_row + 10:start_row + 26, :], axis=0)\n",
    "            histogram = histogram.astype(np.uint8)\n",
    "            pos2, x = self.find_lane_nearest_neighbors(\n",
    "                histogram, pos1, int(neighbors * 1.3))\n",
    "            y = start_row + neighbors\n",
    "            for i in range(len(x)):\n",
    "                xval.append(x[i])\n",
    "                yval.append(y)\n",
    "            start_row -= neighbors\n",
    "            pos1 = pos2\n",
    "        self.allX = np.array(xval)\n",
    "        self.allY = np.array(yval)\n",
    "\n",
    "    # scatter plot the points\n",
    "    def scatter_plot(self, img, size=3):\n",
    "        if self.side == 1:\n",
    "            color = (192, 128, 128)\n",
    "        else:\n",
    "            color = (128, 128, 192)\n",
    "        xy_array = np.column_stack((self.allX, self.allY))\n",
    "        xy_array = xy_array.astype(np.int32)\n",
    "        for xy in xy_array:\n",
    "            cv2.circle(img, (xy[0], xy[1]), size, color, -1)\n",
    "\n",
    "    # draw fitted polyline\n",
    "    def polyline(self, img, size=5):\n",
    "        if self.side == 1:\n",
    "            color = (255, 0, 0)\n",
    "        else:\n",
    "            color = (0, 0, 255)\n",
    "        cv2.polylines(img, [self.XYPolyline], 0, color, size)\n",
    "\n",
    "    # Fit a (default=second order) polynomial to lane line\n",
    "    # Use for initialization when first starting up or when lane line was lost\n",
    "    # and starting over.\n",
    "    def fitpoly(self, degree=2):\n",
    "        if len(self.allY) > 150:\n",
    "            # We need to increase our pixel count by 2 to get to 100%\n",
    "            # confidence and maintain the current pixel count to keep\n",
    "            # the line detection\n",
    "            self.confidence_based = len(self.allY) * 2\n",
    "            self.confidence = len(self.allY) / self.confidence_based\n",
    "            self.detected = True\n",
    "\n",
    "            self.currentFit = np.polyfit(self.allY, self.allX, degree)\n",
    "            polynomial = np.poly1d(self.currentFit)\n",
    "\n",
    "            # reverse the polyline since we went up from the bottom\n",
    "            self.allY = self.allY[::-1]\n",
    "            self.currentX = polynomial(self.allY)\n",
    "\n",
    "            # create linepoly\n",
    "            xy1 = np.column_stack(\n",
    "                (self.currentX + 15, self.allY)).astype(np.int32)\n",
    "            xy2 = np.column_stack(\n",
    "                (self.currentX - 15, self.allY)).astype(np.int32)\n",
    "            self.linePoly = np.concatenate((xy1, xy2[::-1]), axis=0)\n",
    "\n",
    "            # create mask\n",
    "            self.linemask = np.zeros_like(self.linemask)\n",
    "            cv2.fillConvexPoly(self.linemask, self.linePoly, 64)\n",
    "\n",
    "            # Add the point at the bottom.\n",
    "            # NOTE: we walked up from the bottom - so the base point should be\n",
    "            # the first point.\n",
    "            allX = polynomial(self.allY)\n",
    "            allY = np.append(self.allY, self.projectedY - 1)\n",
    "            allX = np.append(allX, self.pixelBasePos)\n",
    "            self.XYPolyline = np.column_stack((allX, allY)).astype(np.int32)\n",
    "\n",
    "            # create the accumulator\n",
    "            self.bestFit = self.currentFit\n",
    "\n",
    "    # Fit a (default=second order) polynomial to lane line\n",
    "    # This version assumes that a manual fit was already done and is using\n",
    "    # the previously generated poly to fit the current line in the new frame\n",
    "    def fitpoly2(self, degree=2):\n",
    "        if len(self.allY) > 50:\n",
    "            self.currentFit = np.polyfit(self.allY, self.allX, degree)\n",
    "\n",
    "            # sanity check\n",
    "            self.diffs = self.currentFit - self.bestFit\n",
    "            if abs(sum(self.diffs)) < 150.0:\n",
    "                polynomial = np.poly1d(self.currentFit)\n",
    "\n",
    "                # Add the point at the bottom.\n",
    "                # NOTE: these points are counted by numpy:\n",
    "                # it does topdown, so our bottom point\n",
    "                # is now at the end of the list.\n",
    "                x = polynomial([self.projectedY - 1])\n",
    "                self.allY = np.append(self.allY, self.projectedY - 1)\n",
    "                self.allX = np.append(self.allX, x[0])\n",
    "                self.pixelBasePos = x[0]\n",
    "\n",
    "                # honoring the road manager request to move higher\n",
    "                # NOTE: these points are counted by numpy:\n",
    "                # it does topdown, so our top point\n",
    "                # is now at the front of the list.\n",
    "                if self.newYTop is not None:\n",
    "                    x = polynomial([self.newYTop])\n",
    "                    self.allY = np.insert(self.allY, 0, self.newYTop)\n",
    "                    self.allX = np.insert(self.allX, 0, x[0])\n",
    "                    self.newYTop = None\n",
    "\n",
    "                # fit the poly and generate the current fit.\n",
    "                self.currentX = polynomial(self.allY)\n",
    "                self.XYPolyline = np.column_stack(\n",
    "                    (self.currentX, self.allY)).astype(np.int32)\n",
    "\n",
    "                # create linepoly\n",
    "                xy1 = np.column_stack(\n",
    "                    (self.currentX + self.maskDelta, self.allY))\n",
    "                xy1 = xy1.astype(np.int32)\n",
    "                xy2 = np.column_stack(\n",
    "                    (self.currentX - self.maskDelta, self.allY))\n",
    "                xy2 = xy2.astype(np.int32)\n",
    "                self.linePoly = np.concatenate((xy1, xy2[::-1]), axis=0)\n",
    "\n",
    "                # create mask\n",
    "                self.linemask = np.zeros_like(self.linemask)\n",
    "                cv2.fillConvexPoly(self.linemask, self.linePoly, 64)\n",
    "\n",
    "                # add to the accumulators\n",
    "                self.bestFit = (self.bestFit + self.currentFit) / 2\n",
    "\n",
    "                # figure out confidence level\n",
    "                self.confidence = len(self.allY) / self.confidence_based\n",
    "                if self.confidence > 0.5:\n",
    "                    self.detected = True\n",
    "                    if self.confidence > 1.0:\n",
    "                        self.confidence = 1.0\n",
    "                else:\n",
    "                    self.detected = False\n",
    "            else:\n",
    "                # difference check failed - need to re-initialize\n",
    "                self.confidence = 0.0\n",
    "                self.detected = False\n",
    "        else:\n",
    "            # not enough points - need to re-initialize\n",
    "            self.confidence = 0.0\n",
    "            self.detected = False\n",
    "\n",
    "    # apply the line masking poly\n",
    "    def applyLineMask(self, img):\n",
    "        # print(\"img: \", img.shape)\n",
    "        # print(\"self.linemask: \", self.linemask.shape)\n",
    "        img0 = img[:, :, 1]\n",
    "        masked_edge = np.copy(self.linemask).astype(np.uint8)\n",
    "        masked_edge[(masked_edge > 0)] = 255\n",
    "        return cv2.bitwise_and(img0, img0, mask=masked_edge)\n",
    "\n",
    "    # apply the reverse line masking poly\n",
    "    def applyReverseLineMask(self, img):\n",
    "        # print(\"img: \", img.shape)\n",
    "        # print(\"self.linemask: \", self.linemask.shape)\n",
    "        masked_edge = np.copy(self.linemask).astype(np.uint8)\n",
    "        masked_edge[(self.linemask == 0)] = 255\n",
    "        masked_edge[(masked_edge < 255)] = 0\n",
    "        return cv2.bitwise_and(img, img, mask=masked_edge)\n",
    "\n",
    "    # sample line color'\n",
    "    def getLineStats(self, img, faint=1.0, resized=False):\n",
    "        # print(\"side: \", self.side)\n",
    "        # print(\"img: \", img.shape)\n",
    "        # print(\"self.linemask: \", self.linemask.shape)\n",
    "        imgR = np.copy(img[:, :, 0])\n",
    "        imgG = np.copy(img[:, :, 1])\n",
    "        imgB = np.copy(img[:, :, 2])\n",
    "        masked_edge = np.copy(self.linemask).astype(np.uint8)\n",
    "        masked_edge[(masked_edge > 0)] = 255\n",
    "        imgR = cv2.bitwise_and(imgR, imgR, mask=masked_edge)\n",
    "        imgG = cv2.bitwise_and(imgG, imgG, mask=masked_edge)\n",
    "        imgB = cv2.bitwise_and(imgB, imgB, mask=masked_edge)\n",
    "        red = np.max(imgR)\n",
    "        green = np.max(imgG)\n",
    "        blue = np.max(imgB)\n",
    "        self.line_rgb = (red, green, blue)\n",
    "        if len(self.allY) > 0:\n",
    "            self.line_height = np.max(self.allY) - np.min(self.allY)\n",
    "            self.pixelDensity = len(self.allY) / self.line_height\n",
    "            if resized:\n",
    "                self.pixelDensity *= 1.05\n",
    "            self.lineClassified = True\n",
    "        else:\n",
    "            self.line_height = 0\n",
    "            self.pixelDensity = 0.00000001\n",
    "\n",
    "        # detect if we have yellow lane line or white lane line\n",
    "        if (red > np.absolute(200 * faint) and\n",
    "            green < np.absolute(200 * faint) and\n",
    "            blue < np.absolute(200 * faint)) or \\\n",
    "            (red > np.absolute(200 * faint) and\n",
    "             green > np.absolute(200 * faint) and\n",
    "             blue < np.absolute(200 * faint)):\n",
    "            if faint == 1.0:\n",
    "                self.line_color = \"yellow\"\n",
    "            elif not resized and np.absolute(faint) < 0.7 and faint > 0.5:\n",
    "                self.line_color = \"white\"\n",
    "                self.lineType = \"solid\"\n",
    "                self.lineClassified = True\n",
    "            else:\n",
    "                self.line_color = \"white\"\n",
    "        elif (red > np.absolute(200 * faint) and\n",
    "              green > np.absolute(200 * faint) and\n",
    "              blue > np.absolute(200 * faint)):\n",
    "            if resized and np.absolute(faint) < 0.8:\n",
    "                if faint < -0.5:\n",
    "                    self.line_color = \"white\"\n",
    "                    self.lineType = \"dashed\"\n",
    "                    self.lineClassified = True\n",
    "                elif faint < 0.0:\n",
    "                    self.line_color = \"white\"\n",
    "                    self.lineType = \"solid\"\n",
    "                    self.lineClassified = True\n",
    "                else:\n",
    "                    self.line_color = \"yellow\"\n",
    "                    self.lineType = \"solid\"\n",
    "                    self.lineClassified = True\n",
    "            elif not resized and np.absolute(faint) < 0.7:\n",
    "                if faint < -0.50:\n",
    "                    self.line_color = \"yellow\"\n",
    "                    self.lineType = \"solid\"\n",
    "                    self.lineClassified = True\n",
    "                else:\n",
    "                    self.line_color = \"white\"\n",
    "                    self.lineType = \"solid\"\n",
    "                    self.lineClassified = True\n",
    "            else:\n",
    "                self.line_color = \"white\"\n",
    "        else:\n",
    "            self.lineClassified = False\n",
    "            self.line_color = \"\"\n",
    "\n",
    "        # detect if we have solid or dashed lines\n",
    "        if self.pixelDensity > 1.0 or self.line_color == \"yellow\":\n",
    "            self.lineType = \"solid\"\n",
    "        elif self.pixelDensity < 0.0001:\n",
    "            self.lineClassified = False\n",
    "            self.lineType = \"not found\"\n",
    "        elif self.lineType == \"not found\":\n",
    "            self.lineType = \"dashed\"\n",
    "\n",
    "        # determine if we should have adjacent lane lines\n",
    "        # left solid yellow\n",
    "        if self.lineType == \"solid\" and \\\n",
    "           self.line_color == \"yellow\" and \\\n",
    "           self.side == 1:\n",
    "            self.adjacentLeft = False\n",
    "            self.adjacentLLine = None\n",
    "            self.adjacentRight = True\n",
    "            self.adjacentRLine = None\n",
    "        elif (self.lineType == \"solid\" and\n",
    "              self.line_color == \"white\" and\n",
    "              self.side == 2):\n",
    "            self.adjacentLeft = True\n",
    "            self.adjacentLLine = None\n",
    "            self.adjacentRight = False\n",
    "            self.adjacentRLine = None\n",
    "        elif self.line_height > 600:\n",
    "            self.adjacentLeft = True\n",
    "            self.adjacentLLine = None\n",
    "            self.adjacentRight = True\n",
    "            self.adjacentRLine = None\n",
    "        else:\n",
    "            self.adjacentLeft = True\n",
    "            self.adjacentLLine = None\n",
    "            self.adjacentRight = False\n",
    "            self.adjacentRLine = None\n",
    "        # print(\"line type\", self.lineType, \"color\",\n",
    "        #        self.line_color, \"classified: \", self.lineClassified)\n",
    "        # print(\"rgb:\", red, green, blue )\n",
    "        # print(\"faint:\", faint )\n",
    "        # print(\"pixel density:\", self.pixelDensity )\n",
    "\n",
    "    # get the top point of the detected line.\n",
    "    # use to see if we lost track\n",
    "    def getTopPoint(self):\n",
    "        if (self.allY is not None and\n",
    "                self.currentFit is not None and\n",
    "                len(self.allY) > 0):\n",
    "            y = np.min(self.allY)\n",
    "            polynomial = np.poly1d(self.currentFit)\n",
    "            x = polynomial([y])\n",
    "            return(x[0], y)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # road manager request to move the line detection higher\n",
    "    # otherwise the algorithm is lazy and will lose the entire line.\n",
    "    def requestTopY(self, newY):\n",
    "        self.newYTop = newY\n",
    "\n",
    "    # reset the mask delta for dynamically adjusting masking curve when lines\n",
    "    # are harder to find.\n",
    "    def setMaskDelta(self, maskDelta):\n",
    "        self.maskDelta = maskDelta\n",
    "\n",
    "    # Define conversions in x and y from pixels space to meters given lane\n",
    "    # line separation in pixels\n",
    "    # NOTE: Only do calculation if it make sense - otherwise give previous\n",
    "    # answer.\n",
    "    def radius_in_meters(self, throwDistanceInMeters, distance):\n",
    "        # print(\"throwDistanceInMeters: \", throwDistanceInMeters)\n",
    "        if (throwDistanceInMeters > 0.0 and\n",
    "                self.allY is not None and\n",
    "                self.currentX is not None and\n",
    "                len(self.allY) > 0 and\n",
    "                len(self.currentX) > 0 and\n",
    "                len(self.allY) == len(self.currentX)):\n",
    "\n",
    "            ###################################################################\n",
    "            # Note: We are using 100 instead of 30 here since our throw for the\n",
    "            #       perspective transform is much longer. We estimate our throw\n",
    "            #       is 100 meters based on US Highway reecommended guides for\n",
    "            #       Longitudinal Pavement Markings.\n",
    "            #       See: http://mutcd.fhwa.dot.gov/htm/2003r1/part3/part3a.htm\n",
    "            #       Section 3A.05 Widths and Patterns of Longitudinal Pavement\n",
    "            #       Markings.\n",
    "            #       Guidance:\n",
    "            #           Broken lines should consist of 3 m (10 ft) line\n",
    "            #           segments and 9 m (30 ft) gaps, or dimensions in a\n",
    "            #           similar ratio of line segments to gaps as appropriate\n",
    "            #           for traffic speeds and need for delineation.\n",
    "            #       With new Full HD projected dimensions rotated 90 degrees,\n",
    "            #       lying on its side (1080, 1920), We are detecting about 8\n",
    "            #       to 9 sets of dashed line lanes on the right side:\n",
    "            #           8.5x(3+9)=8.5x12=~102m or just round to 100m AS DEFAULT\n",
    "            #       We are now calculating the throw Distance based on detected\n",
    "            #       projection top.\n",
    "            ###################################################################\n",
    "\n",
    "            # we have more pixels for Y changed from 720 to 1920\n",
    "            # meters per pixel in y dimension\n",
    "            ym_per_pix = throwDistanceInMeters / self.projectedY\n",
    "            # meteres per pixel in x dimension (at the base)\n",
    "            xm_per_pix = 3.7 / distance\n",
    "            #\n",
    "            # Use the middle point in the distance of the road instead of the\n",
    "            # base where the car is at\n",
    "            # NOTE:\n",
    "            # since we are using a 1920 pixel throw, 8 seems to be the correct\n",
    "            # divisor now.\n",
    "            ypoint = self.projectedY / 6\n",
    "            fit_cr = np.polyfit(self.allY * ym_per_pix,\n",
    "                                self.currentX * xm_per_pix, 2)\n",
    "            self.radiusOfCurvature = (\n",
    "                (1 + (2 * fit_cr[0] * ypoint +\n",
    "                 fit_cr[1])**2)**1.5) / (2 * fit_cr[0])\n",
    "        return self.radiusOfCurvature\n",
    "\n",
    "    # Define conversion in x off center from pixel space to meters given lane\n",
    "    # line separation in pixels\n",
    "    def meters_from_center_of_vehicle(self, distance):\n",
    "        # meteres per pixel in x dimension given lane line separation in pixels\n",
    "        xm_per_pix = 3.7 / distance\n",
    "        pixels_off_center = int(self.pixelBasePos - (self.projectedX / 2))\n",
    "        self.lineBasePos = xm_per_pix * pixels_off_center\n",
    "        return self.lineBasePos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle\n",
    "\n",
    "Vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Vehicle():\n",
    "\n",
    "    # initialization\n",
    "    def __init__(\n",
    "            self, ID, lanes, projMgr, roadGrid,\n",
    "            objIdx, perspectiveImage, mainLaneIdx):\n",
    "        self.vehIdx = ID\n",
    "        self.vehStr = '%d' % (ID)\n",
    "        self.projMgr = projMgr\n",
    "        self.roadGrid = roadGrid\n",
    "        self.projectedX = projMgr.projectedX\n",
    "        self.projectedY = projMgr.projectedY\n",
    "        self.middle = self.projectedX/2\n",
    "        self.x = projMgr.x\n",
    "        self.y = projMgr.y\n",
    "        self.lanes = lanes\n",
    "        self.mainLaneIdx = mainLaneIdx\n",
    "        self.selfieX = 640\n",
    "        self.selfieY = 240\n",
    "\n",
    "        # special effects\n",
    "        # closing circle sweep\n",
    "        self.sweepDone = False\n",
    "        self.sweepDeltaFrame = 0\n",
    "        # scanning sweep\n",
    "        self.scanDone = False\n",
    "        self.scanDeltaFrame = 0\n",
    "\n",
    "        # this would be the width, height, depth of the vehicle\n",
    "        # if we could see it in birds-eye view\n",
    "        # we will calculate this during 3D reconstruction\n",
    "        self.boundingShape = np.array([0.0, 0.0, 0.0]).astype(np.float32)\n",
    "\n",
    "        # estimated x,y location in birds-eye projected view\n",
    "        self.xcenter = 0\n",
    "        self.ycenter = 0\n",
    "\n",
    "        # estimated initial size 64x64\n",
    "        self.deltaX = 32\n",
    "        self.deltaY = 32\n",
    "\n",
    "        # use the projection manager's estimated height - our z value\n",
    "        self.z = projMgr.z * 1.2\n",
    "\n",
    "        # initial windows during detection\n",
    "        self.lastObjList = roadGrid.getObjectList(objIdx)\n",
    "        self.initialWindows = roadGrid.getObjectListWindows(objIdx)\n",
    "\n",
    "        # windows\n",
    "        self.windows = roadGrid.getFoundAndNotOccludedWindowsInObject(objIdx)\n",
    "\n",
    "        # boxes\n",
    "        self.boxes = roadGrid.getFoundAndNotOccludedBoxesInObject(objIdx)\n",
    "\n",
    "        # lane and location in the voxel grid the vehicle is on\n",
    "        if len(self.boxes) > 0:\n",
    "            self.lane, self.yidx = roadGrid.gridCoordinates(self.boxes[0])\n",
    "            self.box = self.boxes[0]\n",
    "            self.xcenter, self.ycenter = self.windowCenter(\n",
    "                roadGrid.getBoxWindow(self.box))\n",
    "\n",
    "        else:\n",
    "            self.lane = None\n",
    "            self.yidx = None\n",
    "            self.box = None\n",
    "            self.initialMaskVector = None\n",
    "\n",
    "        # was the vehicle detected in the last iteration?\n",
    "        self.detected = False\n",
    "\n",
    "        # percentage confidence\n",
    "        self.detectConfidence = 0.0\n",
    "        self.detectConfidence_base = 0.0\n",
    "        self.initFrames = 0\n",
    "        self.graceFrames = 10\n",
    "        self.exitFrames = 0\n",
    "        self.traveled = False\n",
    "\n",
    "        # contour of vehicle\n",
    "        self.contourInPerspective = None\n",
    "\n",
    "        # mask of vehicle\n",
    "        self.maskedProfile = None\n",
    "        self.vehicleHeatMap = np.zeros(\n",
    "            (self.selfieY, self.selfieX), dtype=np.float32)\n",
    "        self.vehicleMaskInPerspective = None\n",
    "\n",
    "        # vehicle status and statistics\n",
    "        self.vehicleClassified = False\n",
    "        self.color = (0, 0, 0)\n",
    "        self.colorpoints = 0\n",
    "        self.webColorName = None\n",
    "        self.statusColor = None\n",
    "        self.status = \"Not Found\"\n",
    "        self.vehicleInLane = None\n",
    "        self.previousboxes = []\n",
    "\n",
    "        # could be one of:\n",
    "        # DetectionPhase:\n",
    "        #     0:Initialized\n",
    "        #     1:DetectionConfirmed\n",
    "        # TrackingPhase:\n",
    "        #     2:Scanning\n",
    "        #     3:VehicleAcquired\n",
    "        #     4:VehicleLocked\n",
    "        #     5:VehicleOccluded\n",
    "        #     6:VehicleLeaving\n",
    "        #     7:VehicleLosted\n",
    "        self.mode = 0\n",
    "\n",
    "        # array of 3d and 2d points for bounding cube\n",
    "        # do the calculations for the 2d and 3d bounding box\n",
    "        self.cube3d, self.cube2d = \\\n",
    "            self.calculateRoughBoundingCubes(self.windows)\n",
    "\n",
    "        # create the rough masked image for projection.\n",
    "        self.maskVertices, self.maskedImage = \\\n",
    "            self.calculateMask(np.copy(perspectiveImage))\n",
    "\n",
    "        # project the image for verification\n",
    "        self.selfie = self.takeProfileSelfie(self.maskedImage)\n",
    "\n",
    "    # update vehicle status before tracking.\n",
    "    def updateVehicle(\n",
    "            self, roadGrid, perspectiveImage, x=None, y=None, lane=None):\n",
    "        self.roadGrid = roadGrid\n",
    "        if lane is not None:\n",
    "            self.lane = lane\n",
    "\n",
    "        # lane and location in the voxel grid the vehicle is on\n",
    "        if x is not None and y is not None and self.lane is not None:\n",
    "            self.ycenter = y\n",
    "            self.xcenter = self.lanes[self.lane].calculateXCenter(y)\n",
    "            self.window = \\\n",
    "                ((self.xcenter - self.deltaX, self.ycenter - self.deltaY),\n",
    "                 (self.xcenter + self.deltaX, self.ycenter + self.deltaY))\n",
    "            self.windows = [self.window]\n",
    "            if lane is not None:\n",
    "                self.lane = lane\n",
    "            if self.lane is not None:\n",
    "                yidx = self.roadGrid.calculateObjectPosition(\n",
    "                    self.lane, self.ycenter)\n",
    "                if yidx > 0:\n",
    "                    self.yidx = yidx\n",
    "            self.box = self.roadGrid.getKey(self.lane, self.yidx)\n",
    "            self.boxes = [self.box]\n",
    "            self.roadGrid.insertTrackedObject(\n",
    "                self.lane, self.yidx, self.window, self.vehIdx, tracking=True)\n",
    "\n",
    "        elif self.mode > 2 and self.mode < 7:\n",
    "            # for testing without tracking.\n",
    "            # self.ycenter -= 0.5\n",
    "            self.xcenter = self.lanes[self.lane].calculateXCenter(self.ycenter)\n",
    "            self.window = \\\n",
    "                ((self.xcenter - self.deltaX, self.ycenter - self.deltaY),\n",
    "                 (self.xcenter + self.deltaX, self.ycenter + self.deltaY))\n",
    "            self.windows = [self.window]\n",
    "            if lane is not None:\n",
    "                self.lane = lane\n",
    "            if self.lane is not None:\n",
    "                yidx = self.roadGrid.calculateObjectPosition(\n",
    "                    self.lane, self.ycenter)\n",
    "                if yidx > 0:\n",
    "                    self.yidx = yidx\n",
    "            newbox = self.roadGrid.getKey(self.lane, self.yidx)\n",
    "\n",
    "            # save last ten voxels for voxel trigger subpression\n",
    "            if newbox != self.box:\n",
    "                self.previousboxes.insert(0, self.box)\n",
    "                self.previousboxes = self.previousboxes[:10]\n",
    "                self.box = newbox\n",
    "            self.boxes = [self.box]\n",
    "            for oldbox in self.previousboxes:\n",
    "                self.roadGrid.setOccluded(oldbox)\n",
    "            self.roadGrid.insertTrackedObject(\n",
    "                self.lane, self.yidx, self.window, self.vehIdx, tracking=True)\n",
    "\n",
    "        else:\n",
    "            # initial windows during detection\n",
    "            # print(\"self.roadGrid.vehicle_list\",\n",
    "            #       self.vehStr, self.roadGrid.vehicle_list)\n",
    "            if self.vehStr in self.roadGrid.vehicle_list:\n",
    "                self.box = self.roadGrid.vehicle_list[self.vehStr]\n",
    "            else:\n",
    "                self.roadGrid.vehicle_list[self.vehStr] = self.box\n",
    "\n",
    "            # windows\n",
    "            self.windows = \\\n",
    "                self.roadGrid.getFoundAndNotOccludedWindowsInVehicle(\n",
    "                    self.vehIdx)\n",
    "\n",
    "            # boxes\n",
    "            self.boxes = \\\n",
    "                self.roadGrid.getFoundAndNotOccludedBoxesInVehicle(\n",
    "                    self.vehIdx)\n",
    "\n",
    "            if len(self.boxes) > 0:\n",
    "                self.lane, self.yidx = \\\n",
    "                    self.roadGrid.gridCoordinates(self.box)\n",
    "                self.xcenter, self.ycenter = self.windowCenter(\n",
    "                    self.roadGrid.getBoxWindow(self.box))\n",
    "\n",
    "        # was the vehicle detected in the last iteration?\n",
    "        self.detected = True\n",
    "\n",
    "        # This is automatic now.  Voxel will reject if not found.\n",
    "        if self.mode == 0:\n",
    "            self.mode = 1\n",
    "\n",
    "        # array of 3d and 2d points for bounding cube\n",
    "        # do the calculations for the 2d and 3d bounding box\n",
    "        self.cube3d, self.cube2d = \\\n",
    "            self.calculateRoughBoundingCubes(self.windows)\n",
    "\n",
    "        # create the rough masked image for projection.\n",
    "        self.maskVertices, self.maskedImage = \\\n",
    "            self.calculateMask(np.copy(perspectiveImage))\n",
    "\n",
    "        # project the image for verification\n",
    "        self.selfie = self.takeProfileSelfie(self.maskedImage)\n",
    "        return self.roadGrid\n",
    "\n",
    "    # classify the vehicle by its main color components\n",
    "    def closest_colour(self, requested_colour):\n",
    "        min_colours = {}\n",
    "        for key, name in webcolors.css3_hex_to_names.items():\n",
    "            r_c, g_c, b_c = webcolors.hex_to_rgb(key)\n",
    "            rd = (r_c - requested_colour[0]) ** 2\n",
    "            gd = (g_c - requested_colour[1]) ** 2\n",
    "            bd = (b_c - requested_colour[2]) ** 2\n",
    "            min_colours[(rd + gd + bd)] = name\n",
    "        return min_colours[min(min_colours.keys())]\n",
    "\n",
    "    # get a name match for the closest color\n",
    "    def get_colour_name(self, requested_colour):\n",
    "        try:\n",
    "            closest_name = webcolors.rgb_to_name(requested_colour)\n",
    "        except ValueError:\n",
    "            closest_name = self.closest_colour(requested_colour)\n",
    "        return closest_name\n",
    "\n",
    "    def modeColor(self):\n",
    "        # unknown state black\n",
    "        color = (0, 0, 0)\n",
    "\n",
    "        # DetectionPhase:\n",
    "        #     0:Initialized\n",
    "        if self.mode == 0:\n",
    "            # yellow\n",
    "            self.statusColor = (255, 255, 0)\n",
    "            self.status = \"Initializing...\"\n",
    "        #     1:DetectionConfirmed\n",
    "        elif self.mode == 1:\n",
    "            # cyan\n",
    "            self.statusColor = (0, 192, 192)\n",
    "            self.status = \"Detected!\"\n",
    "\n",
    "        # TrackingPhase:\n",
    "        #     2:Scanning\n",
    "        elif self.mode == 2:\n",
    "            # blue\n",
    "            self.statusColor = (0, 0, 255)\n",
    "            self.status = \"Scanning...\"\n",
    "\n",
    "        #     3:VehicleAcquired\n",
    "        elif self.mode == 3:\n",
    "            # white\n",
    "            self.statusColor = (255, 255, 255)\n",
    "            self.status = \"Vehicle Acquired\"\n",
    "\n",
    "        #     4:VehicleLocked\n",
    "        elif self.mode == 4:\n",
    "            # green\n",
    "            self.statusColor = (0, 255, 0)\n",
    "            self.status = \"Vehicle Locked\"\n",
    "\n",
    "        #     5:VehicleOccluded\n",
    "        elif self.mode == 5:\n",
    "            # orange\n",
    "            self.statusColor = (255, 165, 0)\n",
    "            self.status = \"Vehicle Occluded\"\n",
    "\n",
    "        #     6:VehicleLeaving\n",
    "        elif self.mode == 6:\n",
    "            # red\n",
    "            self.statusColor = (255, 0, 0)\n",
    "            self.status = \"Vehicle Leaving...\"\n",
    "\n",
    "        #     7:VehicleLosted\n",
    "        elif self.mode == 6:\n",
    "            # black\n",
    "            self.statusColor = (0, 0, 0)\n",
    "            self.status = \"Vehicle Losted\"\n",
    "\n",
    "        return self.statusColor\n",
    "\n",
    "    def distance(self):\n",
    "        xoffset = (self.middle - self.xcenter)\n",
    "        yoffset = (self.projectedY - self.ycenter)\n",
    "        return np.sqrt(xoffset*xoffset+yoffset*yoffset)\n",
    "\n",
    "    def sortByDistance(self):\n",
    "        return self.distance()\n",
    "\n",
    "    # function to project the undistorted camera image to a plane\n",
    "    # at a side of the vehicle bounding cube - to take a selfie!\n",
    "    def unwarp_vehicle(self, img, src, dst, mtx):\n",
    "        # Pass in your image, 4 source points:\n",
    "        #     src = np.float32([[,],[,],[,],[,]])\n",
    "        # and 4 destination points:\n",
    "        #     dst = np.float32([[,],[,],[,],[,]])\n",
    "        # Note: you could pick any four of the detected corners\n",
    "        # as long as those four corners define a rectangle\n",
    "        # One especially smart way to do this would be to use four well-chosen\n",
    "        # use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "        # use cv2.warpPerspective() to warp your image to a side\n",
    "        # view of vehicle bounding box\n",
    "\n",
    "        self.src2dstM = cv2.getPerspectiveTransform(src, dst)\n",
    "        img_size = (self.selfieX, self.selfieY)\n",
    "        warped = cv2.warpPerspective(\n",
    "            img, self.src2dstM, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "        # warped = gray\n",
    "        return warped, self.src2dstM\n",
    "\n",
    "    # function to project the undistorted camera image to a plane at the side.\n",
    "    # of a vehicle bounding cube - we will use this to project augmentation\n",
    "    # back on to the vehicle.\n",
    "    def unwarp_vehicle_back(self, img, src, dst, mtx):\n",
    "        # Pass in your image, 4 source points:\n",
    "        #     src = np.float32([[,],[,],[,],[,]])\n",
    "        # and 4 destination points:\n",
    "        #     dst = np.float32([[,],[,],[,],[,]])\n",
    "        # Note: you could pick any four of the detected corners\n",
    "        # as long as those four corners define a rectangle\n",
    "        # One especially smart way to do this would be to use four well-chosen\n",
    "        # use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "        # use cv2.warpPerspective() to warp your image to a side\n",
    "        # view of the vehicle bounding box.\n",
    "\n",
    "        self.dst2srcM = cv2.getPerspectiveTransform(src, dst)\n",
    "        img_size = (self.x, self.y)\n",
    "        warped = cv2.warpPerspective(\n",
    "            img, self.dst2srcM, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "        # warped = gray\n",
    "        return warped, self.dst2srcM\n",
    "\n",
    "    # function to find center of projection\n",
    "    def findCenter(self, masked_projection):\n",
    "        try:\n",
    "            points = np.nonzero(masked_projection)\n",
    "            x = int(np.average(points[1]))\n",
    "            y = int(np.average(points[0]))\n",
    "            # print(\"findCenter: \", x, y)\n",
    "        except:\n",
    "            h, w = masked_projection.shape[:2]\n",
    "            x = int(w/2)\n",
    "            y = int(h/2)\n",
    "        return x, y\n",
    "\n",
    "    # function to find center of max color\n",
    "    def findMaxColor(self, masked_projection):\n",
    "        xhistogram = np.sum(masked_projection.astype(np.float32), axis=0)\n",
    "        yhistogram = np.sum(masked_projection.astype(np.float32), axis=1)\n",
    "        x = np.argmax(xhistogram)\n",
    "        y = np.argmax(yhistogram)\n",
    "        # print(\"findMaxColor:\", masked_projection.shape, \"x,y\", x, y)\n",
    "        return x, y\n",
    "\n",
    "    # function to find color of vehicle\n",
    "    def sampleColor(self, img):\n",
    "        # default to black\n",
    "        red = 0\n",
    "        green = 0\n",
    "        blue = 0\n",
    "\n",
    "        # experimental\n",
    "        # get a center patch of the image\n",
    "        # midw, midh = self.findMaxColor(img)\n",
    "        midw, midh = self.findCenter(img)\n",
    "        imgR = img[\n",
    "            midh-20:midh+20,\n",
    "            midw-40:midw+40, 0].astype(np.uint8)\n",
    "        imgG = img[\n",
    "            midh-20:midh+20,\n",
    "            midw-40:midw+40, 1].astype(np.uint8)\n",
    "        imgB = img[\n",
    "            midh-20:midh+20,\n",
    "            midw-40:midw+40, 2].astype(np.uint8)\n",
    "        if imgR.shape[1] > 0 and imgG.shape[1] > 0 and imgB.shape[1] > 0:\n",
    "            red1 = np.min(imgR)\n",
    "            green1 = np.min(imgG)\n",
    "            blue1 = np.min(imgB)\n",
    "            red2 = np.max(imgR)\n",
    "            green2 = np.max(imgG)\n",
    "            blue2 = np.max(imgB)\n",
    "            cv2.circle(img, (midw, midh), 22, (0, 0, 0), 2)\n",
    "            cv2.circle(img, (midw, midh), 24, (255, 255, 255), 2)\n",
    "        else:\n",
    "            # get a center patch of the image\n",
    "            h, w = img.shape[:2]\n",
    "            midh = int(h/2)\n",
    "            midw = int(w/2)\n",
    "            imgR = img[\n",
    "                midh-20:midh+20,\n",
    "                midw-40:midw+40, 0].astype(np.uint8)\n",
    "            imgG = img[\n",
    "                midh-20:midh+20,\n",
    "                midw-40:midw+40, 1].astype(np.uint8)\n",
    "            imgB = img[\n",
    "                midh-20:midh+20,\n",
    "                midw-40:midw+40, 2].astype(np.uint8)\n",
    "            red1 = np.min(imgR)\n",
    "            green1 = np.min(imgG)\n",
    "            blue1 = np.min(imgB)\n",
    "            red2 = np.max(imgR)\n",
    "            green2 = np.max(imgG)\n",
    "            blue2 = np.max(imgB)\n",
    "            cv2.circle(img, (midw, midh), 42, (0, 0, 0), 2)\n",
    "            cv2.circle(img, (midw, midh), 44, (255, 255, 255), 2)\n",
    "\n",
    "        # set the vehicle's color\n",
    "        rgb1 = (red1, green1, blue1)\n",
    "        rgbm = (\n",
    "            int((red1+red2)/2),\n",
    "            int((green1+green2)/2),\n",
    "            int((blue1+blue2)/2))\n",
    "        rgb2 = (red2, green2, blue2)\n",
    "        colorpalet = np.array([[rgb1, rgbm, rgb2]]).reshape(3, 1, 3)\n",
    "        vehicle_grays = \\\n",
    "            cv2.cvtColor(colorpalet.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        if vehicle_grays[2] > 200:\n",
    "            self.vehicle_rgb = rgb2\n",
    "            self.vehicle_gray = vehicle_grays[2]\n",
    "        elif vehicle_grays[1] < 55:\n",
    "            self.vehicle_rgb = rgb1\n",
    "            self.vehicle_gray = vehicle_grays[0]\n",
    "        else:\n",
    "            self.vehicle_rgb = rgbm\n",
    "            self.vehicle_gray = vehicle_grays[1]\n",
    "        self.webColorName = self.get_colour_name(self.vehicle_rgb)\n",
    "\n",
    "    def getTextStats(self):\n",
    "        meterDistance = self.distance() * self.projMgr.pixel2Meter()\n",
    "\n",
    "        # check for bad lane setting\n",
    "        if self.lane is None:\n",
    "            lane = 'Unknown'\n",
    "        else:\n",
    "            lane = '%d' % (self.lane)\n",
    "        if self.box is None:\n",
    "            voxel = 'Unknown'\n",
    "        else:\n",
    "            voxel = ''.join(self.box.split('+'))\n",
    "\n",
    "        text = 'Vehicle %d Visuals:\\n' % (self.vehIdx + 1)\n",
    "        text += 'color: %s\\n' % (self.webColorName)\n",
    "        text += 'Status: %s\\n' % (self.status)\n",
    "        text += 'occupies lane: %s\\n' % (lane)\n",
    "        text += 'tracking voxel: %s\\n' % (voxel)\n",
    "        text += 'tracking distance:\\n'\n",
    "        text += '   %fm' % (meterDistance)\n",
    "        return text\n",
    "\n",
    "    # calculate center of window\n",
    "    def windowCenter(self, window):\n",
    "        x = int((window[0][0] + window[1][0]) / 2)\n",
    "        y = int((window[0][1] + window[1][1]) / 2)\n",
    "        return (x, y)\n",
    "\n",
    "    def vehicleInBox(self, box, roadgrid):\n",
    "        if self.lane is not None:\n",
    "            yidx = self.roadGrid.calculateObjectPosition(\n",
    "                self.lane, self.ycenter)\n",
    "            vehbox = roadgrid.getKey(self.lane, yidx)\n",
    "            if vehbox == box:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def objectIsVehicle(self, boxlist, roadgrid):\n",
    "        if self.box is not None:\n",
    "            if self.box in boxlist:\n",
    "                return True\n",
    "        else:\n",
    "            if self.lane is not None:\n",
    "                yidx = self.roadGrid.calculateObjectPosition(\n",
    "                    self.lane, self.ycenter)\n",
    "                vehbox = roadgrid.getKey(self.lane, yidx)\n",
    "                if vehbox in boxlist:\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    # Augmentation Special Effects -\n",
    "    # default full closing circle sweep takes\n",
    "    # about two seconds 52 frames - video is 26fps\n",
    "    def drawClosingCircle(\n",
    "            self, sweepLane, projectionFX, roadProjection,\n",
    "            color=[0, 0, 255], sweepedcolor=[128, 128, 255],\n",
    "            sweepThick=5, fullsweepFrame=20):\n",
    "        if self.lane == sweepLane:\n",
    "            ccolor = sweepedcolor\n",
    "        else:\n",
    "            ccolor = color\n",
    "        if not self.sweepDone:\n",
    "            # calculate sweep radius\n",
    "            radius = (fullsweepFrame -\n",
    "                      (self.sweepDeltaFrame % fullsweepFrame)) * 10\n",
    "            self.sweepDeltaFrame += 1\n",
    "\n",
    "            # closingCircle sweep\n",
    "            cv2.circle(\n",
    "                projectionFX, (int(self.xcenter), int(self.ycenter)),\n",
    "                radius, ccolor, 10)\n",
    "            cv2.circle(\n",
    "                roadProjection, (int(self.xcenter), int(self.ycenter)),\n",
    "                radius, ccolor, 10)\n",
    "\n",
    "            if self.sweepDeltaFrame == fullsweepFrame:\n",
    "                self.sweepDone = True\n",
    "        else:\n",
    "            if self.mode < 2:\n",
    "                self.mode = 2\n",
    "            radius = self.deltaX*2\n",
    "            cv2.circle(\n",
    "                roadProjection, (int(self.xcenter), int(self.ycenter)),\n",
    "                radius, ccolor, 10)\n",
    "\n",
    "    def calculateRoughBoundingCubes(self, windows):\n",
    "\n",
    "        # need to calculate?\n",
    "        if self.boundingShape[0] == 0:\n",
    "\n",
    "            # yes\n",
    "            height = self.z\n",
    "            nWindows = len(windows)\n",
    "            ymin = 0\n",
    "            xmin = self.projectedX\n",
    "            for i in range(nWindows):\n",
    "                if xmin > windows[i][0][0]:\n",
    "                    xmin = windows[i][0][0]\n",
    "                if ymin < windows[i][0][1]:\n",
    "                    ymin = windows[i][0][1]\n",
    "            xmin += 12\n",
    "            xmax = xmin + 40\n",
    "            ymax = ymin + 100\n",
    "\n",
    "            # set the boundingShape: width, height, depth of the vehicle\n",
    "            self.boundingShape[0] = xmax - xmin\n",
    "            self.boundingShape[1] = ymax - ymin\n",
    "            self.boundingShape[2] = height\n",
    "\n",
    "        # nope!  restore from last estimate\n",
    "        else:\n",
    "            xmin = self.xcenter - self.boundingShape[0]/2\n",
    "            xmax = xmin + self.boundingShape[0]\n",
    "            ymin = self.ycenter - self.boundingShape[1]/2\n",
    "            ymax = ymin + self.boundingShape[1]\n",
    "\n",
    "            # height seems to be non-linear closer to the vanishing point\n",
    "            # attempting to adjust height so that we can still have good\n",
    "            # visual of the tracked vehicle\n",
    "            if self.ycenter < (self.projectedY*0.3):\n",
    "                height = self.boundingShape[2]*1.5\n",
    "            elif self.ycenter < (self.projectedY*0.5):\n",
    "                height = self.boundingShape[2]*1.2\n",
    "            elif self.ycenter < (self.projectedY*0.7):\n",
    "                height = self.boundingShape[2]*1.1\n",
    "            else:\n",
    "                height = self.boundingShape[2]\n",
    "\n",
    "        cube3d = np.float32(\n",
    "            [[xmin, ymin, 0],\n",
    "             [xmax, ymin, 0],\n",
    "             [xmax, ymax, 0],\n",
    "             [xmin, ymax, 0],\n",
    "             [xmin, ymin, height],\n",
    "             [xmax, ymin, height],\n",
    "             [xmax, ymax, height],\n",
    "             [xmin, ymax, height]]).reshape(-1, 3)\n",
    "\n",
    "        cube2d = self.projMgr.projectPoints(cube3d)\n",
    "        cube2d = np.int32(cube2d).reshape(-1, 2)\n",
    "        return cube3d, cube2d\n",
    "\n",
    "    # calculate perspective mask location from birds-eye view\n",
    "    def calculateMask(self, perspectiveImage):\n",
    "        # defining a blank mask to start with\n",
    "        mask = np.zeros_like(perspectiveImage)\n",
    "\n",
    "        # defining a 3 channel or 1 channel color to fill the mask with\n",
    "        # depending on the input image\n",
    "        if len(perspectiveImage.shape) > 2:\n",
    "            # i.e. 3 or 4 depending on your image\n",
    "            channel_count = perspectiveImage.shape[2]\n",
    "            ignore_mask_color = (255,) * channel_count\n",
    "        else:\n",
    "            ignore_mask_color = 255\n",
    "\n",
    "        # right side mask\n",
    "        if self.lane is None or self.lane > self.mainLaneIdx:\n",
    "            # collect the 6 points that matters\n",
    "            # p0, p4, p5, p6, p2, p3\n",
    "            vertices = np.array([[\n",
    "                (self.cube2d[0][0], self.cube2d[0][1]),\n",
    "                (self.cube2d[4][0], self.cube2d[4][1]),\n",
    "                (self.cube2d[5][0], self.cube2d[5][1]),\n",
    "                (self.cube2d[6][0], self.cube2d[6][1]),\n",
    "                (self.cube2d[2][0], self.cube2d[2][1]),\n",
    "                (self.cube2d[3][0], self.cube2d[3][1])]], dtype=np.int32)\n",
    "\n",
    "        # straight ahead mask\n",
    "        elif self.lane == self.mainLaneIdx:\n",
    "            # collect the 4 points that matters\n",
    "            # p7, p6, p2, p3\n",
    "            vertices = np.array([[\n",
    "                (self.cube2d[7][0], self.cube2d[7][1]),\n",
    "                (self.cube2d[6][0], self.cube2d[6][1]),\n",
    "                (self.cube2d[2][0], self.cube2d[2][1]),\n",
    "                (self.cube2d[3][0], self.cube2d[3][1])]], dtype=np.int32)\n",
    "\n",
    "        # left side mask\n",
    "        else:\n",
    "            # collect the 6 points that matters\n",
    "            # p7, p4, p5, p1, p2, p3\n",
    "            vertices = np.array([[\n",
    "                (self.cube2d[7][0], self.cube2d[7][1]),\n",
    "                (self.cube2d[4][0], self.cube2d[4][1]),\n",
    "                (self.cube2d[5][0], self.cube2d[5][1]),\n",
    "                (self.cube2d[1][0], self.cube2d[1][1]),\n",
    "                (self.cube2d[2][0], self.cube2d[2][1]),\n",
    "                (self.cube2d[3][0], self.cube2d[3][1])]], dtype=np.int32)\n",
    "\n",
    "        # print(\"vertices\", vertices)\n",
    "        # print(\"mask\", mask.shape)\n",
    "        # print(\"ignore_mask_color\", ignore_mask_color)\n",
    "\n",
    "        # filling pixels inside the polygon defined by\n",
    "        # \"vertices\" with the fill color\n",
    "        cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "        # returning the image only where mask pixels are nonzero\n",
    "        maskedImage = cv2.bitwise_and(perspectiveImage, mask)\n",
    "        return vertices, maskedImage\n",
    "\n",
    "    def draw3DBoundingCube(self, perspectiveImage):\n",
    "        # draw bottom of cube\n",
    "        cv2.drawContours(\n",
    "            perspectiveImage, [self.cube2d[:4]], -1, self.statusColor, 2)\n",
    "        # draw sides of cube\n",
    "        for i, j in zip(range(4), range(4, 8)):\n",
    "            cv2.line(\n",
    "                perspectiveImage,\n",
    "                tuple(self.cube2d[i]), tuple(self.cube2d[j]),\n",
    "                self.statusColor, 2)\n",
    "        # draw top of cube\n",
    "        cv2.drawContours(\n",
    "            perspectiveImage, [self.cube2d[4:]], -1, self.statusColor, 2)\n",
    "\n",
    "    # Augmentation Special Effects\n",
    "    # - default vehicle scanning sweep takes less\n",
    "    # than a second 20 frames - video is 26fps\n",
    "    def drawScanning(\n",
    "            self, projectionFX, roadProjection,\n",
    "            color=[0, 0, 255], sweepThick=2, fullsweepFrame=26):\n",
    "\n",
    "        if self.sweepDone and not self.scanDone:\n",
    "            # calculate scanning height\n",
    "            height = self.scanDeltaFrame\n",
    "            window = self.roadGrid.getBoxWindow(self.box)\n",
    "            be_cube = np.float32(\n",
    "                [[window[0][0], window[0][1], height],\n",
    "                 [window[1][0], window[0][1], height],\n",
    "                 [window[1][0], window[1][1], height],\n",
    "                 [window[0][0], window[1][1], height],\n",
    "                 [window[0][0], window[0][1], height + 1],\n",
    "                 [window[1][0], window[0][1], height + 1],\n",
    "                 [window[1][0], window[1][1], height + 1],\n",
    "                 [window[0][0], window[1][1], height + 1]])\n",
    "            cube = self.projMgr.projectPoints(\n",
    "                be_cube.reshape(-1, 3))\n",
    "            imgpts = np.int32(cube).reshape(-1, 2)\n",
    "\n",
    "            # draw bottom of cube\n",
    "            cv2.drawContours(\n",
    "                projectionFX, [imgpts[:4]],\n",
    "                -1, (0, 0, 255), 3)\n",
    "            cv2.drawContours(\n",
    "                roadProjection, [imgpts[:4]],\n",
    "                -1, (0, 0, 255), 3)\n",
    "            # draw top of cube\n",
    "            cv2.drawContours(\n",
    "                projectionFX, [imgpts[4:]],\n",
    "                -1, (128, 128, 255), 3)\n",
    "            cv2.drawContours(\n",
    "                roadProjection, [imgpts[4:]],\n",
    "                -1, (128, 128, 255), 3)\n",
    "\n",
    "            # check if done.\n",
    "            self.scanDeltaFrame += 1\n",
    "            if height > fullsweepFrame:\n",
    "                self.scanDone = True\n",
    "                if self.mode < 3:\n",
    "                    self.mode = 3\n",
    "        elif self.sweepDone and self.scanDone:\n",
    "            if self.mode < 3:\n",
    "                self.mode = 3\n",
    "            self.draw3DBoundingCube(projectionFX)\n",
    "\n",
    "    def takeProfileSelfie(self, perspectiveImage, newheightFactor=1.0):\n",
    "        # give up if we are not sure which lane we are on\n",
    "        # if it is a bad detect the vehicle tracking module will reject it\n",
    "        if self.lane is None:\n",
    "            # generate an empty cube intersect\n",
    "            self.cube_intersect = np.float32([])\n",
    "            # generate an empty mask profile\n",
    "            # self.maskedProfile = np.array(\n",
    "            #     (self.selfieY, self.selfieX), dtype=np.uint8)\n",
    "            # return an empty vehicle image\n",
    "            projected_carImage = np.array(\n",
    "                (self.selfieY, self.selfieX, 3), dtype=np.uint8)\n",
    "            cv2.rectangle(\n",
    "                projected_carImage, (5, 5), (635, 235), self.statusColor, 5)\n",
    "            return projected_carImage\n",
    "\n",
    "        # for debugging and diagnostics without vehicle tracker\n",
    "        # if self.mode == 3:\n",
    "        #     self.ycenter -= 0.35\n",
    "\n",
    "        # calculate the plane for selfie\n",
    "        height = self.boundingShape[2]*newheightFactor\n",
    "\n",
    "        # if we are looking at it straight ahead - in the same lane\n",
    "        if self.lane == self.mainLaneIdx:\n",
    "            ymin = self.ycenter\n",
    "            ymax = self.ycenter\n",
    "            x1 = self.lanes[self.lane].calculateXCenter(ymin) - self.deltaX\n",
    "            x2 = self.lanes[self.lane].calculateXCenter(ymax) + self.deltaX\n",
    "\n",
    "        # we are looking at it from an angle - different lane\n",
    "        else:\n",
    "            ymin = self.ycenter - self.deltaY*2\n",
    "            ymax = self.ycenter + self.deltaY*3\n",
    "            x1 = self.lanes[self.lane].calculateXCenter(ymin) - self.deltaX*1.5\n",
    "            x2 = self.lanes[self.lane].calculateXCenter(ymax) + self.deltaX*1.5\n",
    "\n",
    "        # slice into the middle of the cube\n",
    "        if self.lane >= self.mainLaneIdx:\n",
    "            # perpendicular from our view port from the left or straight ahead\n",
    "            cube_intersect = np.float32(\n",
    "                [[x1, ymin, 0],\n",
    "                 [x1, ymin, height],\n",
    "                 [x2, ymax, height],\n",
    "                 [x2, ymax, 0]]).reshape(-1, 3)\n",
    "\n",
    "            # put it here in case we need to change it for left\n",
    "            # set up cross section projection destination\n",
    "            dstVehicleCorners = np.float32([\n",
    "                [-200, 195], [-200, 35],\n",
    "                [self.selfieX+200, 35], [self.selfieX+200, 195]])\n",
    "\n",
    "        else:\n",
    "            # perpendicular from our view port from the right\n",
    "            cube_intersect = np.float32(\n",
    "                [[x1, ymax, 0],\n",
    "                 [x1, ymax, height],\n",
    "                 [x2, ymin, height],\n",
    "                 [x2, ymin, 0]]).reshape(-1, 3)\n",
    "\n",
    "            # put it here in case we need to change it for right\n",
    "            # set up cross section projection destination\n",
    "            dstVehicleCorners = np.float32([\n",
    "                [-200, 195], [-200, 35],\n",
    "                [self.selfieX+200, 35], [self.selfieX+200, 195]])\n",
    "\n",
    "        cube_intersect = self.projMgr.projectPoints(cube_intersect)\n",
    "        self.cube_intersect = np.int32(cube_intersect).reshape(-1, 2)\n",
    "\n",
    "        # project the car image\n",
    "        projected_carImage, M = self.unwarp_vehicle(\n",
    "            np.copy(perspectiveImage), cube_intersect.astype(np.float32),\n",
    "            dstVehicleCorners, self.projMgr.mtx)\n",
    "\n",
    "        # generate stats\n",
    "        if self.mode < 3:\n",
    "            self.sampleColor(projected_carImage)\n",
    "        self.modeColor()\n",
    "\n",
    "        # genrate mask from detected color\n",
    "        self.maskedProfile = cv2.cvtColor(\n",
    "            projected_carImage, cv2.COLOR_RGB2GRAY)\n",
    "        self.maskedProfile = self.maskedProfile.astype(np.uint8)\n",
    "\n",
    "        # print(\"self.vehicle_gray\", self.vehicle_gray)\n",
    "        if self.vehicle_gray > 224:\n",
    "            self.maskedProfile[\n",
    "                (self.maskedProfile < (self.vehicle_gray - 48))] = 0\n",
    "            self.maskedProfile[(self.maskedProfile > 0)] = 255\n",
    "        elif self.vehicle_gray < 64:\n",
    "            self.maskedProfile[(self.maskedProfile == 0)] = 128\n",
    "            self.maskedProfile = 255 - self.maskedProfile\n",
    "            self.maskedProfile[\n",
    "                (self.maskedProfile < (255-(self.vehicle_gray)))] = 0\n",
    "            self.maskedProfile[(self.maskedProfile > 0)] = 255\n",
    "        elif self.vehicle_gray > 192:\n",
    "            self.maskedProfile[\n",
    "                (self.maskedProfile < (self.vehicle_gray - 24))] = 0\n",
    "            self.maskedProfile[\n",
    "                (self.maskedProfile > (self.vehicle_gray + 24))] = 0\n",
    "            self.maskedProfile[(self.maskedProfile > 0)] = 255\n",
    "        elif self.vehicle_gray > 128:\n",
    "            self.maskedProfile[\n",
    "                (self.maskedProfile < (self.vehicle_gray - 24))] = 0\n",
    "            self.maskedProfile[\n",
    "                (self.maskedProfile > (self.vehicle_gray + 24))] = 0\n",
    "            self.maskedProfile[(self.maskedProfile > 0)] = 255\n",
    "        elif self.vehicle_gray > 96:\n",
    "            self.maskedProfile[\n",
    "                (self.maskedProfile < (self.vehicle_gray - 24))] = 0\n",
    "            self.maskedProfile[\n",
    "                (self.maskedProfile > (self.vehicle_gray + 24))] = 0\n",
    "            self.maskedProfile[(self.maskedProfile > 0)] = 255\n",
    "        elif self.vehicle_gray > 64:\n",
    "            self.maskedProfile[\n",
    "                (self.maskedProfile < (self.vehicle_gray - 24))] = 0\n",
    "            self.maskedProfile[\n",
    "                (self.maskedProfile > (self.vehicle_gray + 24))] = 0\n",
    "            self.maskedProfile[(self.maskedProfile > 0)] = 255\n",
    "        elif self.vehicle_gray > 32:\n",
    "            self.maskedProfile[\n",
    "                (self.maskedProfile < (self.vehicle_gray - 16))] = 0\n",
    "            self.maskedProfile[\n",
    "                (self.maskedProfile > (self.vehicle_gray + 16))] = 0\n",
    "            self.maskedProfile[(self.maskedProfile > 0)] = 255\n",
    "        else:\n",
    "            self.maskedProfile[\n",
    "                (self.maskedProfile > (self.vehicle_gray + 16))] = 0\n",
    "            self.maskedProfile[(self.maskedProfile > 0)] = 255\n",
    "\n",
    "        try:\n",
    "            if self.mode < 3:\n",
    "                points = np.nonzero(self.maskedProfile)\n",
    "                if len(points[0]) > self.colorpoints:\n",
    "                    self.color = self.vehicle_rgb\n",
    "                    self.gray = self.vehicle_gray\n",
    "                else:\n",
    "                    self_vehicle_rgb = self.color\n",
    "                    self.vehicle_gray = self.gray\n",
    "        except:\n",
    "            self_vehicle_rgb = self.color\n",
    "            self.vehicle_gray = self.gray\n",
    "\n",
    "        # get the contour of the vehicle from the mask\n",
    "        img2, self.contours, hierarchy = cv2.findContours(\n",
    "            self.maskedProfile, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        edges = np.copy(self.maskedProfile)*0\n",
    "\n",
    "        # draw a filled contour for our mask\n",
    "        cv2.drawContours(edges, self.contours, -1, 255, -1)\n",
    "\n",
    "        # return np.dstack((edges, edges, edges))\n",
    "\n",
    "        # mask our image\n",
    "        # projected_carImage = cv2.bitwise_and(\n",
    "        #     projected_carImage, projected_carImage,\n",
    "        #     mask=self.maskedProfile)\n",
    "\n",
    "        # draw the contours on top\n",
    "        cv2.drawContours(\n",
    "            projected_carImage, self.contours, -1, self.statusColor, 2)\n",
    "        vehicle_contour = np.copy(projected_carImage) * 0\n",
    "        cv2.drawContours(\n",
    "            vehicle_contour, self.contours, -1, self.statusColor, 2)\n",
    "\n",
    "        # draw our tracking points\n",
    "        # projected_carImage[:,0:50] = [128, 64, 64]\n",
    "        # projected_carImage[:,self.selfieX-50:self.selfieX] = [128, 64, 64]\n",
    "\n",
    "        cv2.rectangle(\n",
    "            projected_carImage, (5, 5), (635, 235), self.statusColor, 5)\n",
    "\n",
    "        # unwarp the car mask\n",
    "        self.contourInPerspective, M = self.unwarp_vehicle_back(\n",
    "            vehicle_contour, dstVehicleCorners,\n",
    "            self.cube_intersect.astype(np.float32), self.projMgr.mtx)\n",
    "\n",
    "        # debugging masks...\n",
    "        # newedge = np.dstack((edges, edges, edges))\n",
    "        # cv2.drawContours(\n",
    "        #     newedge, self.contours, -1, self.statusColor, 2)\n",
    "        # cv2.rectangle(\n",
    "        #     newedge, (5, 5), (635, 235), self.statusColor, 5)\n",
    "        # return newedge\n",
    "        return projected_carImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle Tracking\n",
    "\n",
    "Vehicle Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VehicleTracking():\n",
    "\n",
    "    # initialize\n",
    "    def __init__(\n",
    "            self, x, y, projectedX, projectedY, lanes):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.projectedX = projectedX\n",
    "        self.projectedY = projectedY\n",
    "        self.lanes = lanes\n",
    "\n",
    "    def isVehicleThere(\n",
    "            self, perspectiveImage, roadGrid, mainLaneIdx, vehicles, vehIdx):\n",
    "        # something is wrong - we should not have a vehicle in this state\n",
    "        # with a maskedProfile that is not there!\n",
    "        # reject the vehicle\n",
    "        if vehicles[vehIdx] is None:\n",
    "            # print(\"rejecting \", vehIdx, \"has has no entry in vehicles array\")\n",
    "            return False\n",
    "\n",
    "        if vehicles[vehIdx].maskedProfile is None:\n",
    "            # print(\"rejecting \", vehIdx, \"has no maskedProfile\")\n",
    "            return False\n",
    "\n",
    "        masked_vehicle = vehicles[vehIdx].maskedProfile\n",
    "        vehicle_points = len(np.nonzero(masked_vehicle)[0])\n",
    "        midw, midh = vehicles[vehIdx].findCenter(masked_vehicle)\n",
    "        # print(\"mode: \", vehicles[vehIdx].mode, \" tracking:\", vehIdx)\n",
    "\n",
    "        # initialization?\n",
    "        if vehicles[vehIdx].mode < 3:\n",
    "\n",
    "            # collect points counts\n",
    "            vehicles[vehIdx].detectConfidence_base += vehicle_points\n",
    "            vehicles[vehIdx].initFrames += 1\n",
    "\n",
    "            # calculate running confidence for quick elimination\n",
    "            # during peer scan pruning\n",
    "            vehicles[vehIdx].confidence = \\\n",
    "                vehicle_points / (\n",
    "                    vehicles[vehIdx].detectConfidence_base /\n",
    "                    vehicles[vehIdx].initFrames)\n",
    "\n",
    "            # merge masks into heatmaps\n",
    "            if masked_vehicle is not None:\n",
    "                vehicles[vehIdx].vehicleHeatMap = \\\n",
    "                    vehicles[vehIdx].projMgr.curImgFtr.miximg(\n",
    "                        vehicles[vehIdx].vehicleHeatMap,\n",
    "                        masked_vehicle, 0.5, 0.1)\n",
    "\n",
    "            # return true until we get out of the scanning phase\n",
    "            # print(\n",
    "            #     \"mode: \", vehicles[vehIdx].mode, \" tracking:\", vehIdx,\n",
    "            #     \"confidence base: \", vehicles[vehIdx].detectConfidence_base,\n",
    "            #     \"current confidence:\", vehicles[vehIdx].confidence)\n",
    "            return True\n",
    "\n",
    "        # scanning done - need to set confidence and start tracking.\n",
    "        # if pasted threshold - make sure we actually have a confiremd vehicle!\n",
    "        elif vehicles[vehIdx].mode == 3:\n",
    "            vehicles[vehIdx].detectConfidence_base /= \\\n",
    "                vehicles[vehIdx].initFrames\n",
    "            # print(\n",
    "            #     \"mode: \", vehicles[vehIdx].mode, \" tracking:\", vehIdx,\n",
    "            #     \"confidence base: \", vehicles[vehIdx].detectConfidence_base,\n",
    "            #     \"current confidence:\", vehicles[vehIdx].confidence)\n",
    "            if vehicles[vehIdx].detectConfidence_base > 100:\n",
    "                # calculate confident\n",
    "                vehicles[vehIdx].confidence = \\\n",
    "                    vehicle_points / vehicles[vehIdx].detectConfidence_base\n",
    "                if vehicles[vehIdx].confidence > 0.5:\n",
    "                    # set found\n",
    "                    vehicles[vehIdx].detected = True\n",
    "\n",
    "                    # set start of tracking...\n",
    "                    vehicles[vehIdx].mode = 4\n",
    "                    # print(\"new mode: \", vehicles[vehIdx].mode,\n",
    "                    #       \" tracking:\", vehIdx)\n",
    "                    return True\n",
    "\n",
    "                # low confidence...\n",
    "                else:\n",
    "                    # give up and drop it - must be a false-positive\n",
    "                    vehicles[vehIdx].detected = False\n",
    "                    vehicles[vehIdx].mode = 7\n",
    "                    # print(\"new mode: \", vehicles[vehIdx].mode,\n",
    "                    #       \" tracking:\", vehIdx)\n",
    "                    return False\n",
    "\n",
    "            # can't find it at all!\n",
    "            else:\n",
    "                # give up and drop it - must be a false-positive\n",
    "                vehicles[vehIdx].detected = False\n",
    "                vehicles[vehIdx].mode = 7\n",
    "                # print(\"new mode: \", vehicles[vehIdx].mode,\n",
    "                #       \" tracking:\", vehIdx)\n",
    "                return False\n",
    "\n",
    "        # tracking mode - need to check confidence.\n",
    "        elif vehicles[vehIdx].mode == 4:\n",
    "            # print(\n",
    "            #     \"mode: \", vehicles[vehIdx].mode, \" tracking:\", vehIdx,\n",
    "            #     \"confidence base: \", vehicles[vehIdx].detectConfidence_base,\n",
    "            #     \"current confidence:\", vehicles[vehIdx].confidence)\n",
    "            # check for occlusion!\n",
    "            if roadGrid.isOccluded(vehicles[vehIdx].box):\n",
    "                # reduce confidence base during this crisis\n",
    "                # and set grace frame to 50\n",
    "                vehicles[vehIdx].detectConfidence_base /= 4\n",
    "                vehicles[vehIdx].graceFrame = 50\n",
    "                vehicles[vehIdx].mode = 5\n",
    "                # print(\n",
    "                #     \"new mode: \", vehicles[vehIdx].mode,\n",
    "                #     \" tracking:\", vehIdx)\n",
    "                return True\n",
    "\n",
    "            # check the counts against confidence\n",
    "            # drop the vehicle to scanning if we are not 50% confident\n",
    "            vehicles[vehIdx].confidence = \\\n",
    "                vehicle_points / vehicles[vehIdx].detectConfidence_base\n",
    "            if vehicles[vehIdx].confidence < 0.5 and \\\n",
    "               vehicles[vehIdx].graceFrame == 0:\n",
    "                vehicles[vehIdx].detected = False\n",
    "                vehicles[vehIdx].mode = 2\n",
    "                # print(\n",
    "                #   \"new mode: \", vehicles[vehIdx].mode, \" tracking:\", vehIdx,\n",
    "                #   \"confidence base:\", vehicles[vehIdx].detectConfidence_base,\n",
    "                #   \"current confidence:\", vehicles[vehIdx].confidence)\n",
    "                return False\n",
    "            elif vehicles[vehIdx].confidence < 0.5:\n",
    "                # ten graceFrame to get back our confidence\n",
    "                vehicles[vehIdx].graceFrame -= 1\n",
    "                # print(\n",
    "                #     \"new grace:\", vehicles[vehIdx].graceFrame,\n",
    "                #     \"tracking:\", vehIdx)\n",
    "                vehicles[vehIdx].takeProfileSelfie(perspectiveImage, 2.0)\n",
    "            elif vehicles[vehIdx].confidence > 0.5:\n",
    "                vehicles[vehIdx].graceFrame = 10\n",
    "                # print(\n",
    "                #     \"new grace:\", vehicles[vehIdx].graceFrame,\n",
    "                #     \"tracking:\", vehIdx)\n",
    "\n",
    "            # get some info on how far shifted is the car image\n",
    "            shift = int(vehicles[vehIdx].selfieX/2) - midw\n",
    "            laneIdx = vehicles[vehIdx].lane\n",
    "\n",
    "            # check direction of travel\n",
    "            # shift would be positive for right and negative for left\n",
    "            #    if travel is forward\n",
    "            # shift would be negative for right and positive for left\n",
    "            #    if travel is backward\n",
    "            if ((shift > 3 and laneIdx > mainLaneIdx) or\n",
    "                    (shift < -3 and laneIdx < mainLaneIdx)):\n",
    "                # forward travel - compensate\n",
    "                # increment center y as a delta percentage\n",
    "                delta = np.absolute(shift)/60.0\n",
    "                # print(\"shift:\", shift, \"moving vehicle\", vehIdx,\n",
    "                #       \"old position\", vehicles[vehIdx].ycenter,\n",
    "                #       \"new position\", vehicles[vehIdx].ycenter - delta,\n",
    "                #       \"decrement by\", delta)\n",
    "                vehicles[vehIdx].ycenter -= delta\n",
    "\n",
    "                if vehicles[vehIdx].ycenter < 1500.0:\n",
    "                    vehicles[vehIdx].traveled = True\n",
    "\n",
    "                # vehicle leaving?\n",
    "                if vehicles[vehIdx].ycenter < 200:\n",
    "                    vehicles[vehIdx].mode = 6\n",
    "                    # print(\"new mode: \", vehicles[vehIdx].mode,\n",
    "                    #       \" tracking:\", vehIdx)\n",
    "\n",
    "            if ((shift < -3 and laneIdx > mainLaneIdx) or\n",
    "                    (shift > 3 and laneIdx < mainLaneIdx)):\n",
    "                # backward travel - compensate\n",
    "                # decrement center y as a delta percentage\n",
    "                # going backward needs to be faster it seems\n",
    "                delta = np.absolute(shift)/15.0\n",
    "                # print(\"shift: \", shift, \"moving vehicle\", vehIdx,\n",
    "                #       \"old position\", vehicles[vehIdx].ycenter,\n",
    "                #       \"new position\", vehicles[vehIdx].ycenter - delta,\n",
    "                #       \"increment by\", delta)\n",
    "                vehicles[vehIdx].ycenter += delta\n",
    "\n",
    "                # vehicle leaving?\n",
    "                laneIdx = vehicles[vehIdx].lane\n",
    "                if vehicles[vehIdx].ycenter > self.lanes[laneIdx].bottomY():\n",
    "                    if vehicles[vehIdx].traveled:\n",
    "                        vehicles[vehIdx].mode = 6\n",
    "                        # print(\n",
    "                        #     \"new mode: \", vehicles[vehIdx].mode,\n",
    "                        #     \"tracking:\", vehIdx)\n",
    "\n",
    "            # returning from mode == 4\n",
    "            return True\n",
    "\n",
    "        # occluded - need to check if we are out of occlusion\n",
    "        elif vehicles[vehIdx].mode == 5:\n",
    "            # print(\n",
    "            #     \"mode: \", vehicles[vehIdx].mode, \" tracking:\", vehIdx,\n",
    "            #     \"confidence base: \", vehicles[vehIdx].detectConfidence_base,\n",
    "            #     \"current confidence:\", vehicles[vehIdx].confidence)\n",
    "            # check for occlusion!\n",
    "            if not roadGrid.isOccluded(vehicles[vehIdx].box):\n",
    "                vehicles[vehIdx].mode = 4\n",
    "                # print(\"new mode: \", vehicles[vehIdx].mode,\n",
    "                #       \" tracking:\", vehIdx)\n",
    "                return True\n",
    "\n",
    "            # check the counts against confidence\n",
    "            # drop the vehicle to scanning if we are not 50% confident\n",
    "            vehicles[vehIdx].confidence = \\\n",
    "                vehicle_points / vehicles[vehIdx].detectConfidence_base\n",
    "            if vehicles[vehIdx].confidence < 0.5 and \\\n",
    "               vehicles[vehIdx].graceFrame == 0:\n",
    "                vehicles[vehIdx].detected = False\n",
    "                vehicles[vehIdx].mode = 2\n",
    "                # print(\n",
    "                #   \"new mode:\", vehicles[vehIdx].mode, \" tracking:\", vehIdx,\n",
    "                #   \"confidence base:\", vehicles[vehIdx].detectConfidence_base,\n",
    "                #   \"current confidence:\", vehicles[vehIdx].confidence)\n",
    "                return False\n",
    "            elif vehicles[vehIdx].confidence < 0.5:\n",
    "                # ten graceFrame to get back our confidence\n",
    "                vehicles[vehIdx].graceFrame -= 1\n",
    "                # print(\n",
    "                #     \"new grace:\", vehicles[vehIdx].graceFrame,\n",
    "                #     \"tracking:\", vehIdx)\n",
    "                vehicles[vehIdx].takeProfileSelfie(perspectiveImage, 2.0)\n",
    "            elif vehicles[vehIdx].confidence > 0.5:\n",
    "                vehicles[vehIdx].graceFrame = 50\n",
    "                # print(\n",
    "                #     \"new grace:\", vehicles[vehIdx].graceFrame,\n",
    "                #     \"tracking:\", vehIdx)\n",
    "\n",
    "            # get some info on how far shifted is the car image\n",
    "            shift = int(vehicles[vehIdx].selfieX/2) - midw\n",
    "            laneIdx = vehicles[vehIdx].lane\n",
    "\n",
    "            # check direction of travel\n",
    "            # shift would be positive for right and negative for left\n",
    "            #    if travel is forward\n",
    "            # shift would be negative for right and positive for left\n",
    "            #    if travel is backward\n",
    "            if ((shift > 3 and laneIdx > mainLaneIdx) or\n",
    "                    (shift < -3 and laneIdx < mainLaneIdx)):\n",
    "                # forward travel - compensate\n",
    "                # increment center y as a delta percentage\n",
    "                delta = np.absolute(shift)/60.0\n",
    "                # print(\n",
    "                #     \"shift: \", shift, \"moving vehicle\", vehIdx,\n",
    "                #     \"old position\", vehicles[vehIdx].ycenter,\n",
    "                #     \"new position\", vehicles[vehIdx].ycenter - delta,\n",
    "                #     \"decrement by\", delta)\n",
    "                vehicles[vehIdx].ycenter -= delta\n",
    "\n",
    "                if vehicles[vehIdx].ycenter < 1500.0:\n",
    "                    vehicles[vehIdx].traveled = True\n",
    "\n",
    "                # vehicle leaving?\n",
    "                if vehicles[vehIdx].ycenter < 200:\n",
    "                    vehicles[vehIdx].mode = 6\n",
    "                    # print(\"new mode: \", vehicles[vehIdx].mode,\n",
    "                    #       \" tracking:\", vehIdx)\n",
    "\n",
    "            if ((shift < -3 and laneIdx > mainLaneIdx) or\n",
    "                    (shift > 3 and laneIdx < mainLaneIdx)):\n",
    "                # backward travel - compensate\n",
    "                # decrement center y as a delta percentage\n",
    "                # going backward needs to be faster it seems\n",
    "                delta = np.absolute(shift)/15.0\n",
    "                # print(\"shift: \", shift, \"moving vehicle\", vehIdx,\n",
    "                #       \"old position\", vehicles[vehIdx].ycenter,\n",
    "                #       \"new position\", vehicles[vehIdx].ycenter - delta,\n",
    "                #       \"increment by\", delta)\n",
    "                vehicles[vehIdx].ycenter += delta\n",
    "\n",
    "                # vehicle leaving?\n",
    "                laneIdx = vehicles[vehIdx].lane\n",
    "                if vehicles[vehIdx].ycenter > self.lanes[laneIdx].bottomY():\n",
    "                    if vehicles[vehIdx].traveled:\n",
    "                        vehicles[vehIdx].mode = 6\n",
    "                        # print(\"new mode: \", vehicles[vehIdx].mode,\n",
    "                        #       \" tracking:\", vehIdx)\n",
    "\n",
    "            # returning from mode == 5\n",
    "            return True\n",
    "\n",
    "        # vehicle leaving the scene\n",
    "        elif vehicles[vehIdx].mode == 6:\n",
    "            # set timer for 26 frames (1 second) and then drop the vehicle\n",
    "            vehicles[vehIdx].exitFrames += 1\n",
    "            if vehicles[vehIdx].exitFrames > 170:\n",
    "                vehicles[vehIdx].detected = False\n",
    "                vehicles[vehIdx].mode = 7\n",
    "                # print(\"new mode: \", vehicles[vehIdx].mode,\n",
    "                #       \" tracking:\", vehIdx)\n",
    "                return False\n",
    "            else:\n",
    "                vehicles[vehIdx].ycenter += 0.40\n",
    "                return True\n",
    "\n",
    "        # vehicle losted (no tracking)\n",
    "        elif vehicles[vehIdx].mode == 7:\n",
    "            # print(\"new mode: \", vehicles[vehIdx].mode,\n",
    "            #       \" tracking:\", vehIdx)\n",
    "            return False\n",
    "\n",
    "        # unknown state - return False\n",
    "        else:\n",
    "            # print(\"unknown mode: \", vehicles[vehIdx].mode,\n",
    "            #       \" tracking:\", vehIdx)\n",
    "            return False\n",
    "\n",
    "        # fell out - default False\n",
    "        # print(\"fellout mode: \", vehicles[vehIdx].mode, \" tracking:\", vehIdx)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle Detection\n",
    "\n",
    "Vehicle Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VehicleDetection():\n",
    "    # initialize\n",
    "    def __init__(self, projectedX, projectedY, versionName=None,\n",
    "                 cspace='RGB', orient=9, pix_per_cell=8, cell_per_block=2,\n",
    "                 hog_channel=0, threshold=2.5,\n",
    "                 dataFileNamePattern=\"imgExt%03d.jpg\"):\n",
    "        self.start = time.strftime(\"%Y%m%d%H%M%S\", time.gmtime())\n",
    "        self.projectedX = projectedX\n",
    "        self.projectedY = projectedY\n",
    "        self.versionName = versionName\n",
    "        self.cspace = cspace\n",
    "        self.hog_channel = hog_channel\n",
    "        if versionName is not None:\n",
    "            self.trained_model = './trained/' + versionName + '.pkl'\n",
    "            self.trained_scalar = './trained/scaler' + versionName + '.pkl'\n",
    "            self.svc = joblib.load(self.trained_model)\n",
    "        self.orient = orient\n",
    "        self.pix_per_cell = pix_per_cell\n",
    "        self.cell_per_block = cell_per_block\n",
    "        if self.trained_scalar is not None and \\\n",
    "                self.versionName is not None:\n",
    "            self.X_scaler = joblib.load(self.trained_scalar)\n",
    "        self.threshold = threshold\n",
    "        self.dataFileNamePattern = dataFileNamePattern\n",
    "\n",
    "    # Define a function to change the detector's threshold\n",
    "    def set_threshold(self, new_threshold):\n",
    "        self.threshold = new_threshold\n",
    "\n",
    "    # Define a function to compute binned color features\n",
    "    def bin_spatial(self, img, size=(32, 32)):\n",
    "        # Use cv2.resize().ravel() to create the feature vector\n",
    "        features = cv2.resize(img, size).ravel()\n",
    "        # Return the feature vector\n",
    "        return features\n",
    "\n",
    "    # Define a function to compute color histogram features\n",
    "    def color_hist(self, img, nbins=32, bins_range=(0, 256)):\n",
    "        # Compute the histogram of the color channels separately\n",
    "        channel1_hist = np.histogram(\n",
    "            img[:, :, 0], bins=nbins, range=bins_range)\n",
    "        channel2_hist = np.histogram(\n",
    "            img[:, :, 1], bins=nbins, range=bins_range)\n",
    "        channel3_hist = np.histogram(\n",
    "            img[:, :, 2], bins=nbins, range=bins_range)\n",
    "        # Concatenate the histograms into a single feature vector\n",
    "        hist_features = np.concatenate(\n",
    "            (channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "        # Return the individual histograms, bin_centers and feature vector\n",
    "        return hist_features\n",
    "\n",
    "    # Define a function to return HOG features and visualization\n",
    "    def get_hog_features(self, img, orient, pix_per_cell, cell_per_block,\n",
    "                         vis=False, feature_vec=True):\n",
    "        # Call with two outputs if vis==True\n",
    "        if vis:\n",
    "            features, hog_image = hog(\n",
    "                img, orientations=orient,\n",
    "                pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                cells_per_block=(cell_per_block, cell_per_block),\n",
    "                transform_sqrt=True,\n",
    "                visualise=vis, feature_vector=feature_vec)\n",
    "            return features, hog_image\n",
    "        # Otherwise call with one output\n",
    "        else:\n",
    "            features = hog(\n",
    "                img, orientations=orient,\n",
    "                pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                cells_per_block=(cell_per_block, cell_per_block),\n",
    "                transform_sqrt=True, visualise=vis,\n",
    "                feature_vector=feature_vec)\n",
    "            return features\n",
    "\n",
    "    # Define a function to extract features from a list of images\n",
    "    # Have this function call bin_spatial() and color_hist()\n",
    "    def extract_features(self, image, cspace='RGB', spatial_size=(32, 32),\n",
    "                         hist_bins=32, hist_range=(0, 256), orient=9,\n",
    "                         pix_per_cell=8, cell_per_block=2, hog_channel=0):\n",
    "\n",
    "        if image.shape[0] > 0 and image.shape[1] > 0:\n",
    "            if image.shape[0] != 64 or image.shape[1] != 64:\n",
    "                image = cv2.resize(image, (64, 64))\n",
    "\n",
    "            # Create a list to append feature vectors to\n",
    "            # apply color conversion if other than 'RGB'\n",
    "            if cspace != 'RGB':\n",
    "                if cspace == 'HSV':\n",
    "                    feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "                elif cspace == 'LUV':\n",
    "                    feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "                elif cspace == 'HLS':\n",
    "                    feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "                elif cspace == 'YUV':\n",
    "                    feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "                elif cspace == 'GRAY':\n",
    "                    feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "                elif cspace == 'GRAYRGB':\n",
    "                    rgbfeature_image = np.copy(image)\n",
    "                    feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "            else:\n",
    "                feature_image = np.copy(image)\n",
    "            # Apply bin_spatial() to get spatial color features\n",
    "            if cspace == 'GRAYRGB':\n",
    "                spatial_features = self.bin_spatial(\n",
    "                    rgbfeature_image, size=spatial_size)\n",
    "                # Apply color_hist() also with a color space option now\n",
    "                hist_features = self.color_hist(\n",
    "                    rgbfeature_image, nbins=hist_bins,\n",
    "                    bins_range=hist_range)\n",
    "                # Call get_hog_features() with vis=False, feature_vec=True\n",
    "                hog_features = self.get_hog_features(\n",
    "                    feature_image, orient, pix_per_cell,\n",
    "                    cell_per_block, vis=False, feature_vec=True)\n",
    "                # Append the new feature vector to the features list\n",
    "                hogFeatures = np.concatenate(\n",
    "                    (spatial_features, hist_features, hog_features))\n",
    "            elif cspace == 'GRAY':\n",
    "                hog_features = self.get_hog_features(\n",
    "                    feature_image, orient, pix_per_cell,\n",
    "                    cell_per_block, vis=False, feature_vec=True)\n",
    "                hogFeatures = hog_features\n",
    "            else:\n",
    "                spatial_features = self.bin_spatial(\n",
    "                    feature_image, size=spatial_size)\n",
    "                # Apply color_hist() also with a color space option now\n",
    "                hist_features = self.color_hist(\n",
    "                    feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "                # Call get_hog_features() with vis=False, feature_vec=True\n",
    "                hog_features = self.get_hog_features(\n",
    "                    feature_image[:, :, hog_channel], orient, pix_per_cell,\n",
    "                    cell_per_block, vis=False, feature_vec=True)\n",
    "                # Append the new feature vector to the features list\n",
    "                hogFeatures = np.concatenate(\n",
    "                    (spatial_features, hist_features, hog_features))\n",
    "            return self.X_scaler.transform(hogFeatures.reshape(1, -1))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # specialized sliding window generation.\n",
    "    # we are looking at top down birds-eye view and\n",
    "    # limiting the detection to just the lanes.\n",
    "    # we need to use the lane lines to help generate the sliding window\n",
    "    # locations.\n",
    "    def slidingWindows(self, lines, laneIdx, complete=False):\n",
    "        # calculate the window positions\n",
    "        nlanes = len(lines) - 1\n",
    "        x0 = self.projectedX/2\n",
    "        y0 = self.projectedY\n",
    "\n",
    "        # create roadgrid for boxes\n",
    "        window_list = RoadGrid(x0, y0, nlanes, laneIdx)\n",
    "\n",
    "        for i in range(nlanes):\n",
    "            lane_boxes = {}\n",
    "            leftPolynomial = np.poly1d(lines[i].currentFit)\n",
    "            rightPolynomial = np.poly1d(lines[i + 1].currentFit)\n",
    "\n",
    "            # horizontal lines\n",
    "            # we treat left and right lanes differently because of the\n",
    "            # projection.  In the 'complete' case we are getting all\n",
    "            # of the sliding windows\n",
    "            if complete:\n",
    "                if i < laneIdx:\n",
    "                    indexedBottom = i + 1\n",
    "                else:\n",
    "                    indexedBottom = i\n",
    "                for j in range(\n",
    "                        int(lines[indexedBottom].bottomProjectedY / 32)):\n",
    "                    y1 = 32 * j\n",
    "                    mid = int(\n",
    "                        (rightPolynomial([y1]) +\n",
    "                         leftPolynomial([y1])) / 2)\n",
    "                    x1 = mid - 32\n",
    "                    x2 = mid + 32\n",
    "                    y2 = y1 + 64\n",
    "                    if (x1 > 0 and x2 < self.projectedX and\n",
    "                            y1 > 0 and y2 < self.projectedY):\n",
    "                        lane_boxes['%d' % (j)] = ((x1, y1), (x2, y2))\n",
    "\n",
    "            # In the else case we are getting only the windows at the top\n",
    "            # and bottom of our lanes for the sliding windows\n",
    "            else:\n",
    "                linetop = lines[i].getTopPoint()\n",
    "                if i == laneIdx:\n",
    "                    ylist = [(linetop[1], 0),\n",
    "                             (linetop[1] + 32, 1),\n",
    "                             (linetop[1] + 64, 2)]\n",
    "                elif i < laneIdx:\n",
    "                    ylist = [(linetop[1], 0),\n",
    "                             (linetop[1] + 32, 1),\n",
    "                             (linetop[1] + 64, 2),\n",
    "                             (lines[i].bottomProjectedY - 96, 55)]\n",
    "                else:\n",
    "                    ylist = [(linetop[1], 0),\n",
    "                             (linetop[1] + 32, 1),\n",
    "                             (linetop[1] + 64, 2),\n",
    "                             (lines[i + 1].bottomProjectedY - 32, 55)]\n",
    "\n",
    "                for y1, j in ylist:\n",
    "                    mid = int(\n",
    "                        (rightPolynomial([y1]) + leftPolynomial([y1])) / 2)\n",
    "                    x1 = mid - 32\n",
    "                    x2 = mid + 32\n",
    "                    y2 = y1 + 64\n",
    "                    if (x1 > 0 and x2 < self.projectedX and\n",
    "                            y1 > 0 and y2 < self.projectedY):\n",
    "                        lane_boxes['%d' % (j)] = ((x1, y1), (x2, y2))\n",
    "            window_list.map_boxes(i, lane_boxes)\n",
    "        return window_list\n",
    "\n",
    "    # draw_boxes function\n",
    "    def draw_boxes(self, img, windows, color=(255, 255, 255), thick=20):\n",
    "        # Iterate through the bounding boxes in a windows list\n",
    "        for bbox in windows:\n",
    "            # Draw a rectangle given bbox coordinates\n",
    "            cv2.rectangle(\n",
    "                img, (int(bbox[0][0]), int(bbox[0][1])),\n",
    "                (int(bbox[1][0]), int(bbox[1][1])), color, thick)\n",
    "\n",
    "    # Define a way for us to write out a sample of the HOG\n",
    "    def drawPlots(self, imagefile, sampleTitle, images):\n",
    "        # print(\"saving image and hog results to \", imagefile)\n",
    "        # Setup plot\n",
    "        fig = plt.figure(figsize=(12, len(images) * 9))\n",
    "        w_ratios = [2.0, 6.5, 6.5]\n",
    "        h_ratios = [9.0 for n in range(len(images))]\n",
    "        grid = gridspec.GridSpec(\n",
    "            len(images), 3, wspace=0.05, hspace=0.0,\n",
    "            width_ratios=w_ratios, height_ratios=h_ratios)\n",
    "        i = 0\n",
    "\n",
    "        for filename, orient, pix_per_cell, \\\n",
    "                cell_per_block, image1, image2 in images:\n",
    "            # draw the images\n",
    "            # next image\n",
    "            title = '%s\\n Orientation: %d\\n'\n",
    "            title += ' Pix_per_cell: %d\\n'\n",
    "            title += ' Cell_per_block: %d'\n",
    "            title = title % \\\n",
    "                (filename, orient, pix_per_cell, cell_per_block)\n",
    "\n",
    "            ax = plt.Subplot(fig, grid[i])\n",
    "            ax.text(-0.5, 0.4, title, fontsize=8)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            for sp in ax.spines.values():\n",
    "                sp.set_visible(False)\n",
    "            fig.add_subplot(ax)\n",
    "            i += 1\n",
    "\n",
    "            ax = plt.Subplot(fig, grid[i])\n",
    "            ax.imshow(image1)\n",
    "            if i == 1:\n",
    "                ax.set_title('Original', size=8)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            fig.add_subplot(ax)\n",
    "            i += 1\n",
    "\n",
    "            ax = plt.Subplot(fig, grid[i])\n",
    "            ax.imshow(image2)\n",
    "            if i == 2:\n",
    "                ax.set_title('Augmented %s' % (sampleTitle), size=8)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            fig.add_subplot(ax)\n",
    "            i += 1\n",
    "\n",
    "        plt.savefig(imagefile)\n",
    "        image = cv2.cvtColor(cv2.imread(imagefile), cv2.COLOR_BGR2RGB)\n",
    "        y, x, ch = image.shape\n",
    "        cuttoff = int((y / len(images)) * 0.65)\n",
    "        image = image[cuttoff:(y - cuttoff), :, :]\n",
    "        cv2.imwrite(imagefile, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Define a way for us to process an image with\n",
    "    # a list of sliding windows and try to detect vehicles\n",
    "    def detectVehicles(self, image, roadgrid):\n",
    "        mapping = roadgrid.getMapping()\n",
    "        for box in mapping.keys():\n",
    "            if not mapping[box]['occluded'] and \\\n",
    "               not mapping[box]['found'] and \\\n",
    "                    mapping[box]['vehicle'] is None:\n",
    "                window = mapping[box]['window']\n",
    "                wimage = image[\n",
    "                    window[0][1]:window[1][1],\n",
    "                    window[0][0]:window[1][0]]\n",
    "                wfeatures = self.extract_features(\n",
    "                    wimage, cspace=self.cspace, spatial_size=(32, 32),\n",
    "                    orient=self.orient, pix_per_cell=self.pix_per_cell,\n",
    "                    cell_per_block=self.cell_per_block,\n",
    "                    hog_channel=self.hog_channel,\n",
    "                    hist_bins=32, hist_range=(0, 256))\n",
    "                if wfeatures is not None:\n",
    "                    confidence = self.svc.decision_function(\n",
    "                        wfeatures.reshape(1, -1))\n",
    "                    if confidence[0] > self.threshold:\n",
    "                        roadgrid.setFound(box)\n",
    "        return roadgrid\n",
    "\n",
    "    # Define a way for us to collect data from images and videos\n",
    "    def collectData(self, frame, image, windows):\n",
    "        baseDir = \"collected/%s/%04d/\" % (self.start, frame)\n",
    "        if not os.path.exists(baseDir):\n",
    "            os.makedirs(baseDir)\n",
    "        i = 0\n",
    "        for window in [lane for lane in windows]:\n",
    "            wimage = image[window[0][1]:window[1][1], window[0][0]:window[1][0]]\n",
    "            outfilename = baseDir + self.dataFileNamePattern % (i)\n",
    "            cv2.imwrite(outfilename, cv2.cvtColor(wimage, cv2.COLOR_RGB2BGR))\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road Grid\n",
    "\n",
    "Road Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadGrid():\n",
    "\n",
    "    # initialize\n",
    "    def __init__(self, x0, y0, nlanes, mainLaneIdx):\n",
    "        self.nlanes = nlanes\n",
    "        self.mainIdx = mainLaneIdx\n",
    "        self.maxkey = 55\n",
    "        self.mapping = {}\n",
    "        self.x0 = x0\n",
    "        self.y0 = y0\n",
    "\n",
    "        # list of objects and their boxes\n",
    "        # trigged by setting found and occlusion checks\n",
    "        self.object_list = []\n",
    "\n",
    "        # list of vehicles and their boxes\n",
    "        # trigged by setting insert and track checks\n",
    "        self.vehicle_list = {}\n",
    "\n",
    "    # we are enforcing some constraints into the road grid\n",
    "    def map_boxes(self, laneIdx, boxes):\n",
    "        numkeys = [int(key) for key in boxes.keys()]\n",
    "        maxkey = max(numkeys)\n",
    "        if self.maxkey < maxkey:\n",
    "            self.maxkey = maxkey\n",
    "        laneAlpha = chr(laneIdx + 65)\n",
    "        for i in numkeys:\n",
    "            box = '%s+%02d' % (laneAlpha, self.maxkey - i)\n",
    "            self.mapping[box] = {\n",
    "                'window': boxes['%d' % (i)],\n",
    "                'found': False,\n",
    "                'occluded': False,\n",
    "                'tracked': False,\n",
    "                'object': None,\n",
    "                'vehicle': None}\n",
    "\n",
    "    def getMapping(self):\n",
    "        return self.mapping\n",
    "\n",
    "    def setVehicle(self, boxlist, vehIdx):\n",
    "        for box in boxlist:\n",
    "            self.mapping[box]['vehicle'] = vehIdx\n",
    "            if not self.mapping[box]['occluded']:\n",
    "                vehStr = '%d' % (vehIdx)\n",
    "                self.vehicle_list[vehStr] = box\n",
    "\n",
    "    def setFound(self, box):\n",
    "        self.mapping[box]['found'] = True\n",
    "        # print(\"from setFound...\")\n",
    "        self.calculateVoxelOcclusionAndObjectSeparation(\n",
    "            box, forceIntoOne=True)\n",
    "\n",
    "    def setOccluded(self, box):\n",
    "        if box in self.mapping:\n",
    "            self.mapping[box]['occluded'] = True\n",
    "\n",
    "    def getKey(self, lane, y):\n",
    "        box = '%s+%02d' % (chr(lane + 65), y)\n",
    "        return box\n",
    "\n",
    "    def getBox(self, lane, y):\n",
    "        box = '%s+%02d' % (chr(lane + 65), y)\n",
    "        if box in self.mapping:\n",
    "            return self.mapping[box]\n",
    "        return None\n",
    "\n",
    "    def getAllWindows(self):\n",
    "        return [self.mapping[map]['window'] for map in self.mapping.keys()]\n",
    "\n",
    "    def getBoxWindow(self, box):\n",
    "        return self.mapping[box]['window']\n",
    "\n",
    "    def getFoundWindows(self):\n",
    "        return [self.mapping[map]['window'] for map in self.mapping.keys()\n",
    "                if self.mapping[map]['found']]\n",
    "\n",
    "    def getOccludedWindows(self):\n",
    "        return [self.mapping[map]['window'] for map in self.mapping.keys()\n",
    "                if self.mapping[map]['occluded']]\n",
    "\n",
    "    def getFoundAndNotOccludedWindows(self):\n",
    "        return [self.mapping[map]['window'] for map in self.mapping.keys()\n",
    "                if self.mapping[map]['found'] and\n",
    "                not self.mapping[map]['occluded']]\n",
    "\n",
    "    def getFoundAndNotOccludedWindowsInObject(self, objIdx):\n",
    "        return [self.mapping[map]['window']\n",
    "                for map in self.object_list[objIdx]\n",
    "                if self.mapping[map]['found'] and\n",
    "                not self.mapping[map]['occluded']]\n",
    "\n",
    "    def getFoundAndNotOccludedWindowsInVehicle(self, vehIdx):\n",
    "        return [self.mapping[map]['window']\n",
    "                for map in self.mapping.keys()\n",
    "                if self.mapping[map]['found'] and\n",
    "                not self.mapping[map]['occluded'] and\n",
    "                self.mapping[map]['vehicle'] is not None and\n",
    "                self.mapping[map]['vehicle'] == vehIdx]\n",
    "\n",
    "    def getFoundAndNotOccludedBoxesInObject(self, objIdx):\n",
    "        return [map for map in self.object_list[objIdx]\n",
    "                if self.mapping[map]['found'] and\n",
    "                not self.mapping[map]['occluded']]\n",
    "\n",
    "    def getFoundAndNotOccludedBoxesInVehicle(self, vehIdx):\n",
    "        return [map for map in self.mapping.keys()\n",
    "                if self.mapping[map]['found'] and\n",
    "                not self.mapping[map]['occluded'] and\n",
    "                self.mapping[map]['vehicle'] is not None and\n",
    "                self.mapping[map]['vehicle'] == vehIdx]\n",
    "\n",
    "    def gridCoordinates(self, box):\n",
    "        lane, y = box.split('+')\n",
    "        return ord(lane)-65, int(y)\n",
    "\n",
    "    def gridSize(self):\n",
    "        return self.nlanes, self.maxkey\n",
    "\n",
    "    def generatePolyRay(self, x0, y0, x1, y1):\n",
    "        allY = np.array([y0, y1])\n",
    "        allX = np.array([x0, x1])\n",
    "        return np.poly1d(np.polyfit(allY, allX, 1))\n",
    "\n",
    "    def getNumObjects(self):\n",
    "        return len(self.object_list)\n",
    "\n",
    "    def getObjects(self):\n",
    "        return self.object_list\n",
    "\n",
    "    def getObjectList(self, i):\n",
    "        return self.object_list[i]\n",
    "\n",
    "    def getObjectListWindows(self, i):\n",
    "        return [self.mapping[map]['window'] for map in self.object_list[i]]\n",
    "\n",
    "    # we will use constrain propagation to limit our search for vehicle testing\n",
    "    # by using voxel occlusion testing to find occluded boxes in the grid\n",
    "    def calculateVoxelOcclusionAndObjectSeparation(\n",
    "            self, box, vehicle=None, forceIntoOne=False):\n",
    "        if not self.mapping[box]['occluded']:\n",
    "            # find the two rays from our camera that hits the edges\n",
    "            # of our box and generate a set of ray polys.\n",
    "            window = self.mapping[box]['window']\n",
    "            x1, y1 = window[0][0], window[0][1]\n",
    "            x2, y2 = window[1][0], window[1][1]\n",
    "            polyRay1 = self.generatePolyRay(self.x0, self.y0, x1, y1)\n",
    "            polyRay2 = self.generatePolyRay(self.x0, self.y0, x2, y2)\n",
    "\n",
    "            newobject = True\n",
    "            # until our rays hit something found before\n",
    "            # then we are a new object\n",
    "            # else we are part of a larger object.\n",
    "            # (or it could be something that is too close\n",
    "            #  to tell apart using this method)\n",
    "            mapping = [n for n in self.mapping.keys()]\n",
    "            mapping.sort()\n",
    "            for map in mapping:\n",
    "                window = self.mapping[map]['window']\n",
    "                boxX1, boxX2 = window[0][0], window[1][0]\n",
    "                boxMidY = (window[0][1] + window[1][1])/2\n",
    "                rayX1 = polyRay1(np.array([boxMidY]))[0]\n",
    "                rayX2 = polyRay2(np.array([boxMidY]))[0]\n",
    "                # print(\"rayX1\", rayX1, \"rayX2\", rayX2, boxMidY)\n",
    "                # print(\"boxX1\", boxX1, \"boxX2\", boxX2, boxMidY)\n",
    "                # print(\"box\", box, \"map\", map)\n",
    "\n",
    "                # three choices for a box to be occluded by our\n",
    "                # box: ray1 hits, ray2 hits, or the box is\n",
    "                #      completely within the two rays\n",
    "                if (((boxX1 <= rayX1 and boxX2 >= rayX1) or\n",
    "                        (boxX1 <= rayX2 and boxX2 >= rayX2) or\n",
    "                        (rayX1 < boxX1 and rayX1 < boxX2 and\n",
    "                         rayX2 > boxX1 and rayX2 > boxX2)) and\n",
    "                        (y1 > boxMidY)):\n",
    "                    # print(\"Hit!\")\n",
    "\n",
    "                    # is our box is a vehicle...?\n",
    "                    if vehicle is not None:\n",
    "                        if self.mapping[map]['vehicle'] is None:\n",
    "                            self.mapping[map]['vehicle'] = vehicle\n",
    "                            self.mapping[map]['found'] = True\n",
    "                            self.mapping[map]['occluded'] = True\n",
    "                            # print(\"10. vehicle is none.!\", box, map)\n",
    "\n",
    "                        # we are the same!\n",
    "                        elif self.mapping[map]['vehicle'] == vehicle:\n",
    "                            # update the vehicle to be us.\n",
    "                            vehStr = '%d' % (vehicle)\n",
    "                            self.vehicle_list[vehStr] = box\n",
    "                            # print(\"11. vehicle is same.!\", box, map)\n",
    "\n",
    "                        # the other box is a vehicle too, but not us!\n",
    "                        # occlude it\n",
    "                        else:\n",
    "                            # print(\"1. this should not happen!\")\n",
    "                            self.mapping[map]['occluded'] = True\n",
    "\n",
    "                    # stop! we found something already\n",
    "                    # occluded - this box maybe be something\n",
    "                    # larger, so adopt its object or vehicle\n",
    "                    elif self.mapping[map]['occluded'] and forceIntoOne:\n",
    "                        # the other voxel is a vehicle!\n",
    "                        if self.mapping[map]['vehicle'] is not None:\n",
    "                            # the vehicle is being tracked by\n",
    "                            # vehicle tracker, don't try to move it!\n",
    "                            # vehicle is not being tracked...\n",
    "                            if self.mapping[map]['tracked']:\n",
    "                                # print(\"2. tracked detected!\", box, map)\n",
    "                                # print(\"setting ourselves occluded\")\n",
    "                                vehIdx = self.mapping[map]['vehicle']\n",
    "                                vehStr = '%d' % (vehIdx)\n",
    "                                self.mapping[box]['occluded'] = True\n",
    "                                self.mapping[box]['vehicle'] = \\\n",
    "                                    self.mapping[map]['vehicle']\n",
    "                                self.vehicle_list[vehStr] = map\n",
    "                                self.mapping[box]['vehicle'] = vehIdx\n",
    "                                self.mapping[box]['found'] = True\n",
    "\n",
    "                            else:\n",
    "                                # print(\"2. new location detected!\", box, map)\n",
    "                                # need to inform the vehicle\n",
    "                                # it has a new location!\n",
    "                                vehIdx = self.mapping[map]['vehicle']\n",
    "                                self.mapping[map]['occluded'] = True\n",
    "                                vehStr = '%d' % (vehIdx)\n",
    "                                self.vehicle_list[vehStr] = box\n",
    "                                self.mapping[box]['vehicle'] = vehIdx\n",
    "                                self.mapping[box]['found'] = True\n",
    "\n",
    "                        elif self.mapping[box]['object'] is not None:\n",
    "                            # if self.mapping[map]['object'] is None:\n",
    "                            #     print(\"That's not suppose to happen!\")\n",
    "                            # else:\n",
    "                            #     print(\"objectlist\", self.object_list)\n",
    "                            # print(\"3. new location detected!\", box, map)\n",
    "                            idx = self.mapping[map]['object']\n",
    "                            if idx is not None:\n",
    "                                self.mapping[box]['object'] = idx\n",
    "                                # and add ourselves to their list\n",
    "                                # print(\"idx=\", idx)\n",
    "                                self.object_list[idx].append(box)\n",
    "\n",
    "                        # our objects do not match!\n",
    "                        elif self.mapping[box]['object'] is None and \\\n",
    "                                self.mapping[map]['object'] is not None:\n",
    "                            # print(\"4. new location detected!\", box, map)\n",
    "                            idx = self.mapping[map]['object']\n",
    "                            self.mapping[box]['object'] = idx\n",
    "                            # else:\n",
    "                            #     print(\"newer list than ours!!!\")\n",
    "                            # otherwise we are the same object already\n",
    "                            # - nothing to do.\n",
    "\n",
    "                    # other box is not occluded\n",
    "                    # elif not self.mapping[map]['occluded'] and \\\n",
    "                    #      not self.mapping[map]['tracked']:\n",
    "                    elif not self.mapping[map]['occluded']:\n",
    "                        # the other voxel is also a vehicle!\n",
    "                        if self.mapping[map]['vehicle'] is not None:\n",
    "                            # print(\"5. new location detected!\", box, map)\n",
    "                            # need to inform the vehicle\n",
    "                            # it has a new location!\n",
    "                            vehIdx = self.mapping[map]['vehicle']\n",
    "                            self.mapping[map]['occluded'] = True\n",
    "                            vehStr = '%d' % (vehIdx)\n",
    "                            self.vehicle_list[vehStr] = box\n",
    "                            self.mapping[box]['vehicle'] = vehIdx\n",
    "                            self.mapping[box]['found'] = True\n",
    "\n",
    "                        # but we don't belong in the same object\n",
    "                        if self.mapping[box]['object'] is not None and \\\n",
    "                                self.mapping[map]['object'] is not None \\\n",
    "                                and self.mapping[box]['object'] != \\\n",
    "                                self.mapping[map]['object']:\n",
    "                            # we seem to be occluding another object!\n",
    "                            # just set their occluded flag\n",
    "                            # print(\"6. new location detected!\")\n",
    "                            self.mapping[map]['occluded'] = True\n",
    "\n",
    "                        # we thought we were our own list, we need\n",
    "                        # the other object is not in a different\n",
    "                        # object list and we don't either!\n",
    "                        elif self.mapping[box]['object'] is None:\n",
    "                            # we must be a new object then!\n",
    "                            # create a new object list,\n",
    "                            # and add this to our object.\n",
    "                            idx = len(self.object_list)\n",
    "                            self.mapping[box]['object'] = idx\n",
    "                            self.mapping[map]['object'] = idx\n",
    "                            self.object_list.append([box, map])\n",
    "                            # and set the occlusion!\n",
    "                            self.mapping[map]['occluded'] = True\n",
    "                        else:\n",
    "                            # are in our own list, just add this one to\n",
    "                            # it and set to our object.\n",
    "                            idx = self.mapping[box]['object']\n",
    "                            self.object_list[idx].append(map)\n",
    "                            self.mapping[map]['object'] = idx\n",
    "                            # and set the occlusion!\n",
    "                            self.mapping[map]['occluded'] = True\n",
    "\n",
    "                    # the other box is occluded already, but we cannot\n",
    "                    # force our objects into one\n",
    "                    else:\n",
    "                        # this item is already occluded.\n",
    "                        # add ourselves to their list.\n",
    "                        if self.mapping[map]['object'] is not None and \\\n",
    "                                self.mapping[box]['object'] is None:\n",
    "                            # we may be something larger after all!\n",
    "                            idx = self.mapping[map]['object']\n",
    "                            self.mapping[box]['object'] = idx\n",
    "                            # and add ourselves to their list\n",
    "                            self.object_list[idx].append(box)\n",
    "                            # and set the occlusion!\n",
    "                            self.mapping[map]['occluded'] = True\n",
    "        # for debugging objs\n",
    "        # print(\"objs = \", len(self.object_list))\n",
    "\n",
    "    def calculateObjectPosition(self, lane, ycoordinate):\n",
    "        # first check to see if the coordinates falls into an existing box\n",
    "        laneAscii = chr(lane + 65)\n",
    "        boxpattern = re.compile('^%s[0123456789]+$' % (laneAscii))\n",
    "        for box in self.mapping.keys():\n",
    "            if boxpattern.match(box):\n",
    "                window = self.mapping[box]['window']\n",
    "                if (window[0][1] < ycoordinate and\n",
    "                        ycoordinate < window[1][1]):\n",
    "                    return int(box.replace(laneAscii, ''))\n",
    "\n",
    "        # if not, return an estimate\n",
    "        return int((1.0-ycoordinate/self.y0) * self.maxkey)-3\n",
    "\n",
    "    def insertTrackedObject(self, lane, yidx, window, vehIdx, tracking=False):\n",
    "        box = '%s+%02d' % (chr(lane + 65), yidx)\n",
    "        # its not there - insert it\n",
    "        if box not in self.mapping:\n",
    "            self.mapping[box] = {\n",
    "                'window': window,\n",
    "                'found': True,\n",
    "                'tracked': tracking,\n",
    "                'occluded': False,\n",
    "                'object': None,\n",
    "                'vehicle': vehIdx}\n",
    "\n",
    "        # its already there - replace it\n",
    "        else:\n",
    "            self.mapping[box]['window'] = window\n",
    "            self.mapping[box]['found'] = True\n",
    "            self.mapping[box]['tracked'] = tracking\n",
    "            self.mapping[box]['vehicle'] = vehIdx\n",
    "\n",
    "        vehStr = '%d' % (vehIdx)\n",
    "        self.vehicle_list[vehStr] = box\n",
    "        # print(\"from insertTrackedObject...\")\n",
    "        self.calculateVoxelOcclusionAndObjectSeparation(box, vehicle=vehIdx)\n",
    "        return self.vehicle_list[vehStr]\n",
    "\n",
    "    def isOccluded(self, box):\n",
    "        if box in self.mapping:\n",
    "            return self.mapping[box]['occluded']\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road Management\n",
    "\n",
    "Road Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RoadManager():\n",
    "    # Initialize roadManager\n",
    "\n",
    "    def __init__(self, camCal, keepN=10, debug=False, scrType=0):\n",
    "        # for both left and right lines\n",
    "        # set debugging\n",
    "        self.debug = debug\n",
    "        self.scrType = scrType\n",
    "\n",
    "        # frameNumber\n",
    "        self.curFrame = None\n",
    "\n",
    "        # keep last N\n",
    "        self.keepN = keepN\n",
    "\n",
    "        # our own copy of the camera calibration results\n",
    "        self.mtx, self.dist, self.img_size = camCal.get()\n",
    "\n",
    "        # normal image size\n",
    "        self.x, self.y = self.img_size\n",
    "\n",
    "        # mid point\n",
    "        self.mid = int(self.y / 2)\n",
    "\n",
    "        # create our own projection manager\n",
    "        self.projMgr = ProjectionManager(camCal, keepN=keepN, debug=self.debug)\n",
    "\n",
    "        # sides definitions\n",
    "        self.left = 1\n",
    "        self.right = 2\n",
    "\n",
    "        # default left-right lane masking\n",
    "        self.maskDelta = 5\n",
    "\n",
    "        # road statistics\n",
    "        # the left and right lanes curvature measurement could be misleading -\n",
    "        # need a threshold to indicate straight road.\n",
    "        self.roadStraight = False\n",
    "        # radius of curvature of the line in meters\n",
    "        self.radiusOfCurvature = None\n",
    "\n",
    "        # distance in meters of vehicle center is off from road center\n",
    "        self.lineBasePos = None\n",
    "\n",
    "        # ghosting of lane lines (for use in trouble spots - i.e: bridge or in\n",
    "        # harder challenges)\n",
    "        self.lastNEdges = None\n",
    "\n",
    "        # array of lines - we will create a set of empty lines at the beginning\n",
    "        # and have the first lane initialize them\n",
    "        leftLine = Line(self.left, self.x, self.y, self.projMgr.projectedX,\n",
    "                        self.projMgr.projectedY, self.maskDelta)\n",
    "        rightLine = Line(self.right, self.x, self.y, self.projMgr.projectedX,\n",
    "                         self.projMgr.projectedY, self.maskDelta)\n",
    "        self.lines = [leftLine, rightLine]\n",
    "\n",
    "        # array of lanes - we will create one at the begining and add more\n",
    "        # during processing of the first frame.\n",
    "        self.lanes = [Lane(self.x, self.y,\n",
    "                           self.projMgr.projectedX,\n",
    "                           self.projMgr.projectedY,\n",
    "                           self.maskDelta, self.lines)]\n",
    "        self.mainLaneIdx = 0\n",
    "        self.resized = False\n",
    "\n",
    "        # road overhead and unwarped views\n",
    "        self.roadsurface = np.zeros(\n",
    "            (self.projMgr.projectedY, self.projMgr.projectedX, 3),\n",
    "            dtype=np.uint8)\n",
    "        self.roadunwarped = None\n",
    "        self.lastTop = 0\n",
    "        self.restartCount = 0\n",
    "        self.resetProjectionCount = 0\n",
    "\n",
    "        # cloudy mode\n",
    "        self.cloudyMode = False\n",
    "\n",
    "        # pixel offset from direction of travel\n",
    "        self.lastLeftRightOffset = 0\n",
    "\n",
    "        # boosting\n",
    "        self.boosting = 0.0\n",
    "\n",
    "        # vehicles\n",
    "        self.versionName = \"CHOGRGB4\"\n",
    "        self.cspace = 'RGB'\n",
    "        self.orient = 8\n",
    "        self.pix_per_cell = 4\n",
    "        self.cell_per_block = 2\n",
    "        self.hog_channel = 0\n",
    "        # self.threshold = 10.15\n",
    "        # self.threshold = 20.0\n",
    "        # self.threshold = 15.0\n",
    "        # self.threshold = 27.0\n",
    "        # self.threshold = 40.0\n",
    "        self.threshold = 50.0\n",
    "        self.vehicleDetection = VehicleDetection(\n",
    "                                    self.projMgr.projectedX,\n",
    "                                    self.projMgr.projectedY,\n",
    "                                    self.versionName,\n",
    "                                    self.cspace, self.orient,\n",
    "                                    self.pix_per_cell,\n",
    "                                    self.cell_per_block,\n",
    "                                    self.hog_channel,\n",
    "                                    self.threshold)\n",
    "        self.vehicleTracking = VehicleTracking(\n",
    "                                    self.x,\n",
    "                                    self.y,\n",
    "                                    self.projMgr.projectedX,\n",
    "                                    self.projMgr.projectedY,\n",
    "                                    self.lanes)\n",
    "\n",
    "        self.possibleVehicleWindows = []\n",
    "        self.vehicles = []\n",
    "\n",
    "        # special effects image\n",
    "        self.specialProjectedEffects = np.zeros(\n",
    "            (self.projMgr.projectedY, self.projMgr.projectedX, 3),\n",
    "            dtype=np.uint8)\n",
    "        self.specialPerspectiveEffects = np.zeros(\n",
    "            (self.y, self.x, 3), dtype=np.uint8)\n",
    "\n",
    "        # activeWindows\n",
    "        self.activeWindows = []\n",
    "\n",
    "        # resulting image\n",
    "        self.final = None\n",
    "\n",
    "        # for debugging only\n",
    "        if self.debug:\n",
    "            self.diag1 = np.zeros((self.y, self.x, 3), dtype=np.float32)\n",
    "\n",
    "    def addLaneLeft(self, curLane):\n",
    "        faint = -(curLane.maskvalue / 128)\n",
    "        if self.resized:\n",
    "            faint *= 0.75\n",
    "        if ((np.absolute(faint) > 0.5 or\n",
    "                (self.resized and np.absolute(faint) > 0.4)) and\n",
    "                curLane.adjacentLeft and\n",
    "                curLane.adjacentLLane is None):\n",
    "            # print(\"threshold:\", faint)\n",
    "            newLeftLine = Line(self.left, self.x, self.y,\n",
    "                               self.projMgr.projectedX,\n",
    "                               self.projMgr.projectedY,\n",
    "                               self.maskDelta)\n",
    "            newLeftLine.createPolyFitLeft(\n",
    "                self.curImgFtr, curLane, faint=faint, resized=self.resized)\n",
    "            if newLeftLine.detected and newLeftLine.lineClassified:\n",
    "                # print(\"adding left lane\")\n",
    "                newLeftLine.findBottomOfLine(self.curImgFtr)\n",
    "                self.lines.insert(0, newLeftLine)\n",
    "                for lane in self.lanes:\n",
    "                    leftIdx, rightIdx = lane.getLineIndex()\n",
    "                    lane.setLineIndex(leftIdx + 1, rightIdx + 1)\n",
    "                newLane = Lane(self.x, self.y,\n",
    "                               self.projMgr.projectedX,\n",
    "                               self.projMgr.projectedY,\n",
    "                               self.maskDelta, self.lines,\n",
    "                               maskvalue=curLane.maskvalue - 28)\n",
    "                newLane.adjacentRLane = curLane\n",
    "                newLane.adjacentRight = True\n",
    "                newLane.adjacentLeft = newLeftLine.adjacentLeft\n",
    "                newLane.adjacentLLane = None\n",
    "                newLane.leftprojection = newLeftLine.applyLineMask(\n",
    "                    self.curImgFtr.getEdgeProjection())\n",
    "                newLane.rightprojection = curLane.leftprojection\n",
    "                self.lanes.insert(0, newLane)\n",
    "                curLane.adjacentLLane = newLane\n",
    "                curLane.adjacentLeft = True\n",
    "                self.mainLaneIdx += 1\n",
    "            else:\n",
    "                # print(\"left lane not detected\")\n",
    "                curLane.adjacentLeft = False\n",
    "\n",
    "    def addLaneRight(self, curLane):\n",
    "        faint = (curLane.maskvalue / 128)\n",
    "        if self.resized:\n",
    "            faint *= 0.75\n",
    "        if ((faint > 0.5 or\n",
    "                (self.resized and faint > 0.4)) and\n",
    "                curLane.adjacentRight and\n",
    "                curLane.adjacentRLane is None):\n",
    "            # print(\"threshold:\", faint)\n",
    "            newRightLine = Line(self.right, self.x, self.y,\n",
    "                                self.projMgr.projectedX,\n",
    "                                self.projMgr.projectedY, self.maskDelta)\n",
    "            newRightLine.createPolyFitRight(\n",
    "                self.curImgFtr,  curLane, faint=faint, resized=self.resized)\n",
    "            if newRightLine.detected and newRightLine.lineClassified:\n",
    "                # print(\"adding right lane\")\n",
    "                newRightLine.findBottomOfLine(self.curImgFtr)\n",
    "                self.lines.append(newRightLine)\n",
    "                newLane = Lane(self.x, self.y,\n",
    "                               self.projMgr.projectedX,\n",
    "                               self.projMgr.projectedY,\n",
    "                               self.maskDelta, self.lines,\n",
    "                               len(self.lines) - 2,\n",
    "                               len(self.lines) - 1,\n",
    "                               curLane.maskvalue - 24)\n",
    "                newLane.adjacentLLane = curLane\n",
    "                newLane.adjacentRLane = None\n",
    "                newLane.adjacentLeft = True\n",
    "                newLane.adjacentRight = newRightLine.adjacentRight\n",
    "                newLane.leftprojection = curLane.rightprojection\n",
    "                newLane.rightprojection = newRightLine.applyLineMask(\n",
    "                    self.curImgFtr.getEdgeProjection())\n",
    "                self.lanes.append(newLane)\n",
    "                curLane.adjacentRLane = newLane\n",
    "                curLane.adjacentRight = True\n",
    "            else:\n",
    "                # print(\"right lane not detected\")\n",
    "                curLane.adjacentRight = False\n",
    "\n",
    "    def updateLaneLeft(self, curLane):\n",
    "        if curLane.adjacentLeft and curLane.adjacentLLane is not None:\n",
    "            leftLine = curLane.adjacentLLane.lines[curLane.adjacentLLane.left]\n",
    "            leftLine.updatePolyFitLeft(curLane)\n",
    "            leftLine.findBottomOfLine(self.curImgFtr)\n",
    "\n",
    "    def updateLaneRight(self, curLane):\n",
    "        if curLane.adjacentRight and curLane.adjacentRLane is not None:\n",
    "            rightLine = curLane.adjacentRLane.lines[\n",
    "                curLane.adjacentRLane.right]\n",
    "            rightLine.updatePolyFitRight(curLane)\n",
    "            rightLine.findBottomOfLine(self.curImgFtr)\n",
    "\n",
    "    def findLanes(self, img, resized=False):\n",
    "        self.resized = resized\n",
    "        if self.curFrame is None:\n",
    "            self.curFrame = 0\n",
    "        else:\n",
    "            self.curFrame += 1\n",
    "            # print(\"############################################\")\n",
    "            # print(\"Frame #\", self.curFrame)\n",
    "            # print(\"############################################\")\n",
    "\n",
    "        if resized and self.curFrame < 2:\n",
    "            # self.threshold = 5.0\n",
    "            # self.threshold = 10.0\n",
    "            # self.threshold = 12.0\n",
    "            # self.threshold = -0.25\n",
    "            self.threshold = 30.0\n",
    "            self.vehicleDetection.set_threshold(self.threshold)\n",
    "\n",
    "        self.curImgFtr = ImageFilters(self.projMgr.camCal,\n",
    "                                      self.projMgr.projectedX,\n",
    "                                      self.projMgr.projectedY,\n",
    "                                      debug=True)\n",
    "        self.projMgr.set_image_filter(self.curImgFtr)\n",
    "        self.curImgFtr.imageQ(img)\n",
    "        mainLane = self.lanes[self.mainLaneIdx]\n",
    "\n",
    "        # Experimental\n",
    "        # if self.curImgFtr.visibility < -30 or \\\n",
    "        #   self.curImgFtr.skyImageQ == 'Sky Image: overexposed' or \\\n",
    "        #   self.curImgFtr.skyImageQ == 'Sky Image: underexposed':\n",
    "        #    self.curImgFtr.balanceEx()\n",
    "\n",
    "        # detected cloudy condition!\n",
    "        if (self.curImgFtr.skyText == 'Sky Condition: cloudy' and\n",
    "                self.curFrame == 0):\n",
    "            self.cloudyMode = True\n",
    "\n",
    "        # choose a default filter based on weather condition\n",
    "        # line class can update filter based on what it wants too (different\n",
    "        # for each lane line).\n",
    "        if self.cloudyMode:\n",
    "            self.curImgFtr.applyFilter3()\n",
    "            self.maskDelta = 10\n",
    "            mainLane.setMaskDelta(self.maskDelta)\n",
    "        elif (self.curImgFtr.skyText == 'Sky Condition: clear' or\n",
    "              self.curImgFtr.skyText == 'Sky Condition: tree shaded'):\n",
    "            self.curImgFtr.applyFilter2()\n",
    "        elif self.curFrame < 2:\n",
    "            self.curImgFtr.applyFilter4()\n",
    "        else:\n",
    "            self.curImgFtr.applyFilter5()\n",
    "\n",
    "        self.curImgFtr.horizonDetect(debug=True)\n",
    "\n",
    "        # low confidence?\n",
    "        if mainLane.confidence() < 0.5 or self.curFrame < 2:\n",
    "            self.restartCount += 1\n",
    "            self.projMgr.findInitialRoadCorners(self.curImgFtr)\n",
    "\n",
    "            # Is our destination projection too high for our source?\n",
    "            # update destination rect\n",
    "            # experimental\n",
    "            projectionTopPixel = \\\n",
    "                self.curImgFtr.projectionThrowDistanceDetect(debug=self.debug)\n",
    "\n",
    "            # Experimental\n",
    "            # print(\"projectionTopPixel\", projectionTopPixel)\n",
    "            # if projectionTopPixel > self.projMgr.projectedY/5:\n",
    "            #    self.resetProjectionCount += 1\n",
    "            #    self.lastTop = projectionTopPixel\n",
    "            #    self.projMgr.resetDestTop(self.lastTop)\n",
    "\n",
    "            #    # this is important enough that we want to reproject\n",
    "            #    # right away!\n",
    "            #    self.projMgr.project(self.curImgFtr,\n",
    "            #                         self.lastLeftRightOffset, sameFrame=True)\n",
    "            #    projectionTopPixel = \\\n",
    "            #        self.curImgFtr.projectionThrowDistanceDetect(\n",
    "            #            debug=self.debug)\n",
    "            #    # print(\"2nd Time projectionTopPixel\", projectionTopPixel)\n",
    "\n",
    "            # we may be too conservative...\n",
    "            # Just move up the projection in the next frame\n",
    "            # elif projectionTopPixel == 0 and self.lastTop > 10:\n",
    "            #    self.resetProjectionCount += 1\n",
    "            #    self.lastTop -= 10\n",
    "            #    self.projMgr.resetDestTop(self.lastTop)\n",
    "\n",
    "            # Use visibility to lower the FoV\n",
    "            # adjust source for perspective projection accordingly\n",
    "            self.initialGradient = self.projMgr.curGradient\n",
    "            if (self.curImgFtr.horizonFound and\n",
    "                    self.projMgr.curGradient is not None):\n",
    "                self.roadHorizonGap = (self.projMgr.curGradient -\n",
    "                                       self.curImgFtr.roadhorizon)\n",
    "                newTop = self.curImgFtr.roadhorizon + self.roadHorizonGap\n",
    "                self.projMgr.setSrcTop(\n",
    "                    newTop - self.curImgFtr.visibility,\n",
    "                    self.curImgFtr.visibility)\n",
    "\n",
    "            # find main lane lines left and right\n",
    "            self.lastNEdges = self.curImgFtr.curRoadEdge\n",
    "            mainLane.findInitialLines(self.curImgFtr, resized=self.resized)\n",
    "\n",
    "            # find lane lines left and right\n",
    "            curLane = mainLane\n",
    "            while (curLane is not None and\n",
    "                   curLane.adjacentLeft and\n",
    "                   curLane.adjacentLLane is None):\n",
    "                self.addLaneLeft(curLane)\n",
    "                curLane = curLane.adjacentLLane\n",
    "            curLane = mainLane\n",
    "            while (curLane is not None and\n",
    "                   curLane.adjacentRight and\n",
    "                   curLane.adjacentRLane is None):\n",
    "                self.addLaneRight(curLane)\n",
    "                curLane = curLane.adjacentRLane\n",
    "        else:\n",
    "            # Apply Boosting...\n",
    "            # For Challenges ONLY\n",
    "            if self.cloudyMode:\n",
    "                if self.curImgFtr.skyText == 'Sky Condition: cloudy':\n",
    "                    self.boosting = 0.4\n",
    "                    self.lastNEdges = self.curImgFtr.miximg(\n",
    "                        self.curImgFtr.curRoadEdge, self.lastNEdges, 1.0, 0.4)\n",
    "                else:\n",
    "                    self.boosting = 1.0\n",
    "                    self.lastNEdges = self.curImgFtr.miximg(\n",
    "                        self.curImgFtr.curRoadEdge, self.lastNEdges, 1.0, 1.0)\n",
    "                self.curImgFtr.curRoadEdge = self.lastNEdges\n",
    "            elif (self.curImgFtr.skyText ==\n",
    "                  'Sky Condition: surrounded by trees'):\n",
    "                self.boosting = 0.0\n",
    "                # self.lastNEdges = self.curImgFtr.miximg(\n",
    "                #     self.curImgFtr.curRoadEdge, self.lastNEdges, 1.0, 0.4)\n",
    "                # self.curImgFtr.curRoadEdge = self.lastNEdges\n",
    "\n",
    "            # project the new frame to a plane for further analysis.\n",
    "            self.projMgr.project(self.curImgFtr, self.lastLeftRightOffset)\n",
    "\n",
    "            # Is our destination projection too high for our source? update\n",
    "            # destination rect\n",
    "            projectionTopPixel = self.curImgFtr.projectionThrowDistanceDetect(\n",
    "                debug=self.debug)\n",
    "            # experimental\n",
    "            # print(\"projectionTopPixel\", projectionTopPixel)\n",
    "            # if projectionTopPixel > self.projMgr.projectedY/4:\n",
    "            #    self.resetProjectionCount += 1\n",
    "            #    self.lastTop = projectionTopPixel\n",
    "            #    self.projMgr.resetDestTop(self.lastTop)\n",
    "\n",
    "            #    # this is important enough that we want to reproject\n",
    "            #    # right away!\n",
    "            #    self.projMgr.project(self.curImgFtr,\n",
    "            #                         self.lastLeftRightOffset, sameFrame=True)\n",
    "            #    projectionTopPixel = \\\n",
    "            #        self.curImgFtr.projectionThrowDistanceDetect(\n",
    "            #            debug=self.debug)\n",
    "            #    print(\"2nd Time projectionTopPixel\", projectionTopPixel)\n",
    "\n",
    "            # we may be too conservative...\n",
    "            # Just move up the projection in the next frame\n",
    "            # elif projectionTopPixel == 0 and self.lastTop > 10:\n",
    "            #    self.resetProjectionCount += 1\n",
    "            #    self.lastTop -= 10\n",
    "            #    self.projMgr.resetDestTop(self.lastTop)\n",
    "\n",
    "            # find main lane lines left and right again\n",
    "            mainLane.findExistingLines(self.curImgFtr)\n",
    "\n",
    "            # Update location for FoV\n",
    "            # if mainLane.leftLineLastTop is not None and\n",
    "            #    mainLane.rightLineLastTop is not None and\n",
    "            #    self.curImgFtr.visibility < -30:\n",
    "            #    self.lastLeftRightOffset = int((self.x/2) -\n",
    "            #        (mainLane.leftLineLastTop[0] +\n",
    "            #         mainLane.rightLineLastTop[0])/2)\n",
    "            #    print(\"lastLeftRightOffset: \", self.lastLeftRightOffset)\n",
    "\n",
    "            # update lane lines left and right\n",
    "            curLane = mainLane\n",
    "            while curLane.adjacentLeft and curLane.adjacentLLane is not None:\n",
    "                self.updateLaneLeft(curLane)\n",
    "                curLane = curLane.adjacentLLane\n",
    "            curLane = mainLane\n",
    "            while curLane.adjacentRight and curLane.adjacentRLane is not None:\n",
    "                self.updateLaneRight(curLane)\n",
    "                curLane = curLane.adjacentRLane\n",
    "\n",
    "        # Update Stats and Top points for next frame.\n",
    "        self.leftLineLastTop = mainLane.leftLineLastTop\n",
    "        self.rightLineLastTop = mainLane.rightLineLastTop\n",
    "        self.leftLinePoints = mainLane.leftLinePoints\n",
    "        self.rightLinePoints = mainLane.rightLinePoints\n",
    "\n",
    "        # Update road statistics for display\n",
    "        self.lineBasePos = mainLane.getLineBasePos()\n",
    "        self.radiusOfCurvature, self.roadStraight = \\\n",
    "            mainLane.getRadiusOfCurvature()\n",
    "\n",
    "        # Scan for vehicles\n",
    "        self.vehicleScan = np.copy(self.curImgFtr.getRoadProjection())\n",
    "        if self.curFrame > 1:\n",
    "            if self.curFrame == 2:\n",
    "                if resized:\n",
    "                    # self.threshold = 12.0\n",
    "                    # self.threshold = 15.0\n",
    "                    self.threshold = 30.0\n",
    "                    self.vehicleDetection.set_threshold(self.threshold)\n",
    "                else:\n",
    "                    self.threshold = 25.0\n",
    "                    self.vehicleDetection.set_threshold(self.threshold)\n",
    "\n",
    "            self.roadGrid = self.vehicleDetection.slidingWindows(\n",
    "                self.lines, self.mainLaneIdx, False)\n",
    "            allPossibleWindows = self.roadGrid.getAllWindows()\n",
    "        else:\n",
    "            self.roadGrid = self.vehicleDetection.slidingWindows(\n",
    "                self.lines, self.mainLaneIdx, True)\n",
    "            allPossibleWindows = self.roadGrid.getAllWindows()\n",
    "\n",
    "        if self.scrType & 16 == 16:\n",
    "            self.vehicleDetection.collectData(\n",
    "                self.curFrame, self.vehicleScan, allPossibleWindows)\n",
    "        else:\n",
    "            # add our vehicles into the search space\n",
    "            # to reduce search area\n",
    "            for vehIdx in range(len(self.vehicles)):\n",
    "                if self.vehicles[vehIdx].mode > 2:\n",
    "                    self.roadGrid = self.vehicles[vehIdx].updateVehicle(\n",
    "                        self.roadGrid, np.copy(self.curImgFtr.curImage))\n",
    "                elif len(self.vehicles[vehIdx].windows) > 0:\n",
    "                    lane = self.vehicles[vehIdx].lane\n",
    "                    yidx = self.vehicles[vehIdx].yidx\n",
    "                    window = self.vehicles[vehIdx].windows[0]\n",
    "                    # print(\"vehIdx: \", lane, yidx, window, vehIdx)\n",
    "                    self.roadGrid.insertTrackedObject(\n",
    "                        lane, yidx, window, vehIdx)\n",
    "\n",
    "            # detect any vehicles\n",
    "            self.roadGrid = self.vehicleDetection.detectVehicles(\n",
    "                self.vehicleScan, self.roadGrid)\n",
    "\n",
    "            # get updated location for our existing vehicles\n",
    "            # and check to make sure our vehicles are still there\n",
    "            vehicleDropList = []\n",
    "            for vehIdx in range(len(self.vehicles)):\n",
    "                self.roadGrid = self.vehicles[vehIdx].updateVehicle(\n",
    "                    self.roadGrid, np.copy(self.curImgFtr.curImage))\n",
    "                if not self.vehicleTracking.isVehicleThere(\n",
    "                        np.copy(self.curImgFtr.curImage),\n",
    "                        self.roadGrid, self.mainLaneIdx,\n",
    "                        self.vehicles, vehIdx):\n",
    "                    vehicleDropList.append(self.vehicles[vehIdx])\n",
    "\n",
    "            self.possibleVehicleWindows = \\\n",
    "                self.roadGrid.getFoundAndNotOccludedWindows()\n",
    "            self.hiddenVehicleWindows = \\\n",
    "                self.roadGrid.getOccludedWindows()\n",
    "\n",
    "            # did we lose any vehicles?\n",
    "            for dropped_vehicle in vehicleDropList:\n",
    "                self.vehicles.remove(dropped_vehicle)\n",
    "\n",
    "            # did we get any new vehicles?\n",
    "            for objIdx in range(self.roadGrid.getNumObjects()):\n",
    "                found = False\n",
    "                boxes = self.roadGrid.getObjectList(objIdx)\n",
    "                for vehIdx in range(len(self.vehicles)):\n",
    "                    if self.vehicles[vehIdx].objectIsVehicle(\n",
    "                            boxes, self.roadGrid):\n",
    "                        self.roadGrid.setVehicle(boxes, vehIdx)\n",
    "                        found = True\n",
    "                if not found:\n",
    "                    ID = len(self.vehicles)\n",
    "                    vehicle = Vehicle(\n",
    "                        ID, self.lanes, self.projMgr, self.roadGrid, objIdx,\n",
    "                        np.copy(self.curImgFtr.curImage), self.mainLaneIdx)\n",
    "\n",
    "                    # TODO - need depth ordering here..\n",
    "                    self.vehicles.append(vehicle)\n",
    "\n",
    "            # re-index our vehicles\n",
    "            for vehIdx in range(len(self.vehicles)):\n",
    "                self.vehicles[vehIdx].vehIdx = vehIdx\n",
    "\n",
    "        # Experimental\n",
    "        # adjust source for perspective projection accordingly\n",
    "        # attempt to dampen bounce\n",
    "        # if (self.leftLineLastTop is not None and\n",
    "        #     self.rightLineLastTop is not None):\n",
    "        #    x = int((self.x -\n",
    "        #            (self.leftLineLastTop[0] +\n",
    "        #             self.rightLineLastTop[0]))/4)\n",
    "        #    self.projMgr.setSrcTopX(x)\n",
    "\n",
    "        # create road mask polygon for reprojection back onto perspective view.\n",
    "        roadmask = np.zeros(\n",
    "            (self.projMgr.projectedY, self.projMgr.projectedX), dtype=np.uint8)\n",
    "\n",
    "        leftLinemask = np.zeros(\n",
    "            (self.projMgr.projectedY, self.projMgr.projectedX), dtype=np.uint8)\n",
    "        rightLinemask = np.zeros(\n",
    "            (self.projMgr.projectedY, self.projMgr.projectedX), dtype=np.uint8)\n",
    "        for i in range(len(self.lanes)):\n",
    "            self.lanes[i].drawLanePoly(roadmask)\n",
    "            leftLinemask = self.curImgFtr.miximg(\n",
    "                leftLinemask, self.lanes[i].leftprojection, 1.0, 1.0)\n",
    "            rightLinemask = self.curImgFtr.miximg(\n",
    "                rightLinemask, self.lanes[i].rightprojection, 1.0, 1.0)\n",
    "\n",
    "        self.roadsurface[:, :, 0] = leftLinemask\n",
    "        self.roadsurface[:, :, 1] = roadmask\n",
    "        self.roadsurface[:, :, 2] = rightLinemask\n",
    "\n",
    "        # generate wireframe scanner rendering.\n",
    "        self.specialProjectedEffects = self.curImgFtr.miximg(\n",
    "            self.roadsurface * 0, self.specialProjectedEffects, 1.0, 0.9)\n",
    "        self.specialPerspectiveEffects = \\\n",
    "            self.curImgFtr.miximg(\n",
    "                self.specialPerspectiveEffects * 0,\n",
    "                self.specialPerspectiveEffects, 1.0, 0.9)\n",
    "        self.sweepLane = self.projMgr.sweep(\n",
    "            self.specialProjectedEffects, self.curFrame, self.lines)\n",
    "\n",
    "        self.roadsquares = self.projMgr.wireframe(\n",
    "            self.roadsurface, self.curFrame, self.lanes[self.mainLaneIdx])\n",
    "        self.roadsurface = self.curImgFtr.miximg(\n",
    "            self.roadsurface, self.specialProjectedEffects, 1.0, 1.0)\n",
    "        self.projMgr.sweep(self.roadsurface, self.curFrame, self.lines)\n",
    "\n",
    "        # draw the possible vehicles detected\n",
    "        self.vehicleDetection.draw_boxes(\n",
    "            self.roadsurface, self.possibleVehicleWindows)\n",
    "        self.vehicleDetection.draw_boxes(\n",
    "            self.roadsurface, self.hiddenVehicleWindows, color=(255, 0, 0))\n",
    "\n",
    "        # draw closing circle when we first initialize\n",
    "        # and then track\n",
    "        for vehicle in self.vehicles:\n",
    "            vehicle.drawClosingCircle(\n",
    "                self.sweepLane,\n",
    "                self.specialProjectedEffects,\n",
    "                self.roadsurface)\n",
    "\n",
    "        # unwarp the roadsurface\n",
    "        self.roadunwarped = self.projMgr.curUnWarp(\n",
    "            self.curImgFtr, self.roadsurface)\n",
    "\n",
    "        # print(\"self.roadunwarped:\", self.roadunwarped.shape)\n",
    "        # print(\"self.curImgFtr.curImage:\", self.curImgFtr.curImage.shape)\n",
    "\n",
    "        # create the final image\n",
    "        self.final = self.curImgFtr.miximg(\n",
    "            self.curImgFtr.curImage, self.roadunwarped, 0.95, 0.75)\n",
    "\n",
    "        # add vehicle detection and tracking visuals\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "        self.projMgr.drawRoadSquares(self.final, self.roadsquares)\n",
    "\n",
    "        self.final = self.curImgFtr.miximg(\n",
    "            self.final, self.specialPerspectiveEffects, 1.0, 1.0)\n",
    "\n",
    "        # vehicle info - left or right side?\n",
    "        if self.mainLaneIdx == 0:\n",
    "            startx = 30\n",
    "        else:\n",
    "            startx = self.x - 285 - 300\n",
    "\n",
    "        # draw vehicle info\n",
    "        for vehIdx in range(len(self.vehicles)):\n",
    "            if self.vehicles[vehIdx].contourInPerspective is not None:\n",
    "                self.specialPerspectiveEffects = self.curImgFtr.miximg(\n",
    "                    self.specialPerspectiveEffects,\n",
    "                    self.vehicles[vehIdx].contourInPerspective,\n",
    "                    1.0, 0.20)\n",
    "            self.vehicles[vehIdx].drawScanning(\n",
    "                self.specialPerspectiveEffects, self.final)\n",
    "\n",
    "            # calculate vehicle info positions\n",
    "            y1 = 150 + 120*vehIdx\n",
    "            y2 = y1 + 80\n",
    "            # print(\"y1, y2: \", y1, y2)\n",
    "            if y2 < 720:\n",
    "                if len(self.vehicles[vehIdx].selfie.shape) > 2:\n",
    "                    self.final[y1:y2, startx:startx+240] = \\\n",
    "                        cv2.resize(\n",
    "                            self.vehicles[vehIdx].selfie,\n",
    "                            (240, 80), interpolation=cv2.INTER_AREA)\n",
    "                else:\n",
    "                    selfie = self.vehicles[vehIdx].selfie\n",
    "                    self.final[y1:y2, startx:startx+240] = \\\n",
    "                        cv2.resize(\n",
    "                        np.dstack((selfie, selfie, selfie)),\n",
    "                        (240, 80), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                Text = self.vehicles[vehIdx].getTextStats()\n",
    "                i = 0\n",
    "                for text in Text.split('\\n'):\n",
    "                    if i == 0:\n",
    "                        cv2.putText(\n",
    "                            self.final, text,\n",
    "                            (startx, y1-10), font, 0.60,\n",
    "                            self.vehicles[vehIdx].statusColor, 2)\n",
    "                    else:\n",
    "                        cv2.putText(\n",
    "                            self.final, text,\n",
    "                            (startx+255, y1-10+15*(i-1)),\n",
    "                            font, 0.50,\n",
    "                            (192, 192, 192), 2)\n",
    "                    i += 1\n",
    "\n",
    "        # draw dots and polyline\n",
    "        if self.debug:\n",
    "            # our own diag screen\n",
    "            self.diag1 = np.copy(self.projMgr.diag4)\n",
    "            cv2.putText(self.projMgr.diag4, 'Frame: %d' %\n",
    "                        (self.curFrame), (30, 30), font, 1, (255, 255, 0), 2)\n",
    "            cv2.putText(self.diag1, 'Frame: %d' %\n",
    "                        (self.curFrame), (30, 30), font, 1, (255, 0, 0), 2)\n",
    "            for i in range(len(self.lines)):\n",
    "                self.lines[i].scatter_plot(self.diag1)\n",
    "                self.lines[i].polyline(self.diag1)\n",
    "                self.lines[i].scatter_plot(self.projMgr.diag4)\n",
    "                self.lines[i].polyline(self.projMgr.diag4)\n",
    "                # self.projMgr.diag3 = \\\n",
    "                #     self.lines[i].applyReverseLineMask(self.projMgr.diag3)\n",
    "\n",
    "                # draw bottom of lane line point if not at bottom\n",
    "                if self.lines[i].bottomProjectedY < self.projMgr.projectedY:\n",
    "                    cv2.circle(self.projMgr.diag4,\n",
    "                               (int(self.lines[i].pixelBasePos),\n",
    "                                int(self.lines[i].bottomProjectedY)),\n",
    "                               10, (64, 64, 255), 10)\n",
    "                    linetext = \"x%d,y%d: %d,%d\" % \\\n",
    "                               (i, i,\n",
    "                                int(self.lines[i].pixelBasePos),\n",
    "                                int(self.lines[i].bottomProjectedY))\n",
    "                    if self.lines[i].side == self.left:\n",
    "                        cv2.putText(self.projMgr.diag4, linetext,\n",
    "                                    (int(self.lines[i].pixelBasePos - 275),\n",
    "                                     int(self.lines[i].bottomProjectedY) - 15),\n",
    "                                    font, 1, (0, 0, 255), 2)\n",
    "                    else:\n",
    "                        cv2.putText(self.projMgr.diag4, linetext,\n",
    "                                    (int(self.lines[i].pixelBasePos + 25),\n",
    "                                     int(self.lines[i].bottomProjectedY) - 15),\n",
    "                                    font, 1, (0, 0, 255), 2)\n",
    "                text = 'Line %d: %d count,  %4.1f%% confidence, detected: %r'\n",
    "                cv2.putText(self.projMgr.diag4, text %\n",
    "                            (i, len(self.lines[i].allY),\n",
    "                             self.lines[i].confidence * 100,\n",
    "                             self.lines[i].detected),\n",
    "                            (30, 60 + 90 * i), font, 1, (255, 255, 0), 2)\n",
    "                if (self.lines[i].radiusOfCurvature is not None and\n",
    "                        self.lines[i].lineBasePos is not None):\n",
    "                    text = 'Line %d: RoC: %fm, DfVC: %fcm'\n",
    "                    cv2.putText(self.projMgr.diag4, text %\n",
    "                                (i, self.lines[i].radiusOfCurvature,\n",
    "                                 self.lines[i].lineBasePos * 100),\n",
    "                                (30, 90 + 90 * i), font, 1, (255, 255, 0), 2)\n",
    "                elif self.lines[i].radiusOfCurvature is not None:\n",
    "                    text = 'Line %d: RoC: %fm, DfVC: UNKNOWN'\n",
    "                    cv2.putText(self.projMgr.diag4, text %\n",
    "                                (i, self.lines[i].radiusOfCurvature),\n",
    "                                (30, 90 + 90 * i), font, 1, (255, 255, 0), 2)\n",
    "                elif self.lines[i].lineBasePos is not None:\n",
    "                    text = 'Line %d: RoC: UNKNOWN, DfVC: %fcm'\n",
    "                    cv2.putText(self.projMgr.diag4, text %\n",
    "                                (i, self.lines[i].lineBasePos * 100),\n",
    "                                (30, 90 + 90 * i), font, 1, (255, 255, 0), 2)\n",
    "                else:\n",
    "                    text = 'Line %d: RoC: UNKNOWN, DfVC: UNKNOWN'\n",
    "                    cv2.putText(self.projMgr.diag4, text % (i),\n",
    "                                (30, 90 + 90 * i), font, 1, (255, 255, 0), 2)\n",
    "                linetext = 'Line %d: is %s %s, '\n",
    "                linetext = linetext + 'more left: %r  more right: %r'\n",
    "                linetext = linetext % (i, self.lines[i].lineType,\n",
    "                                       self.lines[i].line_color,\n",
    "                                       self.lines[i].adjacentLeft,\n",
    "                                       self.lines[i].adjacentRight)\n",
    "                cv2.putText(self.projMgr.diag4, linetext,\n",
    "                            (30, 120 + 90 * i), font, 1, (255, 255, 0), 2)\n",
    "\n",
    "            if self.boosting > 0.0:\n",
    "                y = 90 * len(self.lines)\n",
    "                cv2.putText(self.projMgr.diag4, 'Boosting @ %f%%' % (\n",
    "                    self.boosting),\n",
    "                    (30, 60 + y), font, 1, (128, 128, 192), 2)\n",
    "\n",
    "            # print(\"self.roadsurface:\", self.roadsurface.shape)\n",
    "            # print(\"self.roadunwarped:\", self.roadunwarped.shape)\n",
    "            # print(\"self.projMgr.diag4:\", self.projMgr.diag4.shape)\n",
    "            # print(\"self.projMgr.diag2:\", self.projMgr.diag2.shape)\n",
    "\n",
    "            self.projMgr.diag4 = self.curImgFtr.miximg(\n",
    "                self.projMgr.diag4, self.roadsurface, 1.0, 2.0)\n",
    "            self.projMgr.diag2 = self.curImgFtr.miximg(\n",
    "                self.projMgr.diag2, self.roadunwarped, 1.0, 0.5)\n",
    "            self.projMgr.diag1 = self.curImgFtr.miximg(\n",
    "                self.projMgr.diag1, self.roadunwarped[\n",
    "                    self.mid:self.y, :, :], 1.0, 2.0)\n",
    "\n",
    "            # generate the window positions\n",
    "            if self.scrType & 5 == 5:\n",
    "                windows = self.vehicleDetection.slidingWindows(\n",
    "                    self.lines, self.mainLaneIdx, False)\n",
    "                print(\"sentinal_windows=\", windows)\n",
    "                # self.vehicleDetection.draw_boxes(self.projMgr.diag3, windows)\n",
    "            elif self.scrType & 4 == 4:\n",
    "                windows = self.vehicleDetection.slidingWindows(\n",
    "                    self.lines, self.mainLaneIdx, True)\n",
    "                print(\"complete_scan_windows=\", windows)\n",
    "                # self.vehicleDetection.draw_boxes(self.projMgr.diag3, windows)\n",
    "            else:\n",
    "                if mainLane.lines[mainLane.left].adjacentLeft:\n",
    "                    self.projMgr.draw_estimated_lane_line_location(\n",
    "                        self.projMgr.diag3,\n",
    "                        mainLane.lines[mainLane.left].pixelBasePos, 0)\n",
    "                    self.projMgr.draw_estimated_lane_line_location(\n",
    "                        self.projMgr.diag3,\n",
    "                        mainLane.lines[mainLane.left].pixelBasePos,\n",
    "                        -mainLane.distance)\n",
    "                    self.projMgr.draw_estimated_lane_line_location(\n",
    "                        self.projMgr.diag3,\n",
    "                        mainLane.lines[mainLane.left].pixelBasePos,\n",
    "                        -mainLane.distance * 2)\n",
    "                    self.projMgr.draw_estimated_lane_line_location(\n",
    "                        self.projMgr.diag3,\n",
    "                        mainLane.lines[mainLane.left].pixelBasePos,\n",
    "                        -mainLane.distance * 3)\n",
    "                else:\n",
    "                    self.projMgr.draw_estimated_lane_line_location(\n",
    "                        self.projMgr.diag3,\n",
    "                        mainLane.lines[mainLane.left].pixelBasePos, 0)\n",
    "\n",
    "                if mainLane.lines[mainLane.right].adjacentRight:\n",
    "                    self.projMgr.draw_estimated_lane_line_location(\n",
    "                        self.projMgr.diag3,\n",
    "                        mainLane.lines[mainLane.right].pixelBasePos, 0)\n",
    "                    self.projMgr.draw_estimated_lane_line_location(\n",
    "                        self.projMgr.diag3,\n",
    "                        mainLane.lines[mainLane.right].pixelBasePos,\n",
    "                        mainLane.distance)\n",
    "                    self.projMgr.draw_estimated_lane_line_location(\n",
    "                        self.projMgr.diag3,\n",
    "                        mainLane.lines[mainLane.right].pixelBasePos,\n",
    "                        mainLane.distance * 2)\n",
    "                    self.projMgr.draw_estimated_lane_line_location(\n",
    "                        self.projMgr.diag3,\n",
    "                        mainLane.lines[mainLane.right].pixelBasePos,\n",
    "                        mainLane.distance * 3)\n",
    "                else:\n",
    "                    self.projMgr.draw_estimated_lane_line_location(\n",
    "                        self.projMgr.diag3,\n",
    "                        mainLane.lines[mainLane.right].pixelBasePos, 0)\n",
    "                self.vehicleDetection.draw_boxes(\n",
    "                    self.projMgr.diag3, self.possibleVehicleWindows)\n",
    "\n",
    "            # let's try to draw some cubes...\n",
    "            # self.projMgr.drawAxisOnLane(self.projMgr.diag2)\n",
    "            # self.projMgr.drawCalibrationCube(self.projMgr.diag2)\n",
    "            # self.projMgr.drawCubes(self.projMgr.diag2,\n",
    "            #                        self.possibleVehicleWindows)\n",
    "\n",
    "            self.projMgr.drawRoadSquares(self.projMgr.diag2, self.roadsquares)\n",
    "\n",
    "            self.projMgr.diag2 = self.curImgFtr.miximg(\n",
    "                self.projMgr.diag2, self.specialPerspectiveEffects, 1.0, 1.0)\n",
    "\n",
    "            # vehicle info - left or right side?\n",
    "            if self.mainLaneIdx == 0:\n",
    "                startx = 30\n",
    "            else:\n",
    "                startx = self.x - 285 - 300\n",
    "\n",
    "            # diagnostics vehicle info\n",
    "            for vehIdx in range(len(self.vehicles)):\n",
    "                if self.vehicles[vehIdx].contourInPerspective is not None:\n",
    "                    self.specialPerspectiveEffects = self.curImgFtr.miximg(\n",
    "                        self.specialPerspectiveEffects,\n",
    "                        self.vehicles[vehIdx].contourInPerspective,\n",
    "                        1.0, 0.20)\n",
    "                self.vehicles[vehIdx].drawScanning(\n",
    "                    self.specialPerspectiveEffects, self.projMgr.diag2)\n",
    "\n",
    "                # experimental\n",
    "                # draw cube cross-section - if enough points\n",
    "                # if len(self.vehicles[vehIdx].cube_intersect) == 4:\n",
    "                #     print(\"cube_intersect: \",\n",
    "                #         self.vehicles[vehIdx].cube_intersect)\n",
    "                #     cv2.drawContours(\n",
    "                #         self.projMgr.diag2,\n",
    "                #         [self.vehicles[vehIdx].cube_intersect[:4]],\n",
    "                #         -1, (255, 0, 255), 3)\n",
    "\n",
    "                # calculate vehicle info positions\n",
    "                y1 = 275 + 120*vehIdx\n",
    "                y2 = y1 + 80\n",
    "                # print(\"y1, y2: \", y1, y2)\n",
    "                if y2 < 720:\n",
    "                    if len(self.vehicles[vehIdx].selfie.shape) > 2:\n",
    "                        self.projMgr.diag2[y1:y2, startx:startx+240] = \\\n",
    "                            cv2.resize(\n",
    "                                self.vehicles[vehIdx].selfie,\n",
    "                                (240, 80), interpolation=cv2.INTER_AREA)\n",
    "                    else:\n",
    "                        selfie = self.vehicles[vehIdx].selfie\n",
    "                        self.projMgr.diag2[y1:y2, startx:startx+240] = \\\n",
    "                            cv2.resize(\n",
    "                                np.dstack((selfie, selfie, selfie)),\n",
    "                                (240, 80), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "                    Text = self.vehicles[vehIdx].getTextStats()\n",
    "                    i = 0\n",
    "                    for text in Text.split('\\n'):\n",
    "                        if i == 0:\n",
    "                            cv2.putText(\n",
    "                                self.projMgr.diag2, text,\n",
    "                                (startx, 265+120*vehIdx), font, 0.60,\n",
    "                                self.vehicles[vehIdx].statusColor, 2)\n",
    "                        else:\n",
    "                            cv2.putText(\n",
    "                                self.projMgr.diag2, text,\n",
    "                                (startx+255, 265+120*vehIdx+15*(i-1)),\n",
    "                                font, 0.50,\n",
    "                                (192, 192, 192), 2)\n",
    "                        i += 1\n",
    "\n",
    "    def drawLaneStats(self, color=(224, 192, 0)):\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "        if self.roadStraight:\n",
    "            text = 'Estimated lane curvature: road nearly straight'\n",
    "            cv2.putText(self.final, text,\n",
    "                        (30, 60), font, 1, color, 2)\n",
    "        elif self.radiusOfCurvature > 0.0:\n",
    "            text = 'Estimated lane curvature: center is %fm to the right'\n",
    "            cv2.putText(self.final, text % (\n",
    "                self.radiusOfCurvature), (30, 60), font, 1, color, 2)\n",
    "        else:\n",
    "            text = 'Estimated lane curvature: center is %fm to the left'\n",
    "            cv2.putText(self.final, text %\n",
    "                        (-self.radiusOfCurvature), (30, 60), font, 1, color, 2)\n",
    "\n",
    "        if self.lineBasePos < 0.0:\n",
    "            text = 'Estimated left of center: %5.2fcm'\n",
    "            cv2.putText(self.final, text %\n",
    "                        (-self.lineBasePos * 100), (30, 90), font, 1, color, 2)\n",
    "        elif self.lineBasePos > 0.0:\n",
    "            text = 'Estimated right of center: %5.2fcm'\n",
    "            cv2.putText(self.final, text % (\n",
    "                self.lineBasePos * 100), (30, 90), font, 1, color, 2)\n",
    "        else:\n",
    "            text = 'Estimated at center of road'\n",
    "            cv2.putText(self.final, text, (30, 90), font, 1, color, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnosis Management\n",
    "\n",
    "Diagnosis Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DiagManager():\n",
    "    # Initialize ImageFilter\n",
    "\n",
    "    def __init__(self, roadManager):\n",
    "        self.rMgr = roadManager\n",
    "        self.pMgr = self.rMgr.projMgr\n",
    "\n",
    "    ########################################################\n",
    "    # Apply Textural Diagnostics\n",
    "    ########################################################\n",
    "    def textOverlay(self, diagScreen, offset, color=(64, 64, 0)):\n",
    "        roadMgr = self.rMgr\n",
    "        projMgr = self.pMgr\n",
    "        imgFtr = self.rMgr.curImgFtr\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "        # output image stats\n",
    "        y = 30 + offset\n",
    "        text = '%-28s%-28s%-28sBalance: %f' % (\n",
    "            imgFtr.skyText, imgFtr.skyImageQ,\n",
    "            imgFtr.roadImageQ, imgFtr.roadbalance)\n",
    "        cv2.putText(diagScreen, text, (30, y), font, 1, color, 2)\n",
    "\n",
    "        # output projection stats in the next two lines\n",
    "        y += 30\n",
    "        if imgFtr.horizonFound:\n",
    "            text = 'Projection Last Top: %d'\n",
    "            text += '   Road Horizon: %d'\n",
    "            text += '   Vanishing Point: %d'\n",
    "            text = text % (roadMgr.lastTop, imgFtr.roadhorizon,\n",
    "                           projMgr.lane_info[7][1])\n",
    "            cv2.putText(diagScreen, text, (30, y), font, 1, color, 2)\n",
    "        else:\n",
    "            text = 'Projection Last Top: %d   Horizon: NOT FOUND!'\n",
    "            cv2.putText(diagScreen, text % (\n",
    "                roadMgr.lastTop), (30, y), font, 1, color, 2)\n",
    "        y += 30\n",
    "        text = 'Road Backoff at: %d   Gap: %d   Visibility: %6.2fm'\n",
    "        cv2.putText(diagScreen, text % (\n",
    "            projMgr.curGradient,\n",
    "            projMgr.curGradient - projMgr.gradient0,\n",
    "            imgFtr.throwDistance), (30, y), font, 1, color, 2)\n",
    "\n",
    "        # output restart stats\n",
    "        y += 30\n",
    "        text = 'Restart Count: %d   Projection Reset Count: %d' % (\n",
    "            roadMgr.restartCount, roadMgr.resetProjectionCount)\n",
    "        cv2.putText(diagScreen, text, (30, y), font, 1, color, 2)\n",
    "\n",
    "        # output vehicle stats\n",
    "        y += 30\n",
    "        text = 'Vehicle Count: %d' % (\n",
    "            len(roadMgr.vehicles))\n",
    "        cv2.putText(diagScreen, text, (30, y), font, 1, color, 2)\n",
    "\n",
    "        return diagScreen\n",
    "\n",
    "    ########################################################\n",
    "    # Full diagnostics of the RoadManager\n",
    "    ########################################################\n",
    "    def fullDiag(self, color=(128, 128, 0)):\n",
    "        roadMgr = self.rMgr\n",
    "        projMgr = self.pMgr\n",
    "        imgFtr = self.rMgr.curImgFtr\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "        diag2 = projMgr.diag2.astype(np.uint8)\n",
    "        imgFtr.drawHorizon(diag2)\n",
    "        middlepanel = np.zeros((120, 1280, 3), dtype=np.uint8)\n",
    "\n",
    "        # curvature output\n",
    "        if roadMgr.roadStraight:\n",
    "            text = 'Estimated lane curvature: road nearly straight'\n",
    "            cv2.putText(middlepanel, text,\n",
    "                        (30, 60), font, 1, color, 2)\n",
    "        elif roadMgr.radiusOfCurvature > 0.0:\n",
    "            text = 'Estimated lane curvature: center is %fm to the right'\n",
    "            cv2.putText(middlepanel, text % (\n",
    "                roadMgr.radiusOfCurvature), (30, 60), font, 1, color, 2)\n",
    "        else:\n",
    "            text = 'Estimated lane curvature: center is %fm to the left'\n",
    "            cv2.putText(middlepanel, text % (-roadMgr.radiusOfCurvature),\n",
    "                        (30, 60), font, 1, color, 2)\n",
    "\n",
    "        # center of road output\n",
    "        if roadMgr.lineBasePos < 0.0:\n",
    "            text = 'Estimated left of center: %5.2fcm'\n",
    "            cv2.putText(middlepanel, text % (-roadMgr.lineBasePos * 1000),\n",
    "                        (30, 90), font, 1, color, 2)\n",
    "        elif roadMgr.lineBasePos > 0.0:\n",
    "            text = 'Estimated right of center: %5.2fcm'\n",
    "            cv2.putText(middlepanel, text % (roadMgr.lineBasePos * 1000),\n",
    "                        (30, 90), font, 1, color, 2)\n",
    "        else:\n",
    "            cv2.putText(middlepanel, 'Estimated at center of road',\n",
    "                        (30, 90), font, 1, color, 2)\n",
    "\n",
    "        # assemble the screen\n",
    "        diagScreen = np.zeros((1080, 1920, 3), dtype=np.uint8)\n",
    "        if roadMgr.diag1.shape[0] == 720:\n",
    "            diagScreen[0:720, 0:1280] = roadMgr.diag1\n",
    "        else:\n",
    "            diagScreen[0:720, 0:1280] = cv2.resize(\n",
    "                np.rot90(roadMgr.diag1), (1280, 720),\n",
    "                interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # image filters\n",
    "        diagScreen[0:240, 1280:1600] = cv2.resize(\n",
    "            imgFtr.diag1, (320, 240), interpolation=cv2.INTER_AREA)\n",
    "        diagScreen[0:240, 1600:1920] = cv2.resize(\n",
    "            imgFtr.diag2, (320, 240), interpolation=cv2.INTER_AREA)\n",
    "        diagScreen[240:480, 1280:1600] = cv2.resize(\n",
    "            imgFtr.diag3, (320, 240), interpolation=cv2.INTER_AREA)\n",
    "        diagScreen[240:480, 1600:1920] = cv2.resize(\n",
    "            imgFtr.diag4, (320, 240), interpolation=cv2.INTER_AREA) * 4\n",
    "\n",
    "        diagScreen[600:1080, 1280:1920] = cv2.resize(\n",
    "            roadMgr.final, (640, 480), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        diagScreen[720:840, 0:1280] = middlepanel\n",
    "\n",
    "        # projection\n",
    "        diagScreen[840:1080, 0:320] = cv2.resize(\n",
    "            diag2, (320, 240), interpolation=cv2.INTER_AREA)\n",
    "        diagScreen[840:1080, 320:640] = cv2.resize(\n",
    "            projMgr.diag1, (320, 240), interpolation=cv2.INTER_AREA)\n",
    "        diagScreen[840:1080, 640:960] = cv2.resize(\n",
    "            np.rot90(projMgr.diag3), (320, 240),\n",
    "            interpolation=cv2.INTER_AREA)\n",
    "        diagScreen[840:1080, 960:1280] = cv2.resize(\n",
    "            np.rot90(projMgr.diag4), (320, 240),\n",
    "            interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        return diagScreen\n",
    "\n",
    "    ########################################################\n",
    "    # Diagnostics of the Projection Manager (Single)\n",
    "    ########################################################\n",
    "    def projectionHD(self):\n",
    "        projMgr = self.pMgr\n",
    "        imgFtr = self.rMgr.curImgFtr\n",
    "\n",
    "        # assemble the screen\n",
    "        diagScreen = projMgr.diag3.astype(np.uint8)\n",
    "\n",
    "        return diagScreen\n",
    "\n",
    "    ########################################################\n",
    "    # Diagnostics of the Projection Manager\n",
    "    ########################################################\n",
    "    def projectionDiag(self):\n",
    "        projMgr = self.pMgr\n",
    "        imgFtr = self.rMgr.curImgFtr\n",
    "\n",
    "        diag2 = projMgr.diag2.astype(np.uint8)\n",
    "        imgFtr.drawHorizon(diag2)\n",
    "\n",
    "        # assemble the screen\n",
    "        diagScreen = np.zeros((1080, 1920, 3), dtype=np.uint8)\n",
    "        diagScreen[0:540, 0:960] = cv2.resize(\n",
    "            diag2, (960, 540), interpolation=cv2.INTER_AREA)\n",
    "        diagScreen[0:540, 960:1920] = cv2.resize(projMgr.diag1.astype(\n",
    "            np.uint8), (960, 540), interpolation=cv2.INTER_AREA)\n",
    "        diagScreen[540:1080, 0:960] = cv2.resize(np.rot90(\n",
    "            projMgr.diag3.astype(np.uint8)), (960, 540),\n",
    "            interpolation=cv2.INTER_AREA)\n",
    "        diagScreen[540:1080, 960:1920] = cv2.resize(np.rot90(\n",
    "            projMgr.diag4.astype(np.uint8)), (960, 540),\n",
    "            interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        return diagScreen\n",
    "\n",
    "    ########################################################\n",
    "    # Diagnostics of the Image Filters\n",
    "    ########################################################\n",
    "    def filterDiag(self):\n",
    "        imgFtr = self.rMgr.curImgFtr\n",
    "\n",
    "        # assemble the screen\n",
    "        diagScreen = np.zeros((1080, 1920, 3), dtype=np.uint8)\n",
    "        diagScreen[0:540, 0:960] = cv2.resize(\n",
    "            imgFtr.diag1, (960, 540), interpolation=cv2.INTER_AREA)\n",
    "        diagScreen[0:540, 960:1920] = cv2.resize(imgFtr.diag2.astype(\n",
    "            np.uint8), (960, 540), interpolation=cv2.INTER_AREA)\n",
    "        diagScreen[540:1080, 0:960] = cv2.resize(imgFtr.diag3.astype(\n",
    "            np.uint8), (960, 540), interpolation=cv2.INTER_AREA)\n",
    "        diagScreen[540:1080, 960:1920] = cv2.resize(imgFtr.diag4.astype(\n",
    "            np.uint8), (960, 540), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        return diagScreen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main\n",
    "\n",
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_road_image(\n",
    "        img, roadMgr, diagMgr, scrType=0, debug=False, resized=False):\n",
    "    # Run the functions\n",
    "    roadMgr.findLanes(img, resized=resized)\n",
    "\n",
    "    # debug/diagnostics requested\n",
    "    if debug:\n",
    "        # offset for text rendering overlay\n",
    "        offset = 0\n",
    "        color = (192, 192, 0)\n",
    "        # default - full diagnostics\n",
    "        if scrType & 5 == 5:\n",
    "            diagScreen = diagMgr.projectionHD()\n",
    "            offset = 30\n",
    "        if scrType & 4 == 4:\n",
    "            diagScreen = diagMgr.projectionHD()\n",
    "            offset = 30\n",
    "        elif scrType & 3 == 3:\n",
    "            diagScreen = diagMgr.fullDiag()\n",
    "            offset = 30\n",
    "        elif scrType & 3 == 2:\n",
    "            diagScreen = diagMgr.projectionDiag()\n",
    "            offset = 30\n",
    "        elif scrType & 3 == 1:\n",
    "            diagScreen = diagMgr.filterDiag()\n",
    "            offset = 30\n",
    "            color = (192, 192, 192)\n",
    "        if scrType & 8 == 8:\n",
    "            diagScreen = diagMgr.textOverlay(\n",
    "                diagScreen, offset=offset, color=color)\n",
    "        result = diagScreen\n",
    "    else:\n",
    "        if scrType & 8 == 8:\n",
    "            roadMgr.drawLaneStats()\n",
    "        result = roadMgr.final\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    global roadMgr\n",
    "    global diagMgr\n",
    "    global debug\n",
    "    global scrType\n",
    "\n",
    "    # for smaller videos - white.mp4 and yellow.mp4\n",
    "    if image is not None:\n",
    "        resized = False\n",
    "        sizey, sizex, ch = image.shape\n",
    "        if sizex != roadMgr.x or sizey != roadMgr.y:\n",
    "            resized = True\n",
    "            image = cv2.resize(image, (roadMgr.x, roadMgr.y),\n",
    "                               interpolation=cv2.INTER_AREA)\n",
    "    result = process_road_image(image, roadMgr, diagMgr, scrType=scrType, debug=debug, resized=resized)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera Calibration data restored from camera_cal/calibrationdata.p\n",
      "video processing project_video.mp4...\n",
      "[MoviePy] >>>> Building video final.mp4\n",
      "[MoviePy] Writing video final.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [12:42<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: final.mp4 \n",
      "\n",
      "done video processing project_video.mp4...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    # initialize argparse to parse the CLI\n",
    "    usage = 'python %(prog)s [options] infilename outfilename'\n",
    "    desc = 'DIYJAC\\'s Udacity SDC Project 5: Vehicle Detection and Tracking'\n",
    "    diagHelp = 'display diagnostics: [0=off], 1=filter, 2=proj 3=full '\n",
    "    diagHelp += '4=projHD,complete 5=projHD,sentinal'\n",
    "    collectHelp = 'collect 64x64 birds-eye view images for HOG training'\n",
    "    defaultInput = 'project_video.mp4'\n",
    "    inputHelp = 'input image or video file to process'\n",
    "    defaultOutput = 'project_video_out.mp4'\n",
    "    outputHelp = 'output image or video file'\n",
    "\n",
    "    # set default - final/no diagnostics\n",
    "    parser = argparse.ArgumentParser(prog='P4pipeline.py',\n",
    "                                     usage=usage, description=desc)\n",
    "    parser.add_argument('--diag', type=int, default=0, help=diagHelp)\n",
    "    parser.add_argument('--notext', action='store_true',\n",
    "                        default=False, help='do not render text overlay')\n",
    "    parser.add_argument('--collect', action='store_true', default=False,\n",
    "                        help=collectHelp)\n",
    "    parser.add_argument('infilename', type=str, default=defaultInput,\n",
    "                        help=inputHelp)\n",
    "    parser.add_argument('outfilename', type=str, default=defaultOutput,\n",
    "                        help=outputHelp)\n",
    "    args = parser.parse_args()\n",
    "    debug = False\n",
    "\n",
    "    videopattern = re.compile(\"^.+\\.mp4$\")\n",
    "    imagepattern = re.compile(\"^.+\\.(jpg|jpeg|JPG|png|PNG)$\")\n",
    "    image = None\n",
    "    videoin = None\n",
    "    valid = False\n",
    "\n",
    "    # set up pipeline processing options\n",
    "    pleaseCheck = \"Please check and try again.\"\n",
    "    pleaseRemove = \"Please remove and try again.\"\n",
    "    invalidExt = \"Invalid %s filename extension for output.  %s\"\n",
    "    validImageExt = \"Must end with one of [jpg,jpeg,JPG,png,PNG]\"\n",
    "    validVideoExt = \"Must end with '.mp4'\"\n",
    "    \"\"\"\n",
    "    \n",
    "    videopattern = re.compile(\"^.+\\.mp4$\")\n",
    "    imagepattern = re.compile(\"^.+\\.(jpg|jpeg|JPG|png|PNG)$\")\n",
    "    image = None\n",
    "    \n",
    "    collect = False\n",
    "    diag = 3\n",
    "    videoin = 'project_video.mp4'\n",
    "    notext = False\n",
    "    videoout = 'final.mp4'\n",
    "    valid = True\n",
    "\n",
    "    \"\"\"\n",
    "    # if video - set up in/out videos\n",
    "    if videopattern.match(args.infilename):\n",
    "        if videopattern.match(args.outfilename):\n",
    "            if not os.path.exists(args.infilename):\n",
    "                print(\"Video input file: %s does not exist. %s\" % (\n",
    "                    args.infilename, pleaseCheck))\n",
    "                sys.exit(1)\n",
    "            elif os.path.exists(args.outfilename):\n",
    "                print(\"Video output file: %s exists.  %s\" % (\n",
    "                    args.outfilename, pleaseRemove))\n",
    "                sys.exit(2)\n",
    "            else:\n",
    "                videoin = args.infilename\n",
    "                videoout = args.outfilename\n",
    "                valid = True\n",
    "        else:\n",
    "            print(invalidExt % (\"video\", validVideoExt))\n",
    "            sys.exit(3)\n",
    "    \"\"\"\n",
    "\n",
    "    # set up diagnostic pipeline options if requested\n",
    "    if valid:\n",
    "        #scrType = args.diag\n",
    "        scrType = diag\n",
    "        if (scrType & 7) > 0:\n",
    "            debug = True\n",
    "        #if not args.notext:\n",
    "        if not notext:\n",
    "            scrType = scrType | 8\n",
    "        #if args.collect:\n",
    "        if collect:\n",
    "            print(\"Will collect training data from %s...\" % (args.infilename))\n",
    "            scrType = scrType | 16\n",
    "\n",
    "        # initialization\n",
    "        # load or perform camera calibrations\n",
    "        camCal = CameraCal('camera_cal', 'camera_cal/calibrationdata.p')\n",
    "\n",
    "        # override camCal image size\n",
    "        if image is not None:\n",
    "            camCal.setImageSize(image.shape)\n",
    "\n",
    "        # initialize road manager and its managed pipeline components/modules\n",
    "        roadMgr = RoadManager(camCal, debug=debug, scrType=scrType)\n",
    "\n",
    "        # initialize diag manager and its managed diagnostics components\n",
    "        if debug:\n",
    "            diagMgr = DiagManager(roadMgr)\n",
    "        else:\n",
    "            diagMgr = None\n",
    "\n",
    "        # Image only?\n",
    "        if image is not None:\n",
    "            print(\"image processing %s...\" % (args.infilename))\n",
    "            imageout = process_image(image)\n",
    "            cv2.imwrite(args.outfilename, cv2.cvtColor(\n",
    "                imageout, cv2.COLOR_RGB2BGR))\n",
    "            print(\"done image processing %s...\" % (args.infilename))\n",
    "\n",
    "        # Full video pipeline\n",
    "        elif videoin is not None and videoout is not None:\n",
    "            print(\"video processing %s...\" % (videoin))\n",
    "            clip1 = VideoFileClip(videoin)\n",
    "            video_clip = clip1.fl_image(process_image)\n",
    "            video_clip.write_videofile(videoout, audio=False)\n",
    "            print(\"done video processing %s...\" % (videoin))\n",
    "    else:\n",
    "        print(\"error detected.  exiting.\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
